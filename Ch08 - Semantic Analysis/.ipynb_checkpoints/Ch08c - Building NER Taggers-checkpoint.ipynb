{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your own NER Tagger\n",
    "\n",
    "__Named Entity Recognition (NER)__ , also known as entity chunking/extraction , is a popular technique used in information extraction to identify and segment the named entities and classify or categorize them under various predefined classes.\n",
    "\n",
    "There are various off the shelf solutions which offer capabilites to perform named entity extraction (some of which we discussed in the previous units). Yet there are times when the requirements are beyond the capabilities of off-the-shelf classifiers.\n",
    "\n",
    "In this notebook, we will go through an exercise to build our own NER using Conditional Random Fields.\n",
    "We would be utilizing ```sklearn_crfsuite``` to develop our NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Named Entity Recognition is a sequence modeling problem at it's core. It is more related to classification class of problems where in we need a labeled dataset to train a classifier. \n",
    "\n",
    "There are various labeled datasets for NER class of problems. We would be utilizing a pre-processed version of __GMB(Groningen Meaning Bank) corpus__ for this notebook. The preprocessed version is availble at the following link : [kaggle/ner](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)\n",
    "\n",
    "We have provided the dataset in the code repository itself using some intelligent compression and you can access it directly from `pandas` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 4 columns):\n",
      "Sentence #    47959 non-null object\n",
      "Word          1048575 non-null object\n",
      "POS           1048575 non-null object\n",
      "Tag           1048575 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ner_dataset.csv.gz', compression='gzip', encoding='ISO-8859-1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048565</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>impact</td>\n",
       "      <td>.</td>\n",
       "      <td>Indian</td>\n",
       "      <td>forces</td>\n",
       "      <td>said</td>\n",
       "      <td>they</td>\n",
       "      <td>responded</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>TO</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1048575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1              2       3        4        5        \\\n",
       "Sentence #  Sentence: 1     NaN            NaN     NaN      NaN      NaN   \n",
       "Word          Thousands      of  demonstrators    have  marched  through   \n",
       "POS                 NNS      IN            NNS     VBP      VBN       IN   \n",
       "Tag                   O       O              O       O        O        O   \n",
       "\n",
       "           6       7        8       9         ...   1048565 1048566  \\\n",
       "Sentence #     NaN     NaN      NaN     NaN   ...       NaN     NaN   \n",
       "Word        London      to  protest     the   ...    impact       .   \n",
       "POS            NNP      TO       VB      DT   ...        NN       .   \n",
       "Tag          B-geo       O        O       O   ...         O       O   \n",
       "\n",
       "                    1048567 1048568 1048569 1048570    1048571 1048572  \\\n",
       "Sentence #  Sentence: 47959     NaN     NaN     NaN        NaN     NaN   \n",
       "Word                 Indian  forces    said    they  responded      to   \n",
       "POS                      JJ     NNS     VBD     PRP        VBD      TO   \n",
       "Tag                   B-gpe       O       O       O          O       O   \n",
       "\n",
       "           1048573 1048574  \n",
       "Sentence #     NaN     NaN  \n",
       "Word           the  attack  \n",
       "POS             DT      NN  \n",
       "Tag              O       O  \n",
       "\n",
       "[4 rows x 1048575 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 4 columns):\n",
      "Sentence #    1048575 non-null object\n",
      "Word          1048575 non-null object\n",
      "POS           1048575 non-null object\n",
      "Tag           1048575 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048565</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>...</td>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>impact</td>\n",
       "      <td>.</td>\n",
       "      <td>Indian</td>\n",
       "      <td>forces</td>\n",
       "      <td>said</td>\n",
       "      <td>they</td>\n",
       "      <td>responded</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>TO</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1048575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1              2            3            4        \\\n",
       "Sentence #  Sentence: 1  Sentence: 1    Sentence: 1  Sentence: 1  Sentence: 1   \n",
       "Word          Thousands           of  demonstrators         have      marched   \n",
       "POS                 NNS           IN            NNS          VBP          VBN   \n",
       "Tag                   O            O              O            O            O   \n",
       "\n",
       "                5            6            7            8            9        \\\n",
       "Sentence #  Sentence: 1  Sentence: 1  Sentence: 1  Sentence: 1  Sentence: 1   \n",
       "Word            through       London           to      protest          the   \n",
       "POS                  IN          NNP           TO           VB           DT   \n",
       "Tag                   O        B-geo            O            O            O   \n",
       "\n",
       "                 ...                 1048565          1048566  \\\n",
       "Sentence #       ...         Sentence: 47958  Sentence: 47958   \n",
       "Word             ...                  impact                .   \n",
       "POS              ...                      NN                .   \n",
       "Tag              ...                       O                O   \n",
       "\n",
       "                    1048567          1048568          1048569  \\\n",
       "Sentence #  Sentence: 47959  Sentence: 47959  Sentence: 47959   \n",
       "Word                 Indian           forces             said   \n",
       "POS                      JJ              NNS              VBD   \n",
       "Tag                   B-gpe                O                O   \n",
       "\n",
       "                    1048570          1048571          1048572  \\\n",
       "Sentence #  Sentence: 47959  Sentence: 47959  Sentence: 47959   \n",
       "Word                   they        responded               to   \n",
       "POS                     PRP              VBD               TO   \n",
       "Tag                       O                O                O   \n",
       "\n",
       "                    1048573          1048574  \n",
       "Sentence #  Sentence: 47959  Sentence: 47959  \n",
       "Word                    the           attack  \n",
       "POS                      DT               NN  \n",
       "Tag                       O                O  \n",
       "\n",
       "[4 rows x 1048575 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 35178, 42, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentence #'].nunique(), df.Word.nunique(), df.POS.nunique(), df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 47959 sentences that contain 35178 unique words.\n",
    "\n",
    "These sentences have a total of 42 unique POS tags and 17 unique NER tags in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Distribution\n",
    "\n",
    "The GMB dataset utilizes IOB tagging or _Inside, Outside Beginning_. IOB is a common tagging format for tagging tokens which we have discussed earlier. To refresh your memory:\n",
    "\n",
    "+ __I- prefix__ before a tag indicates that the tag is inside a chunk.\n",
    "+ __B- prefix__ before a tag indicates that the tag is the beginning of a chunk.\n",
    "+ __O-  tag__ indicates that a token belongs to no chunk (outside).\n",
    "\n",
    "The tags in this dataset are explained as follows:\n",
    "\n",
    "+ __geo__ = Geographical Entity\n",
    "+ __org__ = Organization\n",
    "+ __per__ = Person\n",
    "+ __gpe__ = Geopolitical Entity\n",
    "+ __tim__ = Time indicator\n",
    "+ __art__ = Artifact\n",
    "+ __eve__ = Event\n",
    "+ __nat__ = Natural Phenomenon\n",
    "\n",
    "Anything outside these classes is termed as other, denoted as __O__. \n",
    "\n",
    "The following output shows the unbalanced distribution of different tags in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tag.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Fields\n",
    "\n",
    "As mentioned above, NER belongs to sequence modeling class of problems. There are different algorithms to tackle sequence modeling, __CRF__ or _Conditional Random Fields_ are one such example. CRFs are proven to perform extremely well on NER and related domains. In this notebook, we will attempt at developing our own NER based on CRFs.\n",
    "\n",
    "---\n",
    "\n",
    "__Question__: What is a CRF and how does it work?\n",
    "\n",
    "__Wikipedia__ :  CRF is an undirected graphical model whose nodes can be divided into exactly two disjoint sets $X$ and $Y$, the observed and output variables, respectively; the conditional distribution $p(Y|X)$ is then modeled.\n",
    "\n",
    "For more details, checkout the paper [__Conditional Random Fields: Probabilistic Models\n",
    "for Segmenting and Labeling Sequence Data__](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "CRF trains upon sequence of input data to learn transitions from one state (label) to another. \n",
    "To enable such an algorithm, we need to define features which take into account different transitions. \n",
    "In the function ```word2features()``` below, we transform each word into a feature dictionary depicting the following attributes or features:\n",
    "\n",
    "+ lower case of word\n",
    "+ suffix containing last 3 characters\n",
    "+ suffix containing last 2 characters\n",
    "+ flags to determine upper-case, title-case, numeric data and POS tag\n",
    "\n",
    "We also attach attributes related to previous and next words or tags to determine beginning of sentence (BOS) or end of sentence (EOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
    "                                                   s['POS'].values.tolist(), \n",
    "                                                   s['Tag'].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('Sentence #').apply(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')])]\n"
     ]
    }
   ],
   "source": [
    "print(grouped_df[grouped_df.index == 'Sentence: 1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [s for s in grouped_df]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'word.lower()': 'through',\n",
       "  'word[-3:]': 'ugh',\n",
       "  'word[-2:]': 'gh',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'BOS': True,\n",
       "  '+1:word.lower()': 'london',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNP',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'london',\n",
       "  'word[-3:]': 'don',\n",
       "  'word[-2:]': 'on',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNP',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'through',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  'EOS': True}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(sentences[0][5:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-geo']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2labels(sentences[0][5:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35969,), (11990,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([sent2features(s) for s in sentences])\n",
    "y = np.array([sent2labels(s) for s in sentences])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models with sklearn-crfsuite\n",
    "\n",
    "__`sklearn-crfsuite`__ is a thin [CRFsuite (python-crfsuite)](https://github.com/scrapinghub/python-crfsuite) wrapper which provides scikit-learn-compatible sklearn_crfsuite.CRF estimator: you can use e.g. scikit-learn model selection utilities (cross-validation, hyperparameter optimization) with it, or save/load CRF models using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-crfsuite\n",
      "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
      "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite)\n",
      "  Downloading https://files.pythonhosted.org/packages/29/c9/b206fa75d5978a631b5e6914a051139d99ff4624f96eac1bec6486413944/python_crfsuite-0.9.6-cp36-cp36m-win_amd64.whl (154kB)\n",
      "Requirement already satisfied: tabulate in c:\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (0.8.2)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (4.26.0)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (1.11.0)\n",
      "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
      "Successfully installed python-crfsuite-0.9.6 sklearn-crfsuite-0.3.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thinc 6.10.2 requires pathlib<2.0.0,>=1.0.0, which is not installed.\n",
      "spacy 2.0.11 requires pathlib, which is not installed.\n",
      "smart-open 1.7.1 requires bz2file, which is not installed.\n",
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "spacy 2.0.11 has requirement regex==2017.4.5, but you'll have regex 2017.11.9 which is incompatible.\n",
      "skater 1.1.1b5 has requirement scikit-image==0.14, but you'll have scikit-image 0.13.1 which is incompatible.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model!\n",
    "\n",
    "Train the model using the default configurations mentioned in the [sklearn-crfsuite API docs](https://sklearn-crfsuite.readthedocs.io/en/latest/api.html)\n",
    "\n",
    "\n",
    "- __algorithm:__ the training algorithm. We use [L-BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS) for gradient descent for optimization and getting model parameters\n",
    "- __c1:__ Coefficient for Lasso (L1) regularization\n",
    "- __c2:__ Coefficient for Ridge (L2) regularization\n",
    "- __all_possible_transitions:__ Specify whether CRFsuite generates transition features that do not even occur in the training data\n",
    "\n",
    "\n",
    "__Note:__ If the model is taking too long to train, you can load up the pre-trained model using the code after the training cells and use that for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs',\n",
    "                           c1=0.1,\n",
    "                           c2=0.1,\n",
    "                           max_iterations=100,\n",
    "                           all_possible_transitions=True,\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|███████████████████████████████████████| 35969/35969 [00:15<00:00, 2384.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 133629\n",
      "Seconds required: 3.486\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=4.01  loss=1264028.26 active=132637 feature_norm=1.00\n",
      "Iter 2   time=3.99  loss=994059.01 active=131294 feature_norm=4.42\n",
      "Iter 3   time=2.00  loss=776413.87 active=125970 feature_norm=3.87\n",
      "Iter 4   time=11.46 loss=422143.40 active=127018 feature_norm=3.24\n",
      "Iter 5   time=2.11  loss=355775.44 active=129029 feature_norm=4.04\n",
      "Iter 6   time=2.23  loss=264125.22 active=124046 feature_norm=6.10\n",
      "Iter 7   time=2.36  loss=222304.71 active=117183 feature_norm=7.69\n",
      "Iter 8   time=2.21  loss=197827.17 active=110838 feature_norm=8.75\n",
      "Iter 9   time=2.09  loss=176877.92 active=105650 feature_norm=10.41\n",
      "Iter 10  time=2.09  loss=158997.61 active=103459 feature_norm=11.60\n",
      "Iter 11  time=2.10  loss=146328.53 active=100247 feature_norm=13.41\n",
      "Iter 12  time=2.09  loss=137671.14 active=98635 feature_norm=14.69\n",
      "Iter 13  time=2.11  loss=130471.62 active=97462 feature_norm=15.45\n",
      "Iter 14  time=2.09  loss=118841.84 active=94124 feature_norm=17.81\n",
      "Iter 15  time=2.11  loss=112928.42 active=92178 feature_norm=20.21\n",
      "Iter 16  time=2.09  loss=105499.44 active=91978 feature_norm=22.27\n",
      "Iter 17  time=2.08  loss=101994.76 active=91940 feature_norm=23.34\n",
      "Iter 18  time=2.10  loss=96362.28 active=89453 feature_norm=26.63\n",
      "Iter 19  time=2.09  loss=90647.28 active=89021 feature_norm=28.85\n",
      "Iter 20  time=2.10  loss=85521.13 active=87547 feature_norm=32.66\n",
      "Iter 21  time=2.11  loss=81239.75 active=87184 feature_norm=36.05\n",
      "Iter 22  time=2.09  loss=77980.98 active=86649 feature_norm=39.45\n",
      "Iter 23  time=2.08  loss=75036.81 active=86300 feature_norm=41.33\n",
      "Iter 24  time=2.10  loss=70028.55 active=82924 feature_norm=47.18\n",
      "Iter 25  time=4.16  loss=67859.30 active=82277 feature_norm=51.09\n",
      "Iter 26  time=2.10  loss=64640.62 active=81815 feature_norm=54.83\n",
      "Iter 27  time=2.09  loss=61783.61 active=80545 feature_norm=60.05\n",
      "Iter 28  time=2.08  loss=59095.29 active=79506 feature_norm=66.46\n",
      "Iter 29  time=2.09  loss=56799.57 active=79733 feature_norm=70.47\n",
      "Iter 30  time=2.09  loss=54812.68 active=79492 feature_norm=75.32\n",
      "Iter 31  time=2.28  loss=52807.07 active=78965 feature_norm=80.24\n",
      "Iter 32  time=2.28  loss=50790.16 active=78225 feature_norm=88.16\n",
      "Iter 33  time=2.15  loss=49548.49 active=78456 feature_norm=90.54\n",
      "Iter 34  time=2.12  loss=48303.45 active=78007 feature_norm=94.98\n",
      "Iter 35  time=2.12  loss=46171.65 active=76442 feature_norm=106.16\n",
      "Iter 36  time=2.11  loss=45327.99 active=75732 feature_norm=115.55\n",
      "Iter 37  time=2.08  loss=43822.08 active=75408 feature_norm=118.88\n",
      "Iter 38  time=2.09  loss=42688.21 active=74715 feature_norm=125.25\n",
      "Iter 39  time=2.09  loss=41275.71 active=73716 feature_norm=139.21\n",
      "Iter 40  time=2.08  loss=40047.55 active=73576 feature_norm=147.46\n",
      "Iter 41  time=2.12  loss=39265.28 active=73554 feature_norm=151.63\n",
      "Iter 42  time=2.12  loss=38403.33 active=72721 feature_norm=159.70\n",
      "Iter 43  time=2.34  loss=37608.69 active=72627 feature_norm=165.70\n",
      "Iter 44  time=2.14  loss=36823.99 active=71771 feature_norm=172.98\n",
      "Iter 45  time=2.11  loss=36326.35 active=70178 feature_norm=184.40\n",
      "Iter 46  time=2.09  loss=35883.80 active=69283 feature_norm=186.01\n",
      "Iter 47  time=2.11  loss=35560.99 active=68923 feature_norm=190.20\n",
      "Iter 48  time=2.10  loss=35404.76 active=67538 feature_norm=199.98\n",
      "Iter 49  time=2.11  loss=35012.55 active=67985 feature_norm=200.64\n",
      "Iter 50  time=2.10  loss=34929.44 active=68033 feature_norm=200.67\n",
      "Iter 51  time=2.08  loss=34693.21 active=67122 feature_norm=201.84\n",
      "Iter 52  time=4.14  loss=34629.25 active=66830 feature_norm=201.25\n",
      "Iter 53  time=2.09  loss=34459.64 active=66761 feature_norm=202.56\n",
      "Iter 54  time=2.10  loss=34344.14 active=66577 feature_norm=203.72\n",
      "Iter 55  time=2.10  loss=34165.12 active=66051 feature_norm=205.31\n",
      "Iter 56  time=2.09  loss=34162.67 active=64890 feature_norm=206.81\n",
      "Iter 57  time=2.13  loss=33943.85 active=65312 feature_norm=207.03\n",
      "Iter 58  time=2.10  loss=33886.19 active=64897 feature_norm=207.50\n",
      "Iter 59  time=2.10  loss=33780.88 active=64020 feature_norm=208.77\n",
      "Iter 60  time=2.10  loss=33666.08 active=63580 feature_norm=209.40\n",
      "Iter 61  time=2.10  loss=33571.12 active=63159 feature_norm=210.40\n",
      "Iter 62  time=2.34  loss=33488.40 active=63013 feature_norm=210.87\n",
      "Iter 63  time=2.23  loss=33397.52 active=62694 feature_norm=211.68\n",
      "Iter 64  time=2.11  loss=33317.69 active=62488 feature_norm=212.22\n",
      "Iter 65  time=2.11  loss=33247.01 active=62238 feature_norm=212.80\n",
      "Iter 66  time=2.08  loss=33173.26 active=62029 feature_norm=213.27\n",
      "Iter 67  time=2.10  loss=33108.73 active=61781 feature_norm=213.91\n",
      "Iter 68  time=2.11  loss=33052.25 active=61575 feature_norm=214.27\n",
      "Iter 69  time=2.08  loss=32996.19 active=61366 feature_norm=214.76\n",
      "Iter 70  time=2.09  loss=32941.28 active=61153 feature_norm=215.10\n",
      "Iter 71  time=2.08  loss=32894.22 active=60966 feature_norm=215.53\n",
      "Iter 72  time=2.10  loss=32853.09 active=60815 feature_norm=215.78\n",
      "Iter 73  time=2.07  loss=32814.22 active=60658 feature_norm=216.15\n",
      "Iter 74  time=2.10  loss=32778.22 active=60513 feature_norm=216.37\n",
      "Iter 75  time=2.09  loss=32743.64 active=60336 feature_norm=216.67\n",
      "Iter 76  time=2.09  loss=32711.92 active=60185 feature_norm=216.86\n",
      "Iter 77  time=2.11  loss=32682.08 active=60090 feature_norm=217.11\n",
      "Iter 78  time=2.09  loss=32654.10 active=59916 feature_norm=217.27\n",
      "Iter 79  time=2.09  loss=32627.76 active=59768 feature_norm=217.54\n",
      "Iter 80  time=2.10  loss=32603.13 active=59701 feature_norm=217.65\n",
      "Iter 81  time=2.11  loss=32580.63 active=59546 feature_norm=217.85\n",
      "Iter 82  time=2.08  loss=32559.76 active=59413 feature_norm=217.96\n",
      "Iter 83  time=2.08  loss=32538.88 active=59278 feature_norm=218.17\n",
      "Iter 84  time=2.14  loss=32520.71 active=59165 feature_norm=218.27\n",
      "Iter 85  time=2.12  loss=32501.10 active=59088 feature_norm=218.47\n",
      "Iter 86  time=2.09  loss=32484.14 active=58988 feature_norm=218.56\n",
      "Iter 87  time=2.08  loss=32467.58 active=58909 feature_norm=218.71\n",
      "Iter 88  time=2.16  loss=32452.86 active=58808 feature_norm=218.80\n",
      "Iter 89  time=2.08  loss=32437.92 active=58717 feature_norm=218.98\n",
      "Iter 90  time=2.10  loss=32424.99 active=58671 feature_norm=219.06\n",
      "Iter 91  time=2.13  loss=32411.01 active=58618 feature_norm=219.21\n",
      "Iter 92  time=2.09  loss=32399.15 active=58552 feature_norm=219.29\n",
      "Iter 93  time=2.08  loss=32386.63 active=58490 feature_norm=219.40\n",
      "Iter 94  time=2.08  loss=32375.74 active=58448 feature_norm=219.48\n",
      "Iter 95  time=2.10  loss=32364.54 active=58374 feature_norm=219.60\n",
      "Iter 96  time=2.07  loss=32354.96 active=58381 feature_norm=219.68\n",
      "Iter 97  time=2.08  loss=32344.27 active=58343 feature_norm=219.80\n",
      "Iter 98  time=2.09  loss=32335.08 active=58304 feature_norm=219.87\n",
      "Iter 99  time=2.07  loss=32324.92 active=58249 feature_norm=219.98\n",
      "Iter 100 time=2.09  loss=32316.67 active=58226 feature_norm=220.04\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 228.530\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 58226 (133629)\n",
      "Number of active attributes: 29279 (90250)\n",
      "Number of active labels: 17 (17)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.095\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the following to load our pre-trained model if training above takes a lot of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#joblib.dump(crf, 'ner_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = joblib.load('ner_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "Let's evaluate our model performance for NER Tagging on the test data now!\n",
    "\n",
    "Try playing around with the following cells and observe the overall model performance.\n",
    "\n",
    "We use standard classification metrics like precision, recall and f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-per', 'I-per', 'O', 'B-org', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'B-per', 'I-per', 'O', 'B-org', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import metrics as crf_metrics\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-org       0.81      0.73      0.77      5116\n",
      "       B-per       0.85      0.84      0.84      4239\n",
      "       I-per       0.85      0.90      0.88      4273\n",
      "       B-geo       0.86      0.91      0.89      9403\n",
      "       I-geo       0.81      0.80      0.81      1826\n",
      "       B-tim       0.93      0.89      0.91      5095\n",
      "       I-org       0.82      0.79      0.80      4195\n",
      "       B-gpe       0.97      0.94      0.96      3961\n",
      "       I-tim       0.84      0.81      0.82      1604\n",
      "       B-nat       0.50      0.24      0.32        55\n",
      "       B-eve       0.51      0.33      0.40        80\n",
      "       B-art       0.36      0.14      0.20       102\n",
      "       I-art       0.24      0.07      0.10        90\n",
      "       I-eve       0.45      0.19      0.27        74\n",
      "       I-gpe       0.86      0.53      0.66        36\n",
      "       I-nat       0.57      0.22      0.32        18\n",
      "\n",
      "   micro avg       0.86      0.85      0.86     40167\n",
      "   macro avg       0.70      0.58      0.62     40167\n",
      "weighted avg       0.86      0.85      0.85     40167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have intentially left out the ___Others___ tag to understand the performance of model on the remaining tags. The above evaluation statistics showcase a model which seems to have learnt the transitions quite well giving us an overall F1-score of 85%!\n",
    "\n",
    "We can achieve even better results by fine tuning the feature engineering step along with hyper-parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End NER Tagger with trained NER Model\n",
    "\n",
    "There is no fun (or value!) if we cannot use our model to tag new sentences in the future assuming we would want to put this model in production. Let's try and build an end-to-end workflow to perform NER Tagging on our sample document. First we perform NER tagging with SpaCy to remind you how it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three more countries have joined an “international grand committee” of parliaments, adding to calls for Facebook’s boss, Mark Zuckerberg, to give evidence on misinformation to the coalition. Brazil, Latvia and Singapore bring the total to eight different parliaments across the world, with plans to send representatives to London on 27 November with the intention of hearing from Zuckerberg. Since the Cambridge Analytica scandal broke, the Facebook chief has only appeared in front of two legislatures: the American Senate and House of Representatives, and the European parliament. Facebook has consistently rebuffed attempts from others, including the UK and Canadian parliaments, to hear from Zuckerberg. He added that an article in the New York Times on Thursday, in which the paper alleged a pattern of behaviour from Facebook to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly dealt with within Facebook.”'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"Three more countries have joined an “international grand committee” of parliaments, adding to calls for \n",
    "Facebook’s boss, Mark Zuckerberg, to give evidence on misinformation to the coalition. Brazil, Latvia and Singapore \n",
    "bring the total to eight different parliaments across the world, with plans to send representatives to London on 27 \n",
    "November with the intention of hearing from Zuckerberg. Since the Cambridge Analytica scandal broke, the Facebook chief \n",
    "has only appeared in front of two legislatures: the American Senate and House of Representatives, and the European parliament. \n",
    "Facebook has consistently rebuffed attempts from others, including the UK and Canadian parliaments, to hear from Zuckerberg. \n",
    "He added that an article in the New York Times on Thursday, in which the paper alleged a pattern of behaviour from Facebook \n",
    "to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly \n",
    "dealt with within Facebook.”\n",
    "\"\"\"\n",
    "\n",
    "text = re.sub(r'\\n', '', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER Tagging with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " more countries have joined an “international grand committee” of parliaments, adding to calls for \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s boss, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Mark Zuckerberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", to give evidence on misinformation to the coalition. \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Latvia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Singapore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " bring the total to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    eight\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " different parliaments across the world, with plans to send representatives to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    London\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    27 November\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " with the intention of hearing from \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Zuckerberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". Since the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Cambridge\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " Analytica scandal broke, the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " chief has only appeared in front of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " legislatures: the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Senate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    House of Representatives\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    European\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " parliament. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has consistently rebuffed attempts from others, including the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Canadian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " parliaments, to hear from \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Zuckerberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". He added that an article in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the New York Times\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", in which the paper alleged a pattern of behaviour from \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly dealt with within \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".”</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "text_nlp = nlp(text)\n",
    "displacy.render(text_nlp, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Step 1\n",
    "\n",
    "- Tokenize Text\n",
    "- POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Three', 'CD'),\n",
       " ('more', 'JJR'),\n",
       " ('countries', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('joined', 'VBN'),\n",
       " ('an', 'DT'),\n",
       " ('“', 'NNP'),\n",
       " ('international', 'JJ'),\n",
       " ('grand', 'JJ'),\n",
       " ('committee', 'NN')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text_tokens = nltk.word_tokenize(text)\n",
    "text_pos = nltk.pos_tag(text_tokens)\n",
    "text_pos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Step 2\n",
    "- Extract Features from the POS tagged text document\n",
    "- Hint: Use `sent2features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'three',\n",
       " 'word[-3:]': 'ree',\n",
       " 'word[-2:]': 'ee',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': True,\n",
       " 'word.isdigit()': False,\n",
       " 'postag': 'CD',\n",
       " 'postag[:2]': 'CD',\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': 'more',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:postag': 'JJR',\n",
       " '+1:postag[:2]': 'JJ'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [sent2features(text_pos)]\n",
    "features[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Step 3\n",
    "- Use the CRF Model `crf` to predict on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-art', 'I-art']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = crf.predict(features)\n",
    "doc_labels = labels[0]\n",
    "doc_labels[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Step 4\n",
    "- Combine text tokens with NER Tags\n",
    "- Retrieve relevant named entities from NER Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Three', 'O'), ('more', 'O'), ('countries', 'O'), ('have', 'O'), ('joined', 'O'), ('an', 'O'), ('“', 'O'), ('international', 'O'), ('grand', 'O'), ('committee', 'O'), ('”', 'O'), ('of', 'O'), ('parliaments', 'O'), (',', 'O'), ('adding', 'O'), ('to', 'O'), ('calls', 'O'), ('for', 'O'), ('Facebook', 'B-art'), ('’', 'I-art'), ('s', 'O'), ('boss', 'O'), (',', 'O'), ('Mark', 'B-per'), ('Zuckerberg', 'I-per'), (',', 'O'), ('to', 'O'), ('give', 'O'), ('evidence', 'O'), ('on', 'O'), ('misinformation', 'O'), ('to', 'O'), ('the', 'O'), ('coalition', 'O'), ('.', 'O'), ('Brazil', 'B-geo'), (',', 'O'), ('Latvia', 'B-org'), ('and', 'I-org'), ('Singapore', 'I-org'), ('bring', 'O'), ('the', 'O'), ('total', 'O'), ('to', 'O'), ('eight', 'O'), ('different', 'O'), ('parliaments', 'O'), ('across', 'O'), ('the', 'O'), ('world', 'O'), (',', 'O'), ('with', 'O'), ('plans', 'O'), ('to', 'O'), ('send', 'O'), ('representatives', 'O'), ('to', 'O'), ('London', 'B-geo'), ('on', 'O'), ('27', 'B-tim'), ('November', 'I-tim'), ('with', 'O'), ('the', 'O'), ('intention', 'O'), ('of', 'O'), ('hearing', 'O'), ('from', 'O'), ('Zuckerberg', 'B-geo'), ('.', 'O'), ('Since', 'O'), ('the', 'O'), ('Cambridge', 'B-org'), ('Analytica', 'I-org'), ('scandal', 'O'), ('broke', 'O'), (',', 'O'), ('the', 'O'), ('Facebook', 'B-org'), ('chief', 'O'), ('has', 'O'), ('only', 'O'), ('appeared', 'O'), ('in', 'O'), ('front', 'O'), ('of', 'O'), ('two', 'O'), ('legislatures', 'O'), (':', 'O'), ('the', 'O'), ('American', 'B-gpe'), ('Senate', 'B-org'), ('and', 'I-org'), ('House', 'I-org'), ('of', 'I-org'), ('Representatives', 'I-org'), (',', 'O'), ('and', 'O'), ('the', 'O'), ('European', 'B-org'), ('parliament', 'I-org'), ('.', 'O'), ('Facebook', 'B-org'), ('has', 'O'), ('consistently', 'O'), ('rebuffed', 'O'), ('attempts', 'O'), ('from', 'O'), ('others', 'O'), (',', 'O'), ('including', 'O'), ('the', 'O'), ('UK', 'B-org'), ('and', 'O'), ('Canadian', 'B-gpe'), ('parliaments', 'O'), (',', 'O'), ('to', 'O'), ('hear', 'O'), ('from', 'O'), ('Zuckerberg', 'B-geo'), ('.', 'O'), ('He', 'O'), ('added', 'O'), ('that', 'O'), ('an', 'O'), ('article', 'O'), ('in', 'O'), ('the', 'O'), ('New', 'B-org'), ('York', 'I-org'), ('Times', 'I-org'), ('on', 'O'), ('Thursday', 'B-tim'), (',', 'O'), ('in', 'O'), ('which', 'O'), ('the', 'O'), ('paper', 'O'), ('alleged', 'O'), ('a', 'O'), ('pattern', 'O'), ('of', 'O'), ('behaviour', 'O'), ('from', 'O'), ('Facebook', 'B-org'), ('to', 'O'), ('“', 'O'), ('delay', 'O'), (',', 'O'), ('deny', 'O'), ('and', 'O'), ('deflect', 'O'), ('”', 'O'), ('negative', 'O'), ('news', 'O'), ('stories', 'O'), (',', 'O'), ('“', 'O'), ('raises', 'O'), ('further', 'O'), ('questions', 'O'), ('about', 'O'), ('how', 'O'), ('recent', 'O'), ('data', 'O'), ('breaches', 'O'), ('were', 'O'), ('allegedly', 'O'), ('dealt', 'O'), ('with', 'O'), ('within', 'O'), ('Facebook', 'B-art'), ('.', 'O'), ('”', 'O')]\n"
     ]
    }
   ],
   "source": [
    "text_ner = [(token, tag) for token, tag in zip(text_tokens, doc_labels)]\n",
    "print(text_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = []\n",
    "temp_entity_name = ''\n",
    "temp_named_entity = None\n",
    "for term, tag in text_ner:\n",
    "    if tag != 'O':\n",
    "        temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "        temp_named_entity = (temp_entity_name, tag)\n",
    "    else:\n",
    "        if temp_named_entity:\n",
    "            named_entities.append(temp_named_entity)\n",
    "            temp_entity_name = ''\n",
    "            temp_named_entity = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook ’</td>\n",
       "      <td>I-art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>I-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latvia and Singapore</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27 November</td>\n",
       "      <td>I-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zuckerberg</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cambridge Analytica</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>American Senate and House of Representatives</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>European parliament</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UK</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Canadian</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zuckerberg</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>New York Times</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Entity    Tag\n",
       "0                                     Facebook ’  I-art\n",
       "1                                Mark Zuckerberg  I-per\n",
       "2                                         Brazil  B-geo\n",
       "3                           Latvia and Singapore  I-org\n",
       "4                                         London  B-geo\n",
       "5                                    27 November  I-tim\n",
       "6                                     Zuckerberg  B-geo\n",
       "7                            Cambridge Analytica  I-org\n",
       "8                                       Facebook  B-org\n",
       "9   American Senate and House of Representatives  I-org\n",
       "10                           European parliament  I-org\n",
       "11                                      Facebook  B-org\n",
       "12                                            UK  B-org\n",
       "13                                      Canadian  B-gpe\n",
       "14                                    Zuckerberg  B-geo\n",
       "15                                New York Times  I-org\n",
       "16                                      Thursday  B-tim\n",
       "17                                      Facebook  B-org\n",
       "18                                      Facebook  B-art"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(named_entities, columns=['Entity', 'Tag'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
