{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propositional Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign symbols and propositions\n",
    "symbol_P = 'P'\n",
    "symbol_Q = 'Q'\n",
    "\n",
    "proposition_P = 'He is hungry'\n",
    "propositon_Q = 'He will eat a sandwich'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign various truth values to the propositions\n",
    "p_statuses = [False, False, True, True]\n",
    "q_statuses = [False, True, False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(P & Q)', '(P | Q)', '(P -> Q)', '(P <-> Q)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign the various expressions combining the logical operators\n",
    "conjunction = '(P & Q)'\n",
    "disjunction = '(P | Q)'\n",
    "implication = '(P -> Q)'\n",
    "equivalence = '(P <-> Q)'\n",
    "expressions = [conjunction, disjunction, implication, equivalence]\n",
    "expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each expression using propositional logic\n",
    "results = []\n",
    "for status_p, status_q in zip(p_statuses, q_statuses):\n",
    "    dom = set([])\n",
    "    val = nltk.Valuation([(symbol_P, status_p), \n",
    "                          (symbol_Q, status_q)])\n",
    "    assignments = nltk.Assignment(dom)\n",
    "    model = nltk.Model(dom, val)\n",
    "    row = [status_p, status_q]\n",
    "    for expression in expressions:\n",
    "    # evaluate each expression based on proposition truth values\n",
    "        result = model.evaluate(expression, assignments) \n",
    "        row.append(result)\n",
    "    results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the result table\n",
    "columns = [symbol_P, symbol_Q, conjunction, \n",
    "           disjunction, implication, equivalence]           \n",
    "result_frame = pd.DataFrame(results, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: He is hungry\n",
      "Q: He will eat a sandwich\n",
      "\n",
      "Expression Outcomes:-\n",
      "       P      Q  (P & Q)  (P | Q)  (P -> Q)  (P <-> Q)\n",
      "0  False  False    False    False      True       True\n",
      "1  False   True    False     True      True      False\n",
      "2   True  False    False     True     False      False\n",
      "3   True   True     True     True      True       True\n"
     ]
    }
   ],
   "source": [
    "# display results\n",
    "print('P:', proposition_P)\n",
    "print('Q:', propositon_Q)\n",
    "print()\n",
    "print('Expression Outcomes:-')\n",
    "print(result_frame)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Order Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.inference.resolution.ResolutionProver at 0x28944f5ed68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "\n",
    "# for reading FOL expressions\n",
    "read_expr = nltk.sem.Expression.fromstring\n",
    "\n",
    "# initialize theorem provers (you can choose any)\n",
    "os.environ['PROVER9'] = r'E:/prover9/bin'\n",
    "prover = nltk.Prover9()\n",
    "\n",
    "# I use the following one for our examples\n",
    "prover = nltk.ResolutionProver() \n",
    "prover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] {-jumps_over(dog,fox)}                    A \n",
      "[2] {jumps_over(fox,dog)}                     A \n",
      "[3] {-jumps_over(z4,z3), -jumps_over(z3,z4)}  A \n",
      "[4] {-jumps_over(dog,fox)}                    (2, 3) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the rule expression\n",
    "rule = read_expr('all x. all y. (jumps_over(x, y) -> -jumps_over(y, x))')\n",
    "\n",
    "# set the event occured\n",
    "event = read_expr('jumps_over(fox, dog)')\n",
    "\n",
    "# set the outcome we want to evaluate -- the goal\n",
    "test_outcome = read_expr('jumps_over(dog, fox)')\n",
    "\n",
    "# get the result\n",
    "prover.prove(goal=test_outcome, \n",
    "             assumptions=[event, rule],\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] {-pass(John,exam)}                  A \n",
      "[2] {-studies(John,exam)}               A \n",
      "[3] {-studies(z6,exam), pass(z6,exam)}  A \n",
      "[4] {-studies(John,exam)}               (1, 3) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the rule expression                          \n",
    "rule = read_expr('all x. (studies(x, exam) -> pass(x, exam))') \n",
    "\n",
    "# set the events and outcomes we want to determine\n",
    "event1 = read_expr('-studies(John, exam)')  \n",
    "test_outcome1 = read_expr('pass(John, exam)') \n",
    "\n",
    "prover.prove(goal=test_outcome1, \n",
    "             assumptions=[event1, rule],\n",
    "             verbose=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] {-pass(Pierre,exam)}                A \n",
      "[2] {studies(Pierre,exam)}              A \n",
      "[3] {-studies(z8,exam), pass(z8,exam)}  A \n",
      "[4] {-studies(Pierre,exam)}             (1, 3) \n",
      "[5] {pass(Pierre,exam)}                 (2, 3) \n",
      "[6] {}                                  (1, 5) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event2 = read_expr('studies(Pierre, exam)')  \n",
    "test_outcome2 = read_expr('pass(Pierre, exam)') \n",
    "\n",
    "prover.prove(goal=test_outcome2, \n",
    "             assumptions=[event2, rule],\n",
    "             verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rover': 'r',\n",
       " 'felix': 'f',\n",
       " 'garfield': 'g',\n",
       " 'alex': 'a',\n",
       " 'dog': {('a',), ('r',)},\n",
       " 'cat': {('g',)},\n",
       " 'fox': {('f',)},\n",
       " 'runs': {('a',), ('f',)},\n",
       " 'sleeps': {('g',), ('r',)},\n",
       " 'jumps_over': {('a', 'g'), ('a', 'r'), ('f', 'g'), ('f', 'r')}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define symbols (entities\\functions) and their values\n",
    "rules = \"\"\"\n",
    "    rover => r\n",
    "    felix => f\n",
    "    garfield => g\n",
    "    alex => a\n",
    "    dog => {r, a}\n",
    "    cat => {g}\n",
    "    fox => {f}\n",
    "    runs => {a, f}\n",
    "    sleeps => {r, g}\n",
    "    jumps_over => {(f, g), (a, g), (f, r), (a, r)}\n",
    "    \"\"\"\n",
    "\n",
    "val = nltk.Valuation.fromstring(rules)\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'g', 'a', 'f', 'r'}, {'rover': 'r', 'felix': 'f', 'garfield': 'g', 'alex': 'a', 'dog': {('r',), ('a',)}, 'cat': {('g',)}, 'fox': {('f',)}, 'runs': {('a',), ('f',)}, 'sleeps': {('r',), ('g',)}, 'jumps_over': {('f', 'g'), ('a', 'g'), ('f', 'r'), ('a', 'r')}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom = {'r', 'f', 'g', 'a'}\n",
    "m = nltk.Model(dom, val)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate('jumps_over(felix, rover) & dog(rover) & runs(rover)', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate('jumps_over(felix, rover) & dog(rover) & -runs(rover)', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate('jumps_over(alex, garfield) & dog(alex) & cat(garfield) & sleeps(garfield)', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'r', 'y': 'f'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = nltk.Assignment(dom, [('x', 'r'), ('y', 'f')])   \n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate('runs(y) & jumps_over(y, x) & sleeps(x)', g)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate('exists y. (fox(y) & runs(y))', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'f'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = read_expr('runs(x)')\n",
    "m.satisfiers(formula, 'x', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = read_expr('runs(x) & fox(x)')\n",
    "m.satisfiers(formula, 'x', g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
