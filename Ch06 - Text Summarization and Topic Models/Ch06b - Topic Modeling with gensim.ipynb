{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval\n",
    "\n",
    "This may not work on windows so just use the extracted NIPS papers data from the __`nipstxt/`__ folder present in the same directory as this notebook which already has the data pre-downloaded and extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-07 18:59:33--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
      "Resolving cs.nyu.edu (cs.nyu.edu)... 128.122.49.30\n",
      "Connecting to cs.nyu.edu (cs.nyu.edu)|128.122.49.30|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12851423 (12M) [application/x-gzip]\n",
      "Saving to: ‘nips12raw_str602.tgz’\n",
      "\n",
      "nips12raw_str602.tg 100%[===================>]  12.26M  1.75MB/s    in 7.4s    \n",
      "\n",
      "2018-11-07 18:59:41 (1.65 MB/s) - ‘nips12raw_str602.tgz’ saved [12851423/12851423]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nips01', 'nips04', 'MATLAB_NOTES', 'nips10', 'nips02', 'idx', 'nips11', 'nips03', 'nips07', 'README_yann', 'nips05', 'nips12', 'nips06', 'RAW_DATA_NOTES', 'orig', 'nips00', 'nips08', 'nips09']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
    "# Read all texts into a list.\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652 \n",
      "Scaling Properties of Coarse-Coded Symbol Memories \n",
      "Ronald Rosenfeld \n",
      "David S. Touretzky \n",
      "Computer Science Department \n",
      "Carnegie Mellon University \n",
      "Pittsburgh, Pennsylvania 15213 \n",
      "Abstract\n",
      "Coarse-coded symbol memories have appeared in several neural network \n",
      "symbol processing models. In order to determine how these models would scale, one \n",
      "must first have some understanding of the mathematics of coarse-coded representa- \n",
      "tions. We define the general structure of coarse-coded symbol memories and derive \n",
      "mathematical relationships among their essential parameters: memort size, slmbol-set \n",
      "size and capacitor. The computed capacity of one of the schemes agrees well with actual \n",
      "measurements of the coarse-coded working memory of DCPS, Touretzky and Hinton's \n",
      "distributed connectionist production system. \n",
      "1 Introduction \n",
      "A dstributed representation is a memory scheme in which each entity (concept, symbol) \n",
      "is represented by a pattern of activity over many units [3]. If each unit partic\n"
     ]
    }
   ],
   "source": [
    "print(papers[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Text Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "CPU times: user 38.6 s, sys: 92 ms, total: 38.7 s\n",
      "Wall time: 38.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "            \n",
    "    return norm_papers\n",
    "    \n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scaling', 'property', 'coarse', 'coded', 'symbol', 'memory', 'ronald', 'rosenfeld', 'david', 'touretzky', 'computer', 'science', 'department', 'carnegie', 'mellon', 'university', 'pittsburgh', 'pennsylvania', 'abstract', 'coarse', 'coded', 'symbol', 'memory', 'appeared', 'several', 'neural', 'network', 'symbol', 'processing', 'model', 'order', 'determine', 'model', 'would', 'scale', 'one', 'must', 'first', 'understanding', 'mathematics', 'coarse', 'coded', 'representa', 'tions', 'define', 'general', 'structure', 'coarse', 'coded', 'symbol']\n"
     ]
    }
   ],
   "source": [
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation with Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scaling', 'property', 'coarse_coded', 'symbol', 'memory', 'ronald', 'rosenfeld', 'david_touretzky', 'computer_science', 'department', 'carnegie_mellon', 'university_pittsburgh', 'pennsylvania', 'abstract', 'coarse_coded', 'symbol', 'memory', 'appeared', 'several', 'neural_network', 'symbol', 'processing', 'model', 'order', 'determine', 'model', 'would', 'scale', 'one', 'must', 'first', 'understanding', 'mathematics', 'coarse_coded', 'representa_tions', 'define', 'general', 'structure', 'coarse_coded', 'symbol', 'memory', 'derive', 'mathematical', 'relationship', 'among', 'essential', 'parameter', 'memor', 'size', 'lmbol']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20, delimiter=b'_') # higher threshold fewer phrases.\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "print(bigram_model[norm_papers[0]][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, '8a'), (1, 'abandon'), (2, 'able'), (3, 'abo'), (4, 'abstract'), (5, 'accommodate'), (6, 'accuracy'), (7, 'achieved'), (8, 'acknowledgment_thank'), (9, 'across'), (10, 'active'), (11, 'activity'), (12, 'actual'), (13, 'adjusted'), (14, 'adjusting')]\n",
      "Total Vocabulary Size: 78892\n"
     ]
    }
   ],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 7756\n"
     ]
    }
   ],
   "source": [
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 1), (14, 2), (20, 1), (28, 1), (33, 1), (43, 1), (50, 1), (60, 2), (61, 1), (62, 2), (63, 1), (72, 1), (84, 1), (88, 3), (102, 2), (109, 2), (112, 5), (122, 6), (125, 4), (127, 3), (129, 2), (130, 4), (133, 5), (141, 3), (157, 1), (158, 1), (173, 1), (174, 1), (177, 1), (183, 1), (189, 1), (192, 1), (207, 1), (213, 1), (214, 3), (227, 2), (234, 1), (237, 1), (239, 1), (244, 4), (252, 4), (256, 4), (272, 1), (277, 1), (280, 2), (286, 39), (296, 6), (306, 1), (307, 2), (316, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Transforming corpus into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('achieved', 1), ('allow', 2), ('american_institute', 1), ('another', 1), ('appeared', 1), ('argument', 1), ('assume', 1), ('become', 2), ('becomes', 1), ('behavior', 2), ('behavioral', 1), ('bounded', 1), ('cause', 1), ('certain', 3), ('column', 2), ('complete', 2), ('computational', 5), ('connection', 6), ('consider', 4), ('considered', 3), ('consists', 2), ('constant', 4), ('constraint', 5), ('corresponding', 3), ('denote', 1), ('density', 1), ('determines', 1), ('developed', 1), ('dimension', 1), ('distributed_processing', 1), ('ed_parallel', 1), ('effect', 1), ('enforced', 1), ('equal', 1), ('equation', 3), ('every', 2), ('except', 1), ('expected', 1), ('experiment', 1), ('expression', 4), ('finally', 4), ('fixed', 4), ('furthermore', 1), ('give', 1), ('good', 2), ('group', 39), ('hence', 6), ('implementation', 1), ('implemented', 2), ('independent', 1)]\n"
     ]
    }
   ],
   "source": [
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers: 1740\n"
     ]
    }
   ],
   "source": [
    "print('Total number of papers:', len(bow_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Models with Latent Semantic Indexing (LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 30s, sys: 3min 21s, total: 57min 51s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "TOTAL_TOPICS = 10\n",
    "lsi_bow = gensim.models.LsiModel(bow_corpus, id2word=dictionary, num_topics=TOTAL_TOPICS,\n",
    "                                 onepass=True, chunksize=1740, power_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.215*\"unit\" + 0.212*\"state\" + 0.187*\"training\" + 0.177*\"neuron\" + 0.162*\"pattern\" + 0.145*\"image\" + 0.140*\"vector\" + 0.125*\"feature\" + 0.122*\"cell\" + 0.110*\"layer\" + 0.101*\"task\" + 0.097*\"class\" + 0.091*\"probability\" + 0.089*\"signal\" + 0.087*\"step\" + 0.086*\"response\" + 0.085*\"representation\" + 0.083*\"noise\" + 0.082*\"rule\" + 0.081*\"distribution\"\n",
      "\n",
      "Topic #2:\n",
      "-0.487*\"neuron\" + -0.396*\"cell\" + 0.257*\"state\" + -0.191*\"response\" + 0.187*\"training\" + -0.170*\"stimulus\" + -0.117*\"activity\" + 0.109*\"class\" + -0.099*\"spike\" + -0.097*\"pattern\" + -0.096*\"circuit\" + -0.096*\"synaptic\" + 0.095*\"vector\" + -0.090*\"signal\" + -0.090*\"firing\" + -0.088*\"visual\" + 0.084*\"classifier\" + 0.083*\"action\" + 0.078*\"word\" + -0.078*\"cortical\"\n",
      "\n",
      "Topic #3:\n",
      "-0.627*\"state\" + 0.395*\"image\" + -0.219*\"neuron\" + 0.209*\"feature\" + -0.188*\"action\" + 0.137*\"unit\" + 0.131*\"object\" + -0.130*\"control\" + 0.129*\"training\" + -0.109*\"policy\" + 0.103*\"classifier\" + 0.090*\"class\" + -0.081*\"step\" + -0.081*\"dynamic\" + 0.080*\"classification\" + 0.078*\"layer\" + 0.076*\"recognition\" + -0.074*\"reinforcement_learning\" + 0.069*\"representation\" + 0.068*\"pattern\"\n",
      "\n",
      "Topic #4:\n",
      "-0.686*\"unit\" + 0.433*\"image\" + -0.182*\"pattern\" + -0.131*\"layer\" + -0.123*\"hidden_unit\" + -0.121*\"net\" + -0.114*\"training\" + 0.112*\"feature\" + -0.109*\"activation\" + -0.107*\"rule\" + 0.097*\"neuron\" + -0.078*\"word\" + 0.070*\"pixel\" + -0.070*\"connection\" + 0.067*\"object\" + 0.065*\"state\" + 0.060*\"distribution\" + 0.059*\"face\" + -0.057*\"architecture\" + 0.055*\"estimate\"\n",
      "\n",
      "Topic #5:\n",
      "-0.428*\"image\" + -0.348*\"state\" + 0.266*\"neuron\" + -0.264*\"unit\" + 0.181*\"training\" + 0.174*\"class\" + -0.168*\"object\" + 0.167*\"classifier\" + -0.147*\"action\" + -0.122*\"visual\" + 0.117*\"vector\" + 0.115*\"node\" + 0.105*\"distribution\" + -0.103*\"motion\" + -0.099*\"feature\" + 0.097*\"classification\" + -0.097*\"control\" + -0.095*\"task\" + -0.087*\"cell\" + -0.083*\"representation\"\n",
      "\n",
      "Topic #6:\n",
      "0.660*\"cell\" + -0.508*\"neuron\" + -0.213*\"image\" + -0.103*\"chip\" + -0.097*\"unit\" + 0.093*\"response\" + -0.090*\"object\" + 0.083*\"rat\" + 0.076*\"distribution\" + -0.070*\"circuit\" + 0.069*\"probability\" + 0.064*\"stimulus\" + -0.061*\"memory\" + -0.058*\"analog\" + -0.058*\"activation\" + 0.055*\"class\" + -0.053*\"bit\" + -0.052*\"net\" + 0.051*\"cortical\" + 0.050*\"firing\"\n",
      "\n",
      "Topic #7:\n",
      "-0.353*\"word\" + 0.281*\"unit\" + -0.272*\"training\" + -0.257*\"classifier\" + -0.177*\"recognition\" + 0.159*\"distribution\" + -0.152*\"feature\" + -0.144*\"state\" + -0.142*\"pattern\" + 0.141*\"vector\" + -0.128*\"cell\" + -0.128*\"task\" + 0.122*\"approximation\" + 0.121*\"variable\" + 0.110*\"equation\" + -0.107*\"classification\" + 0.106*\"noise\" + -0.103*\"class\" + 0.101*\"matrix\" + -0.098*\"neuron\"\n",
      "\n",
      "Topic #8:\n",
      "-0.303*\"pattern\" + 0.243*\"signal\" + 0.236*\"control\" + 0.202*\"training\" + -0.181*\"rule\" + -0.178*\"state\" + 0.167*\"noise\" + -0.166*\"class\" + 0.162*\"word\" + -0.155*\"cell\" + -0.154*\"feature\" + 0.147*\"motion\" + 0.140*\"task\" + -0.127*\"node\" + -0.124*\"neuron\" + 0.116*\"target\" + 0.114*\"circuit\" + -0.114*\"probability\" + -0.110*\"classifier\" + -0.109*\"image\"\n",
      "\n",
      "Topic #9:\n",
      "-0.472*\"node\" + -0.254*\"circuit\" + 0.214*\"word\" + -0.201*\"chip\" + 0.190*\"neuron\" + 0.172*\"stimulus\" + -0.160*\"classifier\" + -0.152*\"current\" + 0.147*\"feature\" + -0.146*\"voltage\" + 0.145*\"distribution\" + -0.141*\"control\" + -0.124*\"rule\" + -0.110*\"layer\" + -0.105*\"analog\" + -0.091*\"tree\" + 0.084*\"response\" + 0.080*\"state\" + 0.079*\"probability\" + 0.079*\"estimate\"\n",
      "\n",
      "Topic #10:\n",
      "0.518*\"word\" + -0.254*\"training\" + 0.236*\"vector\" + -0.222*\"task\" + -0.194*\"pattern\" + -0.156*\"classifier\" + 0.149*\"node\" + 0.146*\"recognition\" + -0.139*\"control\" + 0.138*\"sequence\" + -0.126*\"rule\" + 0.125*\"circuit\" + 0.123*\"cell\" + -0.113*\"action\" + -0.105*\"neuron\" + 0.094*\"hmm\" + 0.093*\"character\" + 0.088*\"chip\" + 0.088*\"matrix\" + 0.085*\"structure\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lsi_bow.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.215), ('state', 0.212), ('training', 0.187), ('neuron', 0.177), ('pattern', 0.162), ('image', 0.145), ('vector', 0.14), ('feature', 0.125), ('cell', 0.122), ('layer', 0.11), ('task', 0.101), ('class', 0.097), ('probability', 0.091), ('signal', 0.089), ('step', 0.087), ('response', 0.086), ('representation', 0.085), ('noise', 0.083), ('rule', 0.082), ('distribution', 0.081)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('state', 0.257), ('training', 0.187), ('class', 0.109), ('vector', 0.095), ('classifier', 0.084), ('action', 0.083), ('word', 0.078)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.487), ('cell', -0.396), ('response', -0.191), ('stimulus', -0.17), ('activity', -0.117), ('spike', -0.099), ('pattern', -0.097), ('circuit', -0.096), ('synaptic', -0.096), ('signal', -0.09), ('firing', -0.09), ('visual', -0.088), ('cortical', -0.078)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.395), ('feature', 0.209), ('unit', 0.137), ('object', 0.131), ('training', 0.129), ('classifier', 0.103), ('class', 0.09), ('classification', 0.08), ('layer', 0.078), ('recognition', 0.076), ('representation', 0.069), ('pattern', 0.068)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -0.627), ('neuron', -0.219), ('action', -0.188), ('control', -0.13), ('policy', -0.109), ('step', -0.081), ('dynamic', -0.081), ('reinforcement_learning', -0.074)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.433), ('feature', 0.112), ('neuron', 0.097), ('pixel', 0.07), ('object', 0.067), ('state', 0.065), ('distribution', 0.06), ('face', 0.059), ('estimate', 0.055)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -0.686), ('pattern', -0.182), ('layer', -0.131), ('hidden_unit', -0.123), ('net', -0.121), ('training', -0.114), ('activation', -0.109), ('rule', -0.107), ('word', -0.078), ('connection', -0.07), ('architecture', -0.057)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.266), ('training', 0.181), ('class', 0.174), ('classifier', 0.167), ('vector', 0.117), ('node', 0.115), ('distribution', 0.105), ('classification', 0.097)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.428), ('state', -0.348), ('unit', -0.264), ('object', -0.168), ('action', -0.147), ('visual', -0.122), ('motion', -0.103), ('feature', -0.099), ('control', -0.097), ('task', -0.095), ('cell', -0.087), ('representation', -0.083)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('cell', 0.66), ('response', 0.093), ('rat', 0.083), ('distribution', 0.076), ('probability', 0.069), ('stimulus', 0.064), ('class', 0.055), ('cortical', 0.051), ('firing', 0.05)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.508), ('image', -0.213), ('chip', -0.103), ('unit', -0.097), ('object', -0.09), ('circuit', -0.07), ('memory', -0.061), ('analog', -0.058), ('activation', -0.058), ('bit', -0.053), ('net', -0.052)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.281), ('distribution', 0.159), ('vector', 0.141), ('approximation', 0.122), ('variable', 0.121), ('equation', 0.11), ('noise', 0.106), ('matrix', 0.101)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -0.353), ('training', -0.272), ('classifier', -0.257), ('recognition', -0.177), ('feature', -0.152), ('state', -0.144), ('pattern', -0.142), ('cell', -0.128), ('task', -0.128), ('classification', -0.107), ('class', -0.103), ('neuron', -0.098)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('signal', 0.243), ('control', 0.236), ('training', 0.202), ('noise', 0.167), ('word', 0.162), ('motion', 0.147), ('task', 0.14), ('target', 0.116), ('circuit', 0.114)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('pattern', -0.303), ('rule', -0.181), ('state', -0.178), ('class', -0.166), ('cell', -0.155), ('feature', -0.154), ('node', -0.127), ('neuron', -0.124), ('probability', -0.114), ('classifier', -0.11), ('image', -0.109)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.214), ('neuron', 0.19), ('stimulus', 0.172), ('feature', 0.147), ('distribution', 0.145), ('response', 0.084), ('state', 0.08), ('probability', 0.079), ('estimate', 0.079)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('node', -0.472), ('circuit', -0.254), ('chip', -0.201), ('classifier', -0.16), ('current', -0.152), ('voltage', -0.146), ('control', -0.141), ('rule', -0.124), ('layer', -0.11), ('analog', -0.105), ('tree', -0.091)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.518), ('vector', 0.236), ('node', 0.149), ('recognition', 0.146), ('sequence', 0.138), ('circuit', 0.125), ('cell', 0.123), ('hmm', 0.094), ('character', 0.093), ('chip', 0.088), ('matrix', 0.088), ('structure', 0.085)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('training', -0.254), ('task', -0.222), ('pattern', -0.194), ('classifier', -0.156), ('control', -0.139), ('rule', -0.126), ('action', -0.113), ('neuron', -0.105)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    for term, wt in lsi_bow.show_topic(n, topn=20):\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_topic = lsi_bow.projection.u\n",
    "singular_values = lsi_bow.projection.s\n",
    "topic_document = (gensim.matutils.corpus2dense(lsi_bow[bow_corpus], len(singular_values)).T / singular_values).T\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
       "0   0.038  0.002  0.009 -0.077 -0.010 -0.018  0.030 -0.072  0.000  0.005\n",
       "1   0.022  0.000 -0.022  0.008  0.011 -0.016  0.013 -0.017  0.001  0.007\n",
       "2   0.021 -0.028 -0.004  0.003 -0.003  0.000 -0.008  0.009  0.008 -0.014\n",
       "3   0.024 -0.048  0.011  0.003 -0.023  0.044 -0.002 -0.011 -0.003  0.016\n",
       "4   0.032 -0.020 -0.013  0.013 -0.003  0.058 -0.006 -0.050 -0.061  0.036\n",
       "5   0.085 -0.183 -0.003 -0.022 -0.019  0.307 -0.087 -0.137 -0.040  0.020\n",
       "6   0.020 -0.034 -0.019  0.003  0.017 -0.042 -0.012 -0.014 -0.002 -0.012\n",
       "7   0.012  0.006  0.007 -0.018  0.008 -0.001 -0.004  0.005 -0.003 -0.013\n",
       "8   0.033 -0.071 -0.017  0.003  0.018  0.009 -0.020 -0.019  0.011 -0.011\n",
       "9   0.027  0.007  0.027  0.041 -0.016 -0.008  0.036  0.006 -0.005  0.006\n",
       "10  0.046 -0.011 -0.012 -0.033  0.029 -0.031  0.009 -0.060  0.015  0.023\n",
       "11  0.023 -0.003  0.006  0.031 -0.016 -0.004  0.028  0.021 -0.046  0.021\n",
       "12  0.034 -0.034 -0.017 -0.002  0.023 -0.059 -0.002 -0.024 -0.056  0.021\n",
       "13  0.041 -0.030 -0.019 -0.021  0.019 -0.056  0.018  0.009 -0.018 -0.011\n",
       "14  0.015  0.004 -0.000 -0.023 -0.003 -0.003  0.020 -0.013  0.005  0.010"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_topics.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T6', 'T1', 'T2']\n",
      "Paper Summary:\n",
      "9 \n",
      "Stochastic Learning Networks and their Electronic Implementation \n",
      "Joshua Alspector*, Robert B. Allen, Victor Hut, and Srinagesh Satyanarayana \n",
      "Bell Communications Research, Morristown, NJ 07960 \n",
      "ABSTRACT\n",
      "We describe a family of learning algorithms that operate on a recurrent, symmetrically \n",
      "connected, neuromorphic network that, like the Boltzmann machine, settles in the \n",
      "presence of noise. These networks learn by modifying synaptic connection strengths on \n",
      "the basis of correlations seen loca\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T3', 'T5', 'T8']\n",
      "Paper Summary:\n",
      "266 Zemel, Mozer and Hinton \n",
      "TRAFFIC: Recognizing Objects Using \n",
      "Hierarchical Reference Frame Transformations \n",
      "Richard S. Zemel \n",
      "Computer Science Dept. \n",
      "University of Toronto \n",
      "Toronto, ONT M5S 1A4 \n",
      "Michael C. Mozer \n",
      "Computer Science Dept. \n",
      "University of Colorado \n",
      "Boulder, CO 80309-0430 \n",
      "Geoffrey E. Hinton \n",
      "Computer Science Dept. \n",
      "University of Toronto \n",
      "Toronto, ONT M5S 1A4 \n",
      "ABSTRACT \n",
      "We describe a model that can recognize two-dimensional shapes in \n",
      "an unsegmented image, independent of their orie\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T9', 'T8', 'T10']\n",
      "Paper Summary:\n",
      "Constrained Optimization Applied to the \n",
      "Parameter Setting Problem for Analog Circuits \n",
      "David Kirk, Kurt Fleischer, Lloyd Watts Alan Bart \n",
      "Computer Graphics 350-74 \n",
      "California Institute of Technology \n",
      "Pasadena, CA 91125 \n",
      "Abstract \n",
      "We use constrained optimization to select operating parameters for two \n",
      "circuits: a simple 3-transistor square root circuit, and an analog VLSI \n",
      "artificial cochlea. This automated method uses computer controlled mea- \n",
      "surement and test equipment to choose chip paramet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_numbers = [13, 250, 500]\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing LSI Topic Models from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7756, 1740)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 0., 2., 1.],\n",
       "       [1., 0., 1., ..., 1., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_matrix = gensim.matutils.corpus2dense(corpus=bow_corpus, num_terms=len(dictionary))\n",
    "print(td_matrix.shape)\n",
    "td_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['able', 'abstract', 'accommodate', ..., 'support_vector',\n",
       "       'mozer_jordan', 'kearns_solla'], dtype='<U28')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = np.array(list(dictionary.values()))\n",
    "print('Total vocabulary size:', len(vocabulary))\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'able'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "u, s, vt = svds(td_matrix, k=TOTAL_TOPICS, maxiter=10000)\n",
    "term_topic = u\n",
    "singular_values = s\n",
    "topic_document = vt\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7756)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_weights = term_topic.transpose() * singular_values[:, None]\n",
    "tt_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('training', 92.618), ('task', 80.732), ('pattern', 70.619), ('classifier', 56.989), ('control', 50.677), ('rule', 45.926), ('action', 41.202), ('neuron', 38.193)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -188.488), ('vector', -85.973), ('node', -54.376), ('recognition', -53.232), ('sequence', -50.351), ('circuit', -45.394), ('cell', -44.811), ('hmm', -34.086), ('character', -34.022), ('chip', -32.16), ('matrix', -32.093), ('structure', -30.993)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('word', 78.347), ('neuron', 69.793), ('stimulus', 63.234), ('feature', 53.819), ('distribution', 53.119), ('response', 30.954), ('state', 29.343), ('probability', 29.099), ('estimate', 28.908)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('node', -173.277), ('circuit', -93.0), ('chip', -73.593), ('classifier', -58.717), ('current', -55.844), ('voltage', -53.489), ('control', -51.708), ('rule', -45.293), ('layer', -40.265), ('analog', -38.344), ('tree', -33.483)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('pattern', 116.971), ('rule', 69.783), ('state', 68.605), ('class', 64.259), ('cell', 59.979), ('feature', 59.606), ('node', 49.175), ('neuron', 47.998), ('probability', 43.812), ('classifier', 42.612), ('image', 42.061)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('signal', -93.805), ('control', -91.041), ('training', -77.88), ('noise', -64.397), ('word', -62.392), ('motion', -56.699), ('task', -53.883), ('target', -44.765), ('circuit', -44.129)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('unit', 117.727), ('distribution', 66.719), ('vector', 58.881), ('approximation', 50.931), ('variable', 50.83), ('equation', 46.229), ('noise', 44.247), ('matrix', 42.214)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -147.792), ('training', -113.693), ('classifier', -107.386), ('recognition', -73.948), ('feature', -63.454), ('state', -60.126), ('pattern', -59.562), ('cell', -53.768), ('task', -53.693), ('classification', -44.936), ('class', -43.161), ('neuron', -41.092)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 220.116), ('image', 92.39), ('chip', 44.422), ('unit', 41.922), ('object', 39.001), ('circuit', 30.444), ('memory', 26.475), ('analog', 25.207), ('activation', 24.953), ('bit', 22.997), ('net', 22.699)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('cell', -285.803), ('response', -40.216), ('rat', -35.975), ('distribution', -33.085), ('probability', -29.79), ('stimulus', -27.789), ('class', -24.02), ('cortical', -22.185), ('firing', -21.66)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('image', 209.793), ('state', 170.207), ('unit', 129.108), ('object', 82.185), ('action', 72.136), ('visual', 59.502), ('motion', 50.605), ('feature', 48.665), ('control', 47.427), ('task', 46.496), ('cell', 42.366), ('representation', 40.564)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -130.053), ('training', -88.668), ('class', -85.213), ('classifier', -81.921), ('vector', -57.532), ('node', -56.341), ('distribution', -51.622), ('classification', -47.645)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('image', 215.858), ('feature', 55.647), ('neuron', 48.494), ('pixel', 35.095), ('object', 33.585), ('state', 32.544), ('distribution', 29.977), ('face', 29.256), ('estimate', 27.555)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -341.829), ('pattern', -90.771), ('layer', -65.337), ('hidden_unit', -61.12), ('net', -60.035), ('training', -56.742), ('activation', -54.268), ('rule', -53.377), ('word', -38.903), ('connection', -34.618), ('architecture', -28.439)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('image', 229.287), ('feature', 121.397), ('unit', 79.44), ('object', 76.204), ('training', 75.152), ('classifier', 59.872), ('class', 52.527), ('classification', 46.696), ('layer', 45.149), ('recognition', 44.192), ('representation', 40.179), ('pattern', 39.252)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -364.388), ('neuron', -127.022), ('action', -109.245), ('control', -75.369), ('policy', -63.103), ('step', -47.226), ('dynamic', -46.907), ('reinforcement_learning', -42.747)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 306.151), ('cell', 249.243), ('response', 119.758), ('stimulus', 106.762), ('activity', 73.499), ('spike', 62.039), ('pattern', 60.957), ('circuit', 60.602), ('synaptic', 60.282), ('signal', 56.665), ('firing', 56.597), ('visual', 55.571), ('cortical', 48.867)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -161.465), ('training', -117.32), ('class', -68.732), ('vector', -59.558), ('classifier', -52.589), ('action', -52.113), ('word', -49.239)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: []\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -260.793), ('state', -258.146), ('training', -227.312), ('neuron', -215.681), ('pattern', -197.232), ('image', -175.735), ('vector', -170.154), ('feature', -151.547), ('cell', -148.138), ('layer', -133.593), ('task', -122.389), ('class', -117.849), ('probability', -110.526), ('signal', -108.232), ('step', -105.202), ('response', -104.465), ('representation', -103.255), ('noise', -100.573), ('rule', -99.611), ('distribution', -98.973)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_terms = 20\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(tt_weights), axis=1)[:, :top_terms]\n",
    "topic_keyterm_weights = np.array([tt_weights[row, columns] \n",
    "                             for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    terms, weights = topic_keyterms_weights[n]\n",
    "    term_weights = sorted([(t, w) for t, w in zip(terms, weights)], \n",
    "                          key=lambda row: -abs(row[1]))\n",
    "    for term, wt in term_weights:\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.071</td>\n",
       "      <td>-0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
       "0  -0.005  0.000  0.072  0.030  0.018  0.010 -0.077  0.009 -0.002 -0.038\n",
       "1  -0.007  0.001  0.017  0.013  0.016 -0.011  0.008 -0.022 -0.000 -0.022\n",
       "2   0.014  0.008 -0.009 -0.008 -0.000  0.003  0.003 -0.004  0.028 -0.021\n",
       "3  -0.016 -0.003  0.011 -0.002 -0.044  0.023  0.003  0.011  0.048 -0.024\n",
       "4  -0.036 -0.061  0.050 -0.006 -0.058  0.003  0.013 -0.013  0.020 -0.032\n",
       "5  -0.020 -0.040  0.137 -0.087 -0.307  0.019 -0.022 -0.003  0.183 -0.085\n",
       "6   0.012 -0.002  0.014 -0.012  0.042 -0.017  0.003 -0.019  0.034 -0.020\n",
       "7   0.013 -0.003 -0.005 -0.004  0.001 -0.008 -0.018  0.007 -0.006 -0.012\n",
       "8   0.011  0.011  0.019 -0.020 -0.009 -0.018  0.003 -0.017  0.071 -0.033\n",
       "9  -0.006 -0.005 -0.006  0.036  0.008  0.016  0.041  0.027 -0.007 -0.027\n",
       "10 -0.023  0.015  0.060  0.009  0.031 -0.029 -0.033 -0.012  0.011 -0.046\n",
       "11 -0.021 -0.046 -0.021  0.028  0.004  0.016  0.031  0.006  0.003 -0.023\n",
       "12 -0.021 -0.056  0.024 -0.002  0.059 -0.023 -0.002 -0.017  0.034 -0.034\n",
       "13  0.011 -0.018 -0.009  0.018  0.056 -0.019 -0.021 -0.019  0.030 -0.041\n",
       "14 -0.010  0.005  0.013  0.020  0.003  0.003 -0.023 -0.000 -0.004 -0.015"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_topics.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T5', 'T10', 'T9']\n",
      "Paper Summary:\n",
      "9 \n",
      "Stochastic Learning Networks and their Electronic Implementation \n",
      "Joshua Alspector*, Robert B. Allen, Victor Hut, and Srinagesh Satyanarayana \n",
      "Bell Communications Research, Morristown, NJ 07960 \n",
      "ABSTRACT\n",
      "We describe a family of learning algorithms that operate on a recurrent, symmetrically \n",
      "connected, neuromorphic network that, like the Boltzmann machine, settles in the \n",
      "presence of noise. These networks learn by modifying synaptic connection strengths on \n",
      "the basis of correlations seen loca\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T6', 'T8', 'T3']\n",
      "Paper Summary:\n",
      "266 Zemel, Mozer and Hinton \n",
      "TRAFFIC: Recognizing Objects Using \n",
      "Hierarchical Reference Frame Transformations \n",
      "Richard S. Zemel \n",
      "Computer Science Dept. \n",
      "University of Toronto \n",
      "Toronto, ONT M5S 1A4 \n",
      "Michael C. Mozer \n",
      "Computer Science Dept. \n",
      "University of Colorado \n",
      "Boulder, CO 80309-0430 \n",
      "Geoffrey E. Hinton \n",
      "Computer Science Dept. \n",
      "University of Toronto \n",
      "Toronto, ONT M5S 1A4 \n",
      "ABSTRACT \n",
      "We describe a model that can recognize two-dimensional shapes in \n",
      "an unsegmented image, independent of their orie\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T2', 'T3', 'T1']\n",
      "Paper Summary:\n",
      "Constrained Optimization Applied to the \n",
      "Parameter Setting Problem for Analog Circuits \n",
      "David Kirk, Kurt Fleischer, Lloyd Watts Alan Bart \n",
      "Computer Graphics 350-74 \n",
      "California Institute of Technology \n",
      "Pasadena, CA 91125 \n",
      "Abstract \n",
      "We use constrained optimization to select operating parameters for two \n",
      "circuits: a simple 3-transistor square root circuit, and an analog VLSI \n",
      "artificial cochlea. This automated method uses computer controlled mea- \n",
      "surement and test equipment to choose chip paramet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_numbers = [13, 250, 500]\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Models with Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 32s, sys: 10.7 s, total: 5min 43s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740, \n",
    "                                   alpha='auto', eta='auto', random_state=42,\n",
    "                                   iterations=500, num_topics=TOTAL_TOPICS, \n",
    "                                   passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.016*\"training\" + 0.012*\"classifier\" + 0.007*\"pattern\" + 0.007*\"classification\" + 0.006*\"class\" + 0.006*\"task\" + 0.006*\"vector\" + 0.005*\"training_set\" + 0.005*\"feature\" + 0.004*\"control\" + 0.004*\"size\" + 0.003*\"trained\" + 0.003*\"teacher\" + 0.003*\"rate\" + 0.003*\"student\" + 0.003*\"average\" + 0.003*\"robot\" + 0.003*\"random\" + 0.003*\"rule\" + 0.003*\"search\"\n",
      "\n",
      "Topic #2:\n",
      "0.008*\"vector\" + 0.006*\"equation\" + 0.006*\"matrix\" + 0.006*\"neuron\" + 0.005*\"state\" + 0.005*\"dynamic\" + 0.005*\"solution\" + 0.005*\"unit\" + 0.004*\"node\" + 0.004*\"pattern\" + 0.004*\"linear\" + 0.004*\"let\" + 0.003*\"layer\" + 0.003*\"convergence\" + 0.003*\"rule\" + 0.003*\"size\" + 0.003*\"theorem\" + 0.003*\"threshold\" + 0.003*\"memory\" + 0.003*\"theory\"\n",
      "\n",
      "Topic #3:\n",
      "0.017*\"training\" + 0.011*\"word\" + 0.008*\"recognition\" + 0.007*\"trained\" + 0.006*\"net\" + 0.006*\"unit\" + 0.006*\"feature\" + 0.006*\"speech\" + 0.006*\"task\" + 0.005*\"architecture\" + 0.005*\"class\" + 0.005*\"character\" + 0.004*\"layer\" + 0.004*\"classification\" + 0.004*\"context\" + 0.004*\"test\" + 0.004*\"sequence\" + 0.004*\"hidden_unit\" + 0.004*\"experiment\" + 0.004*\"vector\"\n",
      "\n",
      "Topic #4:\n",
      "0.017*\"motion\" + 0.009*\"rule\" + 0.008*\"direction\" + 0.007*\"stimulus\" + 0.006*\"velocity\" + 0.006*\"task\" + 0.006*\"human\" + 0.006*\"unit\" + 0.005*\"location\" + 0.005*\"target\" + 0.005*\"subject\" + 0.005*\"memory\" + 0.005*\"prediction\" + 0.005*\"position\" + 0.004*\"concept\" + 0.004*\"field\" + 0.004*\"response\" + 0.004*\"cue\" + 0.004*\"layer\" + 0.004*\"hand\"\n",
      "\n",
      "Topic #5:\n",
      "0.008*\"distribution\" + 0.005*\"estimate\" + 0.005*\"sample\" + 0.005*\"training\" + 0.005*\"class\" + 0.005*\"probability\" + 0.005*\"approximation\" + 0.004*\"variable\" + 0.004*\"gaussian\" + 0.004*\"linear\" + 0.004*\"vector\" + 0.004*\"prior\" + 0.004*\"noise\" + 0.004*\"density\" + 0.004*\"prediction\" + 0.003*\"kernel\" + 0.003*\"variance\" + 0.003*\"mixture\" + 0.003*\"bound\" + 0.003*\"regression\"\n",
      "\n",
      "Topic #6:\n",
      "0.037*\"state\" + 0.011*\"action\" + 0.008*\"step\" + 0.008*\"control\" + 0.007*\"policy\" + 0.006*\"sequence\" + 0.006*\"reinforcement_learning\" + 0.005*\"probability\" + 0.005*\"optimal\" + 0.004*\"task\" + 0.004*\"transition\" + 0.004*\"environment\" + 0.003*\"variable\" + 0.003*\"reward\" + 0.003*\"stochastic\" + 0.003*\"goal\" + 0.003*\"machine\" + 0.003*\"current\" + 0.003*\"controller\" + 0.003*\"agent\"\n",
      "\n",
      "Topic #7:\n",
      "0.012*\"circuit\" + 0.011*\"signal\" + 0.011*\"chip\" + 0.009*\"neuron\" + 0.008*\"current\" + 0.007*\"voltage\" + 0.006*\"analog\" + 0.006*\"control\" + 0.005*\"channel\" + 0.004*\"noise\" + 0.004*\"neural\" + 0.004*\"bit\" + 0.004*\"implementation\" + 0.004*\"source\" + 0.003*\"design\" + 0.003*\"gain\" + 0.003*\"processor\" + 0.003*\"synapse\" + 0.003*\"device\" + 0.003*\"array\"\n",
      "\n",
      "Topic #8:\n",
      "0.021*\"neuron\" + 0.019*\"cell\" + 0.009*\"response\" + 0.007*\"activity\" + 0.007*\"stimulus\" + 0.007*\"pattern\" + 0.006*\"spike\" + 0.005*\"synaptic\" + 0.004*\"cortical\" + 0.004*\"neural\" + 0.004*\"signal\" + 0.004*\"firing\" + 0.004*\"connection\" + 0.004*\"effect\" + 0.004*\"layer\" + 0.004*\"et_al\" + 0.004*\"cortex\" + 0.003*\"visual\" + 0.003*\"simulation\" + 0.003*\"synapsis\"\n",
      "\n",
      "Topic #9:\n",
      "0.032*\"image\" + 0.012*\"object\" + 0.012*\"feature\" + 0.006*\"pixel\" + 0.006*\"visual\" + 0.005*\"representation\" + 0.005*\"face\" + 0.005*\"vector\" + 0.004*\"view\" + 0.004*\"recognition\" + 0.004*\"transformation\" + 0.004*\"local\" + 0.003*\"map\" + 0.003*\"structure\" + 0.003*\"region\" + 0.003*\"filter\" + 0.003*\"position\" + 0.003*\"distance\" + 0.003*\"part\" + 0.003*\"location\"\n",
      "\n",
      "Topic #10:\n",
      "0.030*\"unit\" + 0.009*\"pattern\" + 0.007*\"representation\" + 0.007*\"activation\" + 0.006*\"hidden_unit\" + 0.006*\"node\" + 0.006*\"structure\" + 0.006*\"layer\" + 0.005*\"activity\" + 0.004*\"connection\" + 0.004*\"task\" + 0.004*\"component\" + 0.004*\"map\" + 0.004*\"rule\" + 0.004*\"architecture\" + 0.004*\"signal\" + 0.004*\"level\" + 0.003*\"response\" + 0.003*\"connectionist\" + 0.003*\"training\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score: -1.0433305600965899\n"
     ]
    }
   ],
   "source": [
    "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
    "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
    "print('Avg. Coherence Score:', avg_coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "[('training', 0.017), ('word', 0.011), ('recognition', 0.008), ('trained', 0.007), ('net', 0.006), ('unit', 0.006), ('feature', 0.006), ('speech', 0.006), ('task', 0.006), ('architecture', 0.005), ('class', 0.005), ('character', 0.005), ('layer', 0.004), ('classification', 0.004), ('context', 0.004), ('test', 0.004), ('sequence', 0.004), ('hidden_unit', 0.004), ('experiment', 0.004), ('vector', 0.004)]\n",
      "\n",
      "Topic #2:\n",
      "[('unit', 0.03), ('pattern', 0.009), ('representation', 0.007), ('activation', 0.007), ('hidden_unit', 0.006), ('node', 0.006), ('structure', 0.006), ('layer', 0.006), ('activity', 0.005), ('connection', 0.004), ('task', 0.004), ('component', 0.004), ('map', 0.004), ('rule', 0.004), ('architecture', 0.004), ('signal', 0.004), ('level', 0.004), ('response', 0.003), ('connectionist', 0.003), ('training', 0.003)]\n",
      "\n",
      "Topic #3:\n",
      "[('neuron', 0.021), ('cell', 0.019), ('response', 0.009), ('activity', 0.007), ('stimulus', 0.007), ('pattern', 0.007), ('spike', 0.006), ('synaptic', 0.005), ('cortical', 0.004), ('neural', 0.004), ('signal', 0.004), ('firing', 0.004), ('connection', 0.004), ('effect', 0.004), ('layer', 0.004), ('et_al', 0.004), ('cortex', 0.004), ('visual', 0.003), ('simulation', 0.003), ('synapsis', 0.003)]\n",
      "\n",
      "Topic #4:\n",
      "[('image', 0.032), ('object', 0.012), ('feature', 0.012), ('pixel', 0.006), ('visual', 0.006), ('representation', 0.005), ('face', 0.005), ('vector', 0.005), ('view', 0.004), ('recognition', 0.004), ('transformation', 0.004), ('local', 0.004), ('map', 0.003), ('structure', 0.003), ('region', 0.003), ('filter', 0.003), ('position', 0.003), ('distance', 0.003), ('part', 0.003), ('location', 0.003)]\n",
      "\n",
      "Topic #5:\n",
      "[('vector', 0.008), ('equation', 0.006), ('matrix', 0.006), ('neuron', 0.006), ('state', 0.005), ('dynamic', 0.005), ('solution', 0.005), ('unit', 0.005), ('node', 0.004), ('pattern', 0.004), ('linear', 0.004), ('let', 0.004), ('layer', 0.003), ('convergence', 0.003), ('rule', 0.003), ('size', 0.003), ('theorem', 0.003), ('threshold', 0.003), ('memory', 0.003), ('theory', 0.003)]\n",
      "\n",
      "Topic #6:\n",
      "[('distribution', 0.008), ('estimate', 0.005), ('sample', 0.005), ('training', 0.005), ('class', 0.005), ('probability', 0.005), ('approximation', 0.005), ('variable', 0.004), ('gaussian', 0.004), ('linear', 0.004), ('vector', 0.004), ('prior', 0.004), ('noise', 0.004), ('density', 0.004), ('prediction', 0.004), ('kernel', 0.003), ('variance', 0.003), ('mixture', 0.003), ('bound', 0.003), ('regression', 0.003)]\n",
      "\n",
      "Topic #7:\n",
      "[('training', 0.016), ('classifier', 0.012), ('pattern', 0.007), ('classification', 0.007), ('class', 0.006), ('task', 0.006), ('vector', 0.006), ('training_set', 0.005), ('feature', 0.005), ('control', 0.004), ('size', 0.004), ('trained', 0.003), ('teacher', 0.003), ('rate', 0.003), ('student', 0.003), ('average', 0.003), ('robot', 0.003), ('random', 0.003), ('rule', 0.003), ('search', 0.003)]\n",
      "\n",
      "Topic #8:\n",
      "[('state', 0.037), ('action', 0.011), ('step', 0.008), ('control', 0.008), ('policy', 0.007), ('sequence', 0.006), ('reinforcement_learning', 0.006), ('probability', 0.005), ('optimal', 0.005), ('task', 0.004), ('transition', 0.004), ('environment', 0.004), ('variable', 0.003), ('reward', 0.003), ('stochastic', 0.003), ('goal', 0.003), ('machine', 0.003), ('current', 0.003), ('controller', 0.003), ('agent', 0.003)]\n",
      "\n",
      "Topic #9:\n",
      "[('motion', 0.017), ('rule', 0.009), ('direction', 0.008), ('stimulus', 0.007), ('velocity', 0.006), ('task', 0.006), ('human', 0.006), ('unit', 0.006), ('location', 0.005), ('target', 0.005), ('subject', 0.005), ('memory', 0.005), ('prediction', 0.005), ('position', 0.005), ('concept', 0.004), ('field', 0.004), ('response', 0.004), ('cue', 0.004), ('layer', 0.004), ('hand', 0.004)]\n",
      "\n",
      "Topic #10:\n",
      "[('circuit', 0.012), ('signal', 0.011), ('chip', 0.011), ('neuron', 0.009), ('current', 0.008), ('voltage', 0.007), ('analog', 0.006), ('control', 0.006), ('channel', 0.005), ('noise', 0.004), ('neural', 0.004), ('bit', 0.004), ('implementation', 0.004), ('source', 0.004), ('design', 0.003), ('gain', 0.003), ('processor', 0.003), ('synapse', 0.003), ('device', 0.003), ('array', 0.003)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt, 3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics without Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "['training', 'word', 'recognition', 'trained', 'net', 'unit', 'feature', 'speech', 'task', 'architecture', 'class', 'character', 'layer', 'classification', 'context', 'test', 'sequence', 'hidden_unit', 'experiment', 'vector']\n",
      "\n",
      "Topic #2:\n",
      "['unit', 'pattern', 'representation', 'activation', 'hidden_unit', 'node', 'structure', 'layer', 'activity', 'connection', 'task', 'component', 'map', 'rule', 'architecture', 'signal', 'level', 'response', 'connectionist', 'training']\n",
      "\n",
      "Topic #3:\n",
      "['neuron', 'cell', 'response', 'activity', 'stimulus', 'pattern', 'spike', 'synaptic', 'cortical', 'neural', 'signal', 'firing', 'connection', 'effect', 'layer', 'et_al', 'cortex', 'visual', 'simulation', 'synapsis']\n",
      "\n",
      "Topic #4:\n",
      "['image', 'object', 'feature', 'pixel', 'visual', 'representation', 'face', 'vector', 'view', 'recognition', 'transformation', 'local', 'map', 'structure', 'region', 'filter', 'position', 'distance', 'part', 'location']\n",
      "\n",
      "Topic #5:\n",
      "['vector', 'equation', 'matrix', 'neuron', 'state', 'dynamic', 'solution', 'unit', 'node', 'pattern', 'linear', 'let', 'layer', 'convergence', 'rule', 'size', 'theorem', 'threshold', 'memory', 'theory']\n",
      "\n",
      "Topic #6:\n",
      "['distribution', 'estimate', 'sample', 'training', 'class', 'probability', 'approximation', 'variable', 'gaussian', 'linear', 'vector', 'prior', 'noise', 'density', 'prediction', 'kernel', 'variance', 'mixture', 'bound', 'regression']\n",
      "\n",
      "Topic #7:\n",
      "['training', 'classifier', 'pattern', 'classification', 'class', 'task', 'vector', 'training_set', 'feature', 'control', 'size', 'trained', 'teacher', 'rate', 'student', 'average', 'robot', 'random', 'rule', 'search']\n",
      "\n",
      "Topic #8:\n",
      "['state', 'action', 'step', 'control', 'policy', 'sequence', 'reinforcement_learning', 'probability', 'optimal', 'task', 'transition', 'environment', 'variable', 'reward', 'stochastic', 'goal', 'machine', 'current', 'controller', 'agent']\n",
      "\n",
      "Topic #9:\n",
      "['motion', 'rule', 'direction', 'stimulus', 'velocity', 'task', 'human', 'unit', 'location', 'target', 'subject', 'memory', 'prediction', 'position', 'concept', 'field', 'response', 'cue', 'layer', 'hand']\n",
      "\n",
      "Topic #10:\n",
      "['circuit', 'signal', 'chip', 'neuron', 'current', 'voltage', 'analog', 'control', 'channel', 'noise', 'neural', 'bit', 'implementation', 'source', 'design', 'gain', 'processor', 'synapse', 'device', 'array']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.47028476052247825\n",
      "Avg. Coherence Score (UMass): -1.0433305600965896\n",
      "Model Perplexity: -7.792233498252204\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                      texts=norm_corpus_bigrams,\n",
    "                                                      dictionary=dictionary, \n",
    "                                                      coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                         texts=norm_corpus_bigrams,\n",
    "                                                         dictionary=dictionary, \n",
    "                                                         coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
    "\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)\n",
    "\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Models with MALLET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-08 20:06:13--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
      "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
      "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16184794 (15M) [application/zip]\n",
      "Saving to: ‘mallet-2.0.8.zip’\n",
      "\n",
      "mallet-2.0.8.zip    100%[===================>]  15.43M  1.35MB/s    in 12s     \n",
      "\n",
      "2018-11-08 20:06:25 (1.28 MB/s) - ‘mallet-2.0.8.zip’ saved [16184794/16184794]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MALLET_PATH = 'mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus, \n",
    "                                              num_topics=TOTAL_TOPICS, id2word=dictionary,\n",
    "                                              iterations=500, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['neuron', 'cell', 'response', 'stimulus', 'activity', 'pattern', 'signal', 'spike', 'effect', 'synaptic', 'frequency', 'neural', 'unit', 'connection', 'layer', 'cortical', 'firing', 'et_al', 'brain', 'temporal']\n",
      "\n",
      "Topic #2:\n",
      "['prediction', 'control', 'trajectory', 'target', 'task', 'expert', 'training', 'nonlinear', 'dynamic', 'linear', 'local', 'change', 'adaptive', 'mapping', 'hand', 'movement', 'controller', 'position', 'motor', 'architecture']\n",
      "\n",
      "Topic #3:\n",
      "['vector', 'equation', 'linear', 'bound', 'solution', 'theory', 'matrix', 'convergence', 'theorem', 'defined', 'size', 'constant', 'optimal', 'class', 'eq', 'property', 'approximation', 'condition', 'rate', 'probability']\n",
      "\n",
      "Topic #4:\n",
      "['state', 'action', 'step', 'policy', 'environment', 'recurrent', 'transition', 'optimal', 'task', 'reinforcement_learning', 'control', 'path', 'goal', 'stochastic', 'sequence', 'current', 'cost', 'iteration', 'machine', 'update']\n",
      "\n",
      "Topic #5:\n",
      "['image', 'object', 'feature', 'motion', 'visual', 'map', 'direction', 'location', 'pixel', 'field', 'region', 'position', 'filter', 'local', 'view', 'representation', 'face', 'distance', 'surface', 'edge']\n",
      "\n",
      "Topic #6:\n",
      "['distribution', 'estimate', 'gaussian', 'variable', 'probability', 'prior', 'sample', 'approximation', 'variance', 'mixture', 'density', 'noise', 'kernel', 'component', 'estimation', 'bayesian', 'vector', 'matrix', 'log', 'linear']\n",
      "\n",
      "Topic #7:\n",
      "['rule', 'node', 'unit', 'structure', 'representation', 'tree', 'level', 'pattern', 'graph', 'cluster', 'activation', 'sequence', 'connectionist', 'symbol', 'similarity', 'instance', 'represented', 'string', 'memory', 'clustering']\n",
      "\n",
      "Topic #8:\n",
      "['neuron', 'circuit', 'chip', 'current', 'memory', 'signal', 'analog', 'bit', 'voltage', 'neural', 'code', 'implementation', 'noise', 'connection', 'parallel', 'attractor', 'design', 'element', 'operation', 'processor']\n",
      "\n",
      "Topic #9:\n",
      "['training', 'unit', 'pattern', 'hidden_unit', 'layer', 'net', 'classifier', 'class', 'training_set', 'classification', 'trained', 'test', 'task', 'back_propagation', 'hidden_layer', 'table', 'generalization', 'feature', 'size', 'architecture']\n",
      "\n",
      "Topic #10:\n",
      "['word', 'recognition', 'speech', 'sequence', 'feature', 'context', 'training', 'character', 'hmm', 'module', 'signal', 'letter', 'frame', 'trained', 'experiment', 'classification', 'architecture', 'speaker', 'window', 'class']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = [[(term, round(wt, 3)) \n",
    "               for term, wt in lda_mallet.show_topic(n, topn=20)] \n",
    "                   for n in range(0, TOTAL_TOPICS)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.5008326905758488\n",
      "Avg. Coherence Score (UMass): -1.0635635291342118\n",
      "Model Perplexity: -8.53533\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                             texts=norm_corpus_bigrams,\n",
    "                                                             dictionary=dictionary, \n",
    "                                                             coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                                texts=norm_corpus_bigrams,\n",
    "                                                                dictionary=dictionary,  \n",
    "                                                                coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "# from STDOUT: <500> LL/token: -8.53533\n",
    "perplexity = -8.53533\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Tuning - Finding Optimal Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def topic_model_coherence_generator(corpus, texts, dictionary, \n",
    "                                    start_topic_count=2, end_topic_count=10, step=1,\n",
    "                                    cpus=1):\n",
    "    \n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus,\n",
    "                                                            num_topics=topic_nums, id2word=dictionary,\n",
    "                                                            iterations=500, workers=cpus)\n",
    "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, corpus=corpus, \n",
    "                                                                     texts=texts, dictionary=dictionary, \n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(mallet_lda_model)\n",
    "    \n",
    "    return models, coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [37:48<00:00, 92.53s/it]\n"
     ]
    }
   ],
   "source": [
    "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
    "                                                               dictionary=dictionary, start_topic_count=2,\n",
    "                                                               end_topic_count=30, step=1, cpus=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.5461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>0.5427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.5412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.5369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.5369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>0.5363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Topics  Coherence Score\n",
       "24                26           0.5461\n",
       "23                25           0.5427\n",
       "17                19           0.5419\n",
       "16                18           0.5412\n",
       "22                24           0.5405\n",
       "18                20           0.5401\n",
       "21                23           0.5375\n",
       "20                22           0.5369\n",
       "19                21           0.5369\n",
       "27                29           0.5363"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1),\n",
    "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
    "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "x_ax = range(2, 31, 1)\n",
    "y_ax = coherence_scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_ax, y_ax, c='r')\n",
    "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "xl = plt.xlabel('Number of Topics')\n",
    "yl = plt.ylabel('Coherence Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 20].index[0]\n",
    "best_lda_model = lda_models[best_model_idx]\n",
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['class', 'classification', 'classifier', 'training', 'pattern', 'feature', 'kernel', 'machine', 'training_set', 'test', 'sample', 'vector', 'database', 'error_rate', 'margin', 'experiment', 'support_vector', 'nearest_neighbor', 'decision', 'size']\n",
      "\n",
      "Topic #2:\n",
      "['neuron', 'memory', 'pattern', 'dynamic', 'connection', 'phase', 'attractor', 'capacity', 'state', 'hopfield', 'neural', 'fixed_point', 'oscillator', 'delay', 'stable', 'fig', 'oscillation', 'associative_memory', 'behavior', 'stored']\n",
      "\n",
      "Topic #3:\n",
      "['word', 'recognition', 'training', 'speech', 'character', 'context', 'hmm', 'letter', 'mlp', 'speaker', 'feature', 'frame', 'trained', 'speech_recognition', 'phoneme', 'experiment', 'hybrid', 'segmentation', 'vowel', 'level']\n",
      "\n",
      "Topic #4:\n",
      "['noise', 'rate', 'equation', 'curve', 'average', 'correlation', 'rule', 'distribution', 'theory', 'limit', 'solution', 'optimal', 'eq', 'teacher', 'effect', 'size', 'temperature', 'student', 'line', 'random']\n",
      "\n",
      "Topic #5:\n",
      "['bound', 'theorem', 'class', 'probability', 'size', 'threshold', 'proof', 'polynomial', 'theory', 'complexity', 'loss', 'approximation', 'linear', 'assume', 'definition', 'defined', 'hypothesis', 'constant', 'define', 'bounded']\n",
      "\n",
      "Topic #6:\n",
      "['vector', 'matrix', 'linear', 'equation', 'solution', 'gradient', 'constraint', 'convergence', 'optimization', 'nonlinear', 'optimal', 'eq', 'minimum', 'operator', 'gradient_descent', 'condition', 'constant', 'derivative', 'quadratic', 'energy']\n",
      "\n",
      "Topic #7:\n",
      "['search', 'task', 'experiment', 'table', 'instance', 'test', 'domain', 'target', 'query', 'feature', 'user', 'random', 'technique', 'run', 'accuracy', 'block', 'application', 'evaluation', 'strategy', 'important']\n",
      "\n",
      "Topic #8:\n",
      "['distribution', 'probability', 'prior', 'gaussian', 'variable', 'mixture', 'density', 'bayesian', 'estimate', 'approximation', 'log', 'likelihood', 'sample', 'component', 'expert', 'em', 'posterior', 'probabilistic', 'estimation', 'entropy']\n",
      "\n",
      "Topic #9:\n",
      "['visual', 'motion', 'cell', 'response', 'stimulus', 'direction', 'receptive_field', 'map', 'spatial', 'orientation', 'unit', 'eye', 'field', 'activity', 'location', 'velocity', 'center', 'contrast', 'cortical', 'pattern']\n",
      "\n",
      "Topic #10:\n",
      "['neuron', 'cell', 'spike', 'synaptic', 'activity', 'response', 'stimulus', 'firing', 'synapsis', 'et_al', 'effect', 'neural', 'neuronal', 'current', 'pattern', 'inhibitory', 'connection', 'brain', 'simulation', 'firing_rate']\n",
      "\n",
      "Topic #11:\n",
      "['state', 'sequence', 'step', 'recurrent', 'transition', 'stochastic', 'iteration', 'update', 'dynamic', 'probability', 'convergence', 'trajectory', 'xt', 'length', 'observation', 'continuous', 'rate', 'machine', 'current', 'string']\n",
      "\n",
      "Topic #12:\n",
      "['node', 'tree', 'structure', 'graph', 'code', 'level', 'bit', 'path', 'local', 'size', 'variable', 'stage', 'length', 'solution', 'edge', 'link', 'component', 'match', 'binary', 'coding']\n",
      "\n",
      "Topic #13:\n",
      "['image', 'object', 'feature', 'pixel', 'face', 'view', 'recognition', 'representation', 'shape', 'scale', 'part', 'visual', 'region', 'position', 'scene', 'surface', 'vision', 'frame', 'texture', 'location']\n",
      "\n",
      "Topic #14:\n",
      "['control', 'action', 'state', 'policy', 'environment', 'controller', 'reinforcement_learning', 'task', 'optimal', 'robot', 'goal', 'step', 'reward', 'td', 'agent', 'adaptive', 'cost', 'reinforcement', 'trial', 'exploration']\n",
      "\n",
      "Topic #15:\n",
      "['unit', 'layer', 'training', 'hidden_unit', 'net', 'architecture', 'pattern', 'activation', 'trained', 'task', 'back_propagation', 'hidden_layer', 'connection', 'hidden', 'backpropagation', 'learn', 'training_set', 'epoch', 'simulation', 'generalization']\n",
      "\n",
      "Topic #16:\n",
      "['circuit', 'chip', 'current', 'analog', 'voltage', 'implementation', 'processor', 'bit', 'design', 'device', 'computation', 'parallel', 'digital', 'operation', 'array', 'neural', 'synapse', 'element', 'hardware', 'transistor']\n",
      "\n",
      "Topic #17:\n",
      "['rule', 'representation', 'module', 'structure', 'human', 'movement', 'motor', 'target', 'language', 'subject', 'connectionist', 'position', 'task', 'context', 'trajectory', 'hand', 'role', 'symbol', 'learned', 'theory']\n",
      "\n",
      "Topic #18:\n",
      "['vector', 'map', 'distance', 'cluster', 'local', 'dimension', 'clustering', 'mapping', 'dimensional', 'region', 'structure', 'center', 'rbf', 'pca', 'basis_function', 'linear', 'representation', 'global', 'principal_component', 'projection']\n",
      "\n",
      "Topic #19:\n",
      "['signal', 'filter', 'frequency', 'source', 'channel', 'noise', 'component', 'response', 'temporal', 'sound', 'auditory', 'detection', 'phase', 'ica', 'adaptation', 'amplitude', 'subject', 'eeg', 'change', 'correlation']\n",
      "\n",
      "Topic #20:\n",
      "['prediction', 'training', 'estimate', 'regression', 'test', 'noise', 'selection', 'variance', 'training_set', 'sample', 'ensemble', 'estimation', 'average', 'nonlinear', 'linear', 'estimator', 'cross_validation', 'pruning', 'bias', 'risk']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = [[(term, round(wt, 3)) \n",
    "               for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
    "                   for n in range(0, best_lda_model.num_topics)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "      <th>Topic 16</th>\n",
       "      <th>Topic 17</th>\n",
       "      <th>Topic 18</th>\n",
       "      <th>Topic 19</th>\n",
       "      <th>Topic 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Term1</th>\n",
       "      <td>class</td>\n",
       "      <td>neuron</td>\n",
       "      <td>word</td>\n",
       "      <td>noise</td>\n",
       "      <td>bound</td>\n",
       "      <td>vector</td>\n",
       "      <td>search</td>\n",
       "      <td>distribution</td>\n",
       "      <td>visual</td>\n",
       "      <td>neuron</td>\n",
       "      <td>state</td>\n",
       "      <td>node</td>\n",
       "      <td>image</td>\n",
       "      <td>control</td>\n",
       "      <td>unit</td>\n",
       "      <td>circuit</td>\n",
       "      <td>rule</td>\n",
       "      <td>vector</td>\n",
       "      <td>signal</td>\n",
       "      <td>prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term2</th>\n",
       "      <td>classification</td>\n",
       "      <td>memory</td>\n",
       "      <td>recognition</td>\n",
       "      <td>rate</td>\n",
       "      <td>theorem</td>\n",
       "      <td>matrix</td>\n",
       "      <td>task</td>\n",
       "      <td>probability</td>\n",
       "      <td>motion</td>\n",
       "      <td>cell</td>\n",
       "      <td>sequence</td>\n",
       "      <td>tree</td>\n",
       "      <td>object</td>\n",
       "      <td>action</td>\n",
       "      <td>layer</td>\n",
       "      <td>chip</td>\n",
       "      <td>representation</td>\n",
       "      <td>map</td>\n",
       "      <td>filter</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term3</th>\n",
       "      <td>classifier</td>\n",
       "      <td>pattern</td>\n",
       "      <td>training</td>\n",
       "      <td>equation</td>\n",
       "      <td>class</td>\n",
       "      <td>linear</td>\n",
       "      <td>experiment</td>\n",
       "      <td>prior</td>\n",
       "      <td>cell</td>\n",
       "      <td>spike</td>\n",
       "      <td>step</td>\n",
       "      <td>structure</td>\n",
       "      <td>feature</td>\n",
       "      <td>state</td>\n",
       "      <td>training</td>\n",
       "      <td>current</td>\n",
       "      <td>module</td>\n",
       "      <td>distance</td>\n",
       "      <td>frequency</td>\n",
       "      <td>estimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term4</th>\n",
       "      <td>training</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>speech</td>\n",
       "      <td>curve</td>\n",
       "      <td>probability</td>\n",
       "      <td>equation</td>\n",
       "      <td>table</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>response</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>graph</td>\n",
       "      <td>pixel</td>\n",
       "      <td>policy</td>\n",
       "      <td>hidden_unit</td>\n",
       "      <td>analog</td>\n",
       "      <td>structure</td>\n",
       "      <td>cluster</td>\n",
       "      <td>source</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term5</th>\n",
       "      <td>pattern</td>\n",
       "      <td>connection</td>\n",
       "      <td>character</td>\n",
       "      <td>average</td>\n",
       "      <td>size</td>\n",
       "      <td>solution</td>\n",
       "      <td>instance</td>\n",
       "      <td>variable</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>activity</td>\n",
       "      <td>transition</td>\n",
       "      <td>code</td>\n",
       "      <td>face</td>\n",
       "      <td>environment</td>\n",
       "      <td>net</td>\n",
       "      <td>voltage</td>\n",
       "      <td>human</td>\n",
       "      <td>local</td>\n",
       "      <td>channel</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term6</th>\n",
       "      <td>feature</td>\n",
       "      <td>phase</td>\n",
       "      <td>context</td>\n",
       "      <td>correlation</td>\n",
       "      <td>threshold</td>\n",
       "      <td>gradient</td>\n",
       "      <td>test</td>\n",
       "      <td>mixture</td>\n",
       "      <td>direction</td>\n",
       "      <td>response</td>\n",
       "      <td>stochastic</td>\n",
       "      <td>level</td>\n",
       "      <td>view</td>\n",
       "      <td>controller</td>\n",
       "      <td>architecture</td>\n",
       "      <td>implementation</td>\n",
       "      <td>movement</td>\n",
       "      <td>dimension</td>\n",
       "      <td>noise</td>\n",
       "      <td>noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term7</th>\n",
       "      <td>kernel</td>\n",
       "      <td>attractor</td>\n",
       "      <td>hmm</td>\n",
       "      <td>rule</td>\n",
       "      <td>proof</td>\n",
       "      <td>constraint</td>\n",
       "      <td>domain</td>\n",
       "      <td>density</td>\n",
       "      <td>receptive_field</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>iteration</td>\n",
       "      <td>bit</td>\n",
       "      <td>recognition</td>\n",
       "      <td>reinforcement_learning</td>\n",
       "      <td>pattern</td>\n",
       "      <td>processor</td>\n",
       "      <td>motor</td>\n",
       "      <td>clustering</td>\n",
       "      <td>component</td>\n",
       "      <td>selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term8</th>\n",
       "      <td>machine</td>\n",
       "      <td>capacity</td>\n",
       "      <td>letter</td>\n",
       "      <td>distribution</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>convergence</td>\n",
       "      <td>target</td>\n",
       "      <td>bayesian</td>\n",
       "      <td>map</td>\n",
       "      <td>firing</td>\n",
       "      <td>update</td>\n",
       "      <td>path</td>\n",
       "      <td>representation</td>\n",
       "      <td>task</td>\n",
       "      <td>activation</td>\n",
       "      <td>bit</td>\n",
       "      <td>target</td>\n",
       "      <td>mapping</td>\n",
       "      <td>response</td>\n",
       "      <td>variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term9</th>\n",
       "      <td>training_set</td>\n",
       "      <td>state</td>\n",
       "      <td>mlp</td>\n",
       "      <td>theory</td>\n",
       "      <td>theory</td>\n",
       "      <td>optimization</td>\n",
       "      <td>query</td>\n",
       "      <td>estimate</td>\n",
       "      <td>spatial</td>\n",
       "      <td>synapsis</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>local</td>\n",
       "      <td>shape</td>\n",
       "      <td>optimal</td>\n",
       "      <td>trained</td>\n",
       "      <td>design</td>\n",
       "      <td>language</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>temporal</td>\n",
       "      <td>training_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term10</th>\n",
       "      <td>test</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>speaker</td>\n",
       "      <td>limit</td>\n",
       "      <td>complexity</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>feature</td>\n",
       "      <td>approximation</td>\n",
       "      <td>orientation</td>\n",
       "      <td>et_al</td>\n",
       "      <td>probability</td>\n",
       "      <td>size</td>\n",
       "      <td>scale</td>\n",
       "      <td>robot</td>\n",
       "      <td>task</td>\n",
       "      <td>device</td>\n",
       "      <td>subject</td>\n",
       "      <td>region</td>\n",
       "      <td>sound</td>\n",
       "      <td>sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term11</th>\n",
       "      <td>sample</td>\n",
       "      <td>neural</td>\n",
       "      <td>feature</td>\n",
       "      <td>solution</td>\n",
       "      <td>loss</td>\n",
       "      <td>optimal</td>\n",
       "      <td>user</td>\n",
       "      <td>log</td>\n",
       "      <td>unit</td>\n",
       "      <td>effect</td>\n",
       "      <td>convergence</td>\n",
       "      <td>variable</td>\n",
       "      <td>part</td>\n",
       "      <td>goal</td>\n",
       "      <td>back_propagation</td>\n",
       "      <td>computation</td>\n",
       "      <td>connectionist</td>\n",
       "      <td>structure</td>\n",
       "      <td>auditory</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term12</th>\n",
       "      <td>vector</td>\n",
       "      <td>fixed_point</td>\n",
       "      <td>frame</td>\n",
       "      <td>optimal</td>\n",
       "      <td>approximation</td>\n",
       "      <td>eq</td>\n",
       "      <td>random</td>\n",
       "      <td>likelihood</td>\n",
       "      <td>eye</td>\n",
       "      <td>neural</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>stage</td>\n",
       "      <td>visual</td>\n",
       "      <td>step</td>\n",
       "      <td>hidden_layer</td>\n",
       "      <td>parallel</td>\n",
       "      <td>position</td>\n",
       "      <td>center</td>\n",
       "      <td>detection</td>\n",
       "      <td>estimation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term13</th>\n",
       "      <td>database</td>\n",
       "      <td>oscillator</td>\n",
       "      <td>trained</td>\n",
       "      <td>eq</td>\n",
       "      <td>linear</td>\n",
       "      <td>minimum</td>\n",
       "      <td>technique</td>\n",
       "      <td>sample</td>\n",
       "      <td>field</td>\n",
       "      <td>neuronal</td>\n",
       "      <td>xt</td>\n",
       "      <td>length</td>\n",
       "      <td>region</td>\n",
       "      <td>reward</td>\n",
       "      <td>connection</td>\n",
       "      <td>digital</td>\n",
       "      <td>task</td>\n",
       "      <td>rbf</td>\n",
       "      <td>phase</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term14</th>\n",
       "      <td>error_rate</td>\n",
       "      <td>delay</td>\n",
       "      <td>speech_recognition</td>\n",
       "      <td>teacher</td>\n",
       "      <td>assume</td>\n",
       "      <td>operator</td>\n",
       "      <td>run</td>\n",
       "      <td>component</td>\n",
       "      <td>activity</td>\n",
       "      <td>current</td>\n",
       "      <td>length</td>\n",
       "      <td>solution</td>\n",
       "      <td>position</td>\n",
       "      <td>td</td>\n",
       "      <td>hidden</td>\n",
       "      <td>operation</td>\n",
       "      <td>context</td>\n",
       "      <td>pca</td>\n",
       "      <td>ica</td>\n",
       "      <td>nonlinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term15</th>\n",
       "      <td>margin</td>\n",
       "      <td>stable</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>effect</td>\n",
       "      <td>definition</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>expert</td>\n",
       "      <td>location</td>\n",
       "      <td>pattern</td>\n",
       "      <td>observation</td>\n",
       "      <td>edge</td>\n",
       "      <td>scene</td>\n",
       "      <td>agent</td>\n",
       "      <td>backpropagation</td>\n",
       "      <td>array</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>basis_function</td>\n",
       "      <td>adaptation</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term16</th>\n",
       "      <td>experiment</td>\n",
       "      <td>fig</td>\n",
       "      <td>experiment</td>\n",
       "      <td>size</td>\n",
       "      <td>defined</td>\n",
       "      <td>condition</td>\n",
       "      <td>block</td>\n",
       "      <td>em</td>\n",
       "      <td>velocity</td>\n",
       "      <td>inhibitory</td>\n",
       "      <td>continuous</td>\n",
       "      <td>link</td>\n",
       "      <td>surface</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>learn</td>\n",
       "      <td>neural</td>\n",
       "      <td>hand</td>\n",
       "      <td>linear</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>estimator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term17</th>\n",
       "      <td>support_vector</td>\n",
       "      <td>oscillation</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>temperature</td>\n",
       "      <td>hypothesis</td>\n",
       "      <td>constant</td>\n",
       "      <td>application</td>\n",
       "      <td>posterior</td>\n",
       "      <td>center</td>\n",
       "      <td>connection</td>\n",
       "      <td>rate</td>\n",
       "      <td>component</td>\n",
       "      <td>vision</td>\n",
       "      <td>cost</td>\n",
       "      <td>training_set</td>\n",
       "      <td>synapse</td>\n",
       "      <td>role</td>\n",
       "      <td>representation</td>\n",
       "      <td>subject</td>\n",
       "      <td>cross_validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term18</th>\n",
       "      <td>nearest_neighbor</td>\n",
       "      <td>associative_memory</td>\n",
       "      <td>segmentation</td>\n",
       "      <td>student</td>\n",
       "      <td>constant</td>\n",
       "      <td>derivative</td>\n",
       "      <td>evaluation</td>\n",
       "      <td>probabilistic</td>\n",
       "      <td>contrast</td>\n",
       "      <td>brain</td>\n",
       "      <td>machine</td>\n",
       "      <td>match</td>\n",
       "      <td>frame</td>\n",
       "      <td>reinforcement</td>\n",
       "      <td>epoch</td>\n",
       "      <td>element</td>\n",
       "      <td>symbol</td>\n",
       "      <td>global</td>\n",
       "      <td>eeg</td>\n",
       "      <td>pruning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term19</th>\n",
       "      <td>decision</td>\n",
       "      <td>behavior</td>\n",
       "      <td>vowel</td>\n",
       "      <td>line</td>\n",
       "      <td>define</td>\n",
       "      <td>quadratic</td>\n",
       "      <td>strategy</td>\n",
       "      <td>estimation</td>\n",
       "      <td>cortical</td>\n",
       "      <td>simulation</td>\n",
       "      <td>current</td>\n",
       "      <td>binary</td>\n",
       "      <td>texture</td>\n",
       "      <td>trial</td>\n",
       "      <td>simulation</td>\n",
       "      <td>hardware</td>\n",
       "      <td>learned</td>\n",
       "      <td>principal_component</td>\n",
       "      <td>change</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term20</th>\n",
       "      <td>size</td>\n",
       "      <td>stored</td>\n",
       "      <td>level</td>\n",
       "      <td>random</td>\n",
       "      <td>bounded</td>\n",
       "      <td>energy</td>\n",
       "      <td>important</td>\n",
       "      <td>entropy</td>\n",
       "      <td>pattern</td>\n",
       "      <td>firing_rate</td>\n",
       "      <td>string</td>\n",
       "      <td>coding</td>\n",
       "      <td>location</td>\n",
       "      <td>exploration</td>\n",
       "      <td>generalization</td>\n",
       "      <td>transistor</td>\n",
       "      <td>theory</td>\n",
       "      <td>projection</td>\n",
       "      <td>correlation</td>\n",
       "      <td>risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Topic 1             Topic 2             Topic 3  \\\n",
       "Term1              class              neuron                word   \n",
       "Term2     classification              memory         recognition   \n",
       "Term3         classifier             pattern            training   \n",
       "Term4           training             dynamic              speech   \n",
       "Term5            pattern          connection           character   \n",
       "Term6            feature               phase             context   \n",
       "Term7             kernel           attractor                 hmm   \n",
       "Term8            machine            capacity              letter   \n",
       "Term9       training_set               state                 mlp   \n",
       "Term10              test            hopfield             speaker   \n",
       "Term11            sample              neural             feature   \n",
       "Term12            vector         fixed_point               frame   \n",
       "Term13          database          oscillator             trained   \n",
       "Term14        error_rate               delay  speech_recognition   \n",
       "Term15            margin              stable             phoneme   \n",
       "Term16        experiment                 fig          experiment   \n",
       "Term17    support_vector         oscillation              hybrid   \n",
       "Term18  nearest_neighbor  associative_memory        segmentation   \n",
       "Term19          decision            behavior               vowel   \n",
       "Term20              size              stored               level   \n",
       "\n",
       "             Topic 4        Topic 5           Topic 6      Topic 7  \\\n",
       "Term1          noise          bound            vector       search   \n",
       "Term2           rate        theorem            matrix         task   \n",
       "Term3       equation          class            linear   experiment   \n",
       "Term4          curve    probability          equation        table   \n",
       "Term5        average           size          solution     instance   \n",
       "Term6    correlation      threshold          gradient         test   \n",
       "Term7           rule          proof        constraint       domain   \n",
       "Term8   distribution     polynomial       convergence       target   \n",
       "Term9         theory         theory      optimization        query   \n",
       "Term10         limit     complexity         nonlinear      feature   \n",
       "Term11      solution           loss           optimal         user   \n",
       "Term12       optimal  approximation                eq       random   \n",
       "Term13            eq         linear           minimum    technique   \n",
       "Term14       teacher         assume          operator          run   \n",
       "Term15        effect     definition  gradient_descent     accuracy   \n",
       "Term16          size        defined         condition        block   \n",
       "Term17   temperature     hypothesis          constant  application   \n",
       "Term18       student       constant        derivative   evaluation   \n",
       "Term19          line         define         quadratic     strategy   \n",
       "Term20        random        bounded            energy    important   \n",
       "\n",
       "              Topic 8          Topic 9     Topic 10     Topic 11   Topic 12  \\\n",
       "Term1    distribution           visual       neuron        state       node   \n",
       "Term2     probability           motion         cell     sequence       tree   \n",
       "Term3           prior             cell        spike         step  structure   \n",
       "Term4        gaussian         response     synaptic    recurrent      graph   \n",
       "Term5        variable         stimulus     activity   transition       code   \n",
       "Term6         mixture        direction     response   stochastic      level   \n",
       "Term7         density  receptive_field     stimulus    iteration        bit   \n",
       "Term8        bayesian              map       firing       update       path   \n",
       "Term9        estimate          spatial     synapsis      dynamic      local   \n",
       "Term10  approximation      orientation        et_al  probability       size   \n",
       "Term11            log             unit       effect  convergence   variable   \n",
       "Term12     likelihood              eye       neural   trajectory      stage   \n",
       "Term13         sample            field     neuronal           xt     length   \n",
       "Term14      component         activity      current       length   solution   \n",
       "Term15         expert         location      pattern  observation       edge   \n",
       "Term16             em         velocity   inhibitory   continuous       link   \n",
       "Term17      posterior           center   connection         rate  component   \n",
       "Term18  probabilistic         contrast        brain      machine      match   \n",
       "Term19     estimation         cortical   simulation      current     binary   \n",
       "Term20        entropy          pattern  firing_rate       string     coding   \n",
       "\n",
       "              Topic 13                Topic 14          Topic 15  \\\n",
       "Term1            image                 control              unit   \n",
       "Term2           object                  action             layer   \n",
       "Term3          feature                   state          training   \n",
       "Term4            pixel                  policy       hidden_unit   \n",
       "Term5             face             environment               net   \n",
       "Term6             view              controller      architecture   \n",
       "Term7      recognition  reinforcement_learning           pattern   \n",
       "Term8   representation                    task        activation   \n",
       "Term9            shape                 optimal           trained   \n",
       "Term10           scale                   robot              task   \n",
       "Term11            part                    goal  back_propagation   \n",
       "Term12          visual                    step      hidden_layer   \n",
       "Term13          region                  reward        connection   \n",
       "Term14        position                      td            hidden   \n",
       "Term15           scene                   agent   backpropagation   \n",
       "Term16         surface                adaptive             learn   \n",
       "Term17          vision                    cost      training_set   \n",
       "Term18           frame           reinforcement             epoch   \n",
       "Term19         texture                   trial        simulation   \n",
       "Term20        location             exploration    generalization   \n",
       "\n",
       "              Topic 16        Topic 17             Topic 18     Topic 19  \\\n",
       "Term1          circuit            rule               vector       signal   \n",
       "Term2             chip  representation                  map       filter   \n",
       "Term3          current          module             distance    frequency   \n",
       "Term4           analog       structure              cluster       source   \n",
       "Term5          voltage           human                local      channel   \n",
       "Term6   implementation        movement            dimension        noise   \n",
       "Term7        processor           motor           clustering    component   \n",
       "Term8              bit          target              mapping     response   \n",
       "Term9           design        language          dimensional     temporal   \n",
       "Term10          device         subject               region        sound   \n",
       "Term11     computation   connectionist            structure     auditory   \n",
       "Term12        parallel        position               center    detection   \n",
       "Term13         digital            task                  rbf        phase   \n",
       "Term14       operation         context                  pca          ica   \n",
       "Term15           array      trajectory       basis_function   adaptation   \n",
       "Term16          neural            hand               linear    amplitude   \n",
       "Term17         synapse            role       representation      subject   \n",
       "Term18         element          symbol               global          eeg   \n",
       "Term19        hardware         learned  principal_component       change   \n",
       "Term20      transistor          theory           projection  correlation   \n",
       "\n",
       "                Topic 20  \n",
       "Term1         prediction  \n",
       "Term2           training  \n",
       "Term3           estimate  \n",
       "Term4         regression  \n",
       "Term5               test  \n",
       "Term6              noise  \n",
       "Term7          selection  \n",
       "Term8           variance  \n",
       "Term9       training_set  \n",
       "Term10            sample  \n",
       "Term11          ensemble  \n",
       "Term12        estimation  \n",
       "Term13           average  \n",
       "Term14         nonlinear  \n",
       "Term15            linear  \n",
       "Term16         estimator  \n",
       "Term17  cross_validation  \n",
       "Term18           pruning  \n",
       "Term19              bias  \n",
       "Term20              risk  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
    "                              for topic in topics], \n",
    "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
    "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>class, classification, classifier, training, pattern, feature, kernel, machine, training_set, test, sample, vector, database, error_rate, margin, experiment, support_vector, nearest_neighbor, decision, size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>neuron, memory, pattern, dynamic, connection, phase, attractor, capacity, state, hopfield, neural, fixed_point, oscillator, delay, stable, fig, oscillation, associative_memory, behavior, stored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>noise, rate, equation, curve, average, correlation, rule, distribution, theory, limit, solution, optimal, eq, teacher, effect, size, temperature, student, line, random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>vector, matrix, linear, equation, solution, gradient, constraint, convergence, optimization, nonlinear, optimal, eq, minimum, operator, gradient_descent, condition, constant, derivative, quadratic, energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>search, task, experiment, table, instance, test, domain, target, query, feature, user, random, technique, run, accuracy, block, application, evaluation, strategy, important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>visual, motion, cell, response, stimulus, direction, receptive_field, map, spatial, orientation, unit, eye, field, activity, location, velocity, center, contrast, cortical, pattern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>state, sequence, step, recurrent, transition, stochastic, iteration, update, dynamic, probability, convergence, trajectory, xt, length, observation, continuous, rate, machine, current, string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>node, tree, structure, graph, code, level, bit, path, local, size, variable, stage, length, solution, edge, link, component, match, binary, coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>unit, layer, training, hidden_unit, net, architecture, pattern, activation, trained, task, back_propagation, hidden_layer, connection, hidden, backpropagation, learn, training_set, epoch, simulation, generalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>rule, representation, module, structure, human, movement, motor, target, language, subject, connectionist, position, task, context, trajectory, hand, role, symbol, learned, theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>vector, map, distance, cluster, local, dimension, clustering, mapping, dimensional, region, structure, center, rbf, pca, basis_function, linear, representation, global, principal_component, projection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>signal, filter, frequency, source, channel, noise, component, response, temporal, sound, auditory, detection, phase, ica, adaptation, amplitude, subject, eeg, change, correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>prediction, training, estimate, regression, test, noise, selection, variance, training_set, sample, ensemble, estimation, average, nonlinear, linear, estimator, cross_validation, pruning, bias, risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                Terms per Topic\n",
       "Topic1   class, classification, classifier, training, pattern, feature, kernel, machine, training_set, test, sample, vector, database, error_rate, margin, experiment, support_vector, nearest_neighbor, decision, size        \n",
       "Topic2   neuron, memory, pattern, dynamic, connection, phase, attractor, capacity, state, hopfield, neural, fixed_point, oscillator, delay, stable, fig, oscillation, associative_memory, behavior, stored                     \n",
       "Topic3   word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level                              \n",
       "Topic4   noise, rate, equation, curve, average, correlation, rule, distribution, theory, limit, solution, optimal, eq, teacher, effect, size, temperature, student, line, random                                               \n",
       "Topic5   bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded                           \n",
       "Topic6   vector, matrix, linear, equation, solution, gradient, constraint, convergence, optimization, nonlinear, optimal, eq, minimum, operator, gradient_descent, condition, constant, derivative, quadratic, energy          \n",
       "Topic7   search, task, experiment, table, instance, test, domain, target, query, feature, user, random, technique, run, accuracy, block, application, evaluation, strategy, important                                          \n",
       "Topic8   distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, entropy              \n",
       "Topic9   visual, motion, cell, response, stimulus, direction, receptive_field, map, spatial, orientation, unit, eye, field, activity, location, velocity, center, contrast, cortical, pattern                                  \n",
       "Topic10  neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate                              \n",
       "Topic11  state, sequence, step, recurrent, transition, stochastic, iteration, update, dynamic, probability, convergence, trajectory, xt, length, observation, continuous, rate, machine, current, string                       \n",
       "Topic12  node, tree, structure, graph, code, level, bit, path, local, size, variable, stage, length, solution, edge, link, component, match, binary, coding                                                                    \n",
       "Topic13  image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location                                                \n",
       "Topic14  control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration                               \n",
       "Topic15  unit, layer, training, hidden_unit, net, architecture, pattern, activation, trained, task, back_propagation, hidden_layer, connection, hidden, backpropagation, learn, training_set, epoch, simulation, generalization\n",
       "Topic16  circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor                             \n",
       "Topic17  rule, representation, module, structure, human, movement, motor, target, language, subject, connectionist, position, task, context, trajectory, hand, role, symbol, learned, theory                                   \n",
       "Topic18  vector, map, distance, cluster, local, dimension, clustering, mapping, dimensional, region, structure, center, rbf, pca, basis_function, linear, representation, global, principal_component, projection              \n",
       "Topic19  signal, filter, frequency, source, channel, noise, component, response, temporal, sound, auditory, detection, phase, ica, adaptation, amplitude, subject, eeg, change, correlation                                    \n",
       "Topic20  prediction, training, estimate, regression, test, noise, selection, variance, training_set, sample, ensemble, estimation, average, nonlinear, linear, estimator, cross_validation, pruning, bias, risk                "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])  \n",
    "                              for topic in topics],\n",
    "                         columns = ['Terms per Topic'],\n",
    "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
    "                         )\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Topic Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_results = best_lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, 0.2115988756613756),\n",
       " (5, 0.29989652050187554),\n",
       " (9, 0.3307915758896151),\n",
       " (8, 0.5447463768115942),\n",
       " (9, 0.18093823158652983)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] \n",
    "                     for topics in tm_results]\n",
    "corpus_topics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_topic_df = pd.DataFrame()\n",
    "corpus_topic_df['Document'] = range(0, len(papers))\n",
    "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
    "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
    "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
    "corpus_topic_df['Paper'] = papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dominant Topics Distribution across Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/pandas/core/groupby/groupby.py:4656: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>% Total Docs</th>\n",
       "      <th>Topic Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>4.31</td>\n",
       "      <td>class, classification, classifier, training, pattern, feature, kernel, machine, training_set, test, sample, vector, database, error_rate, margin, experiment, support_vector, nearest_neighbor, deci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>3.97</td>\n",
       "      <td>neuron, memory, pattern, dynamic, connection, phase, attractor, capacity, state, hopfield, neural, fixed_point, oscillator, delay, stable, fig, oscillation, associative_memory, behavior, stored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>4.48</td>\n",
       "      <td>word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>3.91</td>\n",
       "      <td>noise, rate, equation, curve, average, correlation, rule, distribution, theory, limit, solution, optimal, eq, teacher, effect, size, temperature, student, line, random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>6.03</td>\n",
       "      <td>bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>4.60</td>\n",
       "      <td>vector, matrix, linear, equation, solution, gradient, constraint, convergence, optimization, nonlinear, optimal, eq, minimum, operator, gradient_descent, condition, constant, derivative, quadratic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>66</td>\n",
       "      <td>3.79</td>\n",
       "      <td>search, task, experiment, table, instance, test, domain, target, query, feature, user, random, technique, run, accuracy, block, application, evaluation, strategy, important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>148</td>\n",
       "      <td>8.51</td>\n",
       "      <td>distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>117</td>\n",
       "      <td>6.72</td>\n",
       "      <td>visual, motion, cell, response, stimulus, direction, receptive_field, map, spatial, orientation, unit, eye, field, activity, location, velocity, center, contrast, cortical, pattern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>141</td>\n",
       "      <td>8.10</td>\n",
       "      <td>neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>2.36</td>\n",
       "      <td>state, sequence, step, recurrent, transition, stochastic, iteration, update, dynamic, probability, convergence, trajectory, xt, length, observation, continuous, rate, machine, current, string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>2.36</td>\n",
       "      <td>node, tree, structure, graph, code, level, bit, path, local, size, variable, stage, length, solution, edge, link, component, match, binary, coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>113</td>\n",
       "      <td>6.49</td>\n",
       "      <td>image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>110</td>\n",
       "      <td>6.32</td>\n",
       "      <td>control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>84</td>\n",
       "      <td>4.83</td>\n",
       "      <td>unit, layer, training, hidden_unit, net, architecture, pattern, activation, trained, task, back_propagation, hidden_layer, connection, hidden, backpropagation, learn, training_set, epoch, simulati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>104</td>\n",
       "      <td>5.98</td>\n",
       "      <td>circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>76</td>\n",
       "      <td>4.37</td>\n",
       "      <td>rule, representation, module, structure, human, movement, motor, target, language, subject, connectionist, position, task, context, trajectory, hand, role, symbol, learned, theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>63</td>\n",
       "      <td>3.62</td>\n",
       "      <td>vector, map, distance, cluster, local, dimension, clustering, mapping, dimensional, region, structure, center, rbf, pca, basis_function, linear, representation, global, principal_component, projec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>69</td>\n",
       "      <td>3.97</td>\n",
       "      <td>signal, filter, frequency, source, channel, noise, component, response, temporal, sound, auditory, detection, phase, ica, adaptation, amplitude, subject, eeg, change, correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>92</td>\n",
       "      <td>5.29</td>\n",
       "      <td>prediction, training, estimate, regression, test, noise, selection, variance, training_set, sample, ensemble, estimation, average, nonlinear, linear, estimator, cross_validation, pruning, bias, risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant Topic  Doc Count  % Total Docs  \\\n",
       "0                1         75          4.31   \n",
       "1                2         69          3.97   \n",
       "2                3         78          4.48   \n",
       "3                4         68          3.91   \n",
       "4                5        105          6.03   \n",
       "5                6         80          4.60   \n",
       "6                7         66          3.79   \n",
       "7                8        148          8.51   \n",
       "8                9        117          6.72   \n",
       "9               10        141          8.10   \n",
       "10              11         41          2.36   \n",
       "11              12         41          2.36   \n",
       "12              13        113          6.49   \n",
       "13              14        110          6.32   \n",
       "14              15         84          4.83   \n",
       "15              16        104          5.98   \n",
       "16              17         76          4.37   \n",
       "17              18         63          3.62   \n",
       "18              19         69          3.97   \n",
       "19              20         92          5.29   \n",
       "\n",
       "                                                                                                                                                                                                 Topic Desc  \n",
       "0   class, classification, classifier, training, pattern, feature, kernel, machine, training_set, test, sample, vector, database, error_rate, margin, experiment, support_vector, nearest_neighbor, deci...  \n",
       "1         neuron, memory, pattern, dynamic, connection, phase, attractor, capacity, state, hopfield, neural, fixed_point, oscillator, delay, stable, fig, oscillation, associative_memory, behavior, stored  \n",
       "2                  word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level  \n",
       "3                                   noise, rate, equation, curve, average, correlation, rule, distribution, theory, limit, solution, optimal, eq, teacher, effect, size, temperature, student, line, random  \n",
       "4               bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded  \n",
       "5   vector, matrix, linear, equation, solution, gradient, constraint, convergence, optimization, nonlinear, optimal, eq, minimum, operator, gradient_descent, condition, constant, derivative, quadratic...  \n",
       "6                              search, task, experiment, table, instance, test, domain, target, query, feature, user, random, technique, run, accuracy, block, application, evaluation, strategy, important  \n",
       "7   distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, ent...  \n",
       "8                      visual, motion, cell, response, stimulus, direction, receptive_field, map, spatial, orientation, unit, eye, field, activity, location, velocity, center, contrast, cortical, pattern  \n",
       "9                  neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate  \n",
       "10          state, sequence, step, recurrent, transition, stochastic, iteration, update, dynamic, probability, convergence, trajectory, xt, length, observation, continuous, rate, machine, current, string  \n",
       "11                                                       node, tree, structure, graph, code, level, bit, path, local, size, variable, stage, length, solution, edge, link, component, match, binary, coding  \n",
       "12                                   image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location  \n",
       "13                  control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration  \n",
       "14  unit, layer, training, hidden_unit, net, architecture, pattern, activation, trained, task, back_propagation, hidden_layer, connection, hidden, backpropagation, learn, training_set, epoch, simulati...  \n",
       "15                circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor  \n",
       "16                      rule, representation, module, structure, human, movement, motor, target, language, subject, connectionist, position, task, context, trajectory, hand, role, symbol, learned, theory  \n",
       "17  vector, map, distance, cluster, local, dimension, clustering, mapping, dimensional, region, structure, center, rbf, pca, basis_function, linear, representation, global, principal_component, projec...  \n",
       "18                       signal, filter, frequency, source, channel, noise, component, response, temporal, sound, auditory, detection, phase, ica, adaptation, amplitude, subject, eeg, change, correlation  \n",
       "19   prediction, training, estimate, regression, test, noise, selection, variance, training_set, sample, ensemble, estimation, average, nonlinear, linear, estimator, cross_validation, pruning, bias, risk  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "topic_stats_df = corpus_topic_df.groupby('Dominant Topic').agg({\n",
    "                                                'Dominant Topic': {\n",
    "                                                    'Doc Count': np.size,\n",
    "                                                    '% Total Docs': np.size }\n",
    "                                              })\n",
    "topic_stats_df = topic_stats_df['Dominant Topic'].reset_index()\n",
    "topic_stats_df['% Total Docs'] = topic_stats_df['% Total Docs'].apply(lambda row: round((row*100) / len(papers), 2))\n",
    "topic_stats_df['Topic Desc'] = [topics_df.iloc[t]['Terms per Topic'] for t in range(len(topic_stats_df))]\n",
    "topic_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dominant Topics in Specific Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>29.10</td>\n",
       "      <td>image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location</td>\n",
       "      <td>622 \\nLEARNING A COLOR ALGORITHM FROM EXAMPLES \\nAnya C. Hurlbert and Tomaso A. Poggio \\nArtificial Intelligence Laboratory and Department of Brain and Cognitive Sciences, \\nMassachusetts Institut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>27.12</td>\n",
       "      <td>circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor</td>\n",
       "      <td>9 \\nStochastic Learning Networks and their Electronic Implementation \\nJoshua Alspector*, Robert B. Allen, Victor Hut, and Srinagesh Satyanarayana \\nBell Communications Research, Morristown, NJ 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>23.00</td>\n",
       "      <td>bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded</td>\n",
       "      <td>338 \\nThe Connectivity Analysis of Simple Association \\nHow Many Connections Do You Need? \\nDan Hammerstrom * \\nOregon Graduate Center, Beaverton, OR 97006 \\nABSTRACT \\nThe efficient realization, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>392</td>\n",
       "      <td>14</td>\n",
       "      <td>67.03</td>\n",
       "      <td>control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration</td>\n",
       "      <td>Integrated Modeling and Control \\nBased on Reinforcement Learning \\nand Dynamic Programming \\nRichard S. Sutton \\nGTE Laboratories Incorporated \\nWaltham, MA 02254 \\nAbstract \\nThis is a summary o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>503</td>\n",
       "      <td>3</td>\n",
       "      <td>60.76</td>\n",
       "      <td>word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level</td>\n",
       "      <td>Multi-State Time Delay Neural Networks \\nfor Continuous Speech Recognition \\nPatrick Haffner \\nCNET Lannion A TSS/RCP \\n22301 LANNION, FRANCE \\nhaffnerlannion.cnet. fr \\nAlex Waibel \\nCarnegie Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>67.58</td>\n",
       "      <td>word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level</td>\n",
       "      <td>Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>733</td>\n",
       "      <td>16</td>\n",
       "      <td>45.55</td>\n",
       "      <td>circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor</td>\n",
       "      <td>High Performance Neural Net Simulation \\non a Multiprocessor System with \\n\"Intelligent\" Communication \\nUrs A. Miiller, Michael Kocheisen, and Anton Gunzinger \\nElectronics Laboratory, Swiss Fede...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>906</td>\n",
       "      <td>10</td>\n",
       "      <td>56.44</td>\n",
       "      <td>neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate</td>\n",
       "      <td>A model of the hippocampus combining self- \\norganization and associative memory function. \\nMichael E. Hasselmo, Eric Schnell \\nJoshua Berke and Edi Barkai \\nDept. of Psychology, Harvard Universi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>19</td>\n",
       "      <td>65.69</td>\n",
       "      <td>signal, filter, frequency, source, channel, noise, component, response, temporal, sound, auditory, detection, phase, ica, adaptation, amplitude, subject, eeg, change, correlation</td>\n",
       "      <td>Using Feedforward Neural Networks to \\nMonitor Alertness from Changes in EEG \\nCorrelation and Coherence \\nScott Makeig \\nNaval Health Research Center, P.O. Box 85122 \\nSan Diego, CA 92186-5122 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1622</td>\n",
       "      <td>8</td>\n",
       "      <td>56.70</td>\n",
       "      <td>distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, ent...</td>\n",
       "      <td>The Infinite Gaussian Mixture Model \\nCarl Edward Rasmussen \\nDepartment of Mathematical Modelling \\nTechnical University of Denmark \\nBuilding 321, DK-2800 Kongens Lyngby, Denmark \\ncarl@imm.dtu....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Document  Dominant Topic  Contribution %  \\\n",
       "9            9              13           29.10   \n",
       "13          13              16           27.12   \n",
       "17          17               5           23.00   \n",
       "392        392              14           67.03   \n",
       "503        503               3           60.76   \n",
       "681        681               3           67.58   \n",
       "733        733              16           45.55   \n",
       "906        906              10           56.44   \n",
       "996        996              19           65.69   \n",
       "1622      1622               8           56.70   \n",
       "\n",
       "                                                                                                                                                                                                   Topic Desc  \\\n",
       "9                                      image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location   \n",
       "13                  circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor   \n",
       "17                bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded   \n",
       "392                   control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration   \n",
       "503                  word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level   \n",
       "681                  word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level   \n",
       "733                 circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor   \n",
       "906                  neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate   \n",
       "996                        signal, filter, frequency, source, channel, noise, component, response, temporal, sound, auditory, detection, phase, ica, adaptation, amplitude, subject, eeg, change, correlation   \n",
       "1622  distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, ent...   \n",
       "\n",
       "                                                                                                                                                                                                        Paper  \n",
       "9     622 \\nLEARNING A COLOR ALGORITHM FROM EXAMPLES \\nAnya C. Hurlbert and Tomaso A. Poggio \\nArtificial Intelligence Laboratory and Department of Brain and Cognitive Sciences, \\nMassachusetts Institut...  \n",
       "13    9 \\nStochastic Learning Networks and their Electronic Implementation \\nJoshua Alspector*, Robert B. Allen, Victor Hut, and Srinagesh Satyanarayana \\nBell Communications Research, Morristown, NJ 0...  \n",
       "17    338 \\nThe Connectivity Analysis of Simple Association \\nHow Many Connections Do You Need? \\nDan Hammerstrom * \\nOregon Graduate Center, Beaverton, OR 97006 \\nABSTRACT \\nThe efficient realization, ...  \n",
       "392   Integrated Modeling and Control \\nBased on Reinforcement Learning \\nand Dynamic Programming \\nRichard S. Sutton \\nGTE Laboratories Incorporated \\nWaltham, MA 02254 \\nAbstract \\nThis is a summary o...  \n",
       "503   Multi-State Time Delay Neural Networks \\nfor Continuous Speech Recognition \\nPatrick Haffner \\nCNET Lannion A TSS/RCP \\n22301 LANNION, FRANCE \\nhaffnerlannion.cnet. fr \\nAlex Waibel \\nCarnegie Me...  \n",
       "681   Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...  \n",
       "733   High Performance Neural Net Simulation \\non a Multiprocessor System with \\n\"Intelligent\" Communication \\nUrs A. Miiller, Michael Kocheisen, and Anton Gunzinger \\nElectronics Laboratory, Swiss Fede...  \n",
       "906   A model of the hippocampus combining self- \\norganization and associative memory function. \\nMichael E. Hasselmo, Eric Schnell \\nJoshua Berke and Edi Barkai \\nDept. of Psychology, Harvard Universi...  \n",
       "996   Using Feedforward Neural Networks to \\nMonitor Alertness from Changes in EEG \\nCorrelation and Coherence \\nScott Makeig \\nNaval Health Research Center, P.O. Box 85122 \\nSan Diego, CA 92186-5122 \\n...  \n",
       "1622  The Infinite Gaussian Mixture Model \\nCarl Edward Rasmussen \\nDepartment of Mathematical Modelling \\nTechnical University of Denmark \\nBuilding 321, DK-2800 Kongens Lyngby, Denmark \\ncarl@imm.dtu....  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "(corpus_topic_df[corpus_topic_df['Document']\n",
    "                 .isin([681, 9, 392, 1622, 17, \n",
    "                        906, 996, 503, 13, 733])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Research Papers per Topic based on Dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1138</td>\n",
       "      <td>1</td>\n",
       "      <td>61.01</td>\n",
       "      <td>class, classification, classifier, training, pattern, feature, kernel, machine, training_set, test, sample, vector, database, error_rate, margin, experiment, support_vector, nearest_neighbor, deci...</td>\n",
       "      <td>Improving the Accuracy and Speed of \\nSupport Vector Machines \\nChris J.C. Burges \\nBell Laboratories \\nLucent Technologies, Room 3G429 \\n101 Crawford's Corner Road \\nHolmdel, NJ 07733-3030 \\nburg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>56.71</td>\n",
       "      <td>neuron, memory, pattern, dynamic, connection, phase, attractor, capacity, state, hopfield, neural, fixed_point, oscillator, delay, stable, fig, oscillation, associative_memory, behavior, stored</td>\n",
       "      <td>568 \\nDYNAMICS OF ANALOG NEURAL \\nNETWORKS WITH TIME DELAY \\nC.M. Marcus and R.M. Westervelt \\nDivision of Applied Sciences and Department of Physics \\nHarvard University, Cambridge Massachusetts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>67.58</td>\n",
       "      <td>word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level</td>\n",
       "      <td>Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1570</td>\n",
       "      <td>4</td>\n",
       "      <td>73.69</td>\n",
       "      <td>noise, rate, equation, curve, average, correlation, rule, distribution, theory, limit, solution, optimal, eq, teacher, effect, size, temperature, student, line, random</td>\n",
       "      <td>Dynamics of Supervised Learning with \\nRestricted Training Sets \\nA.C.C. Coolen \\nDept of Mathematics \\nKing's College London \\nStrand, London WC2R 2LS, UK \\ntcoolen @mth.kcl.ac.uk \\nD. Saad \\nNeu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>431</td>\n",
       "      <td>5</td>\n",
       "      <td>81.06</td>\n",
       "      <td>bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded</td>\n",
       "      <td>Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>57.12</td>\n",
       "      <td>vector, matrix, linear, equation, solution, gradient, constraint, convergence, optimization, nonlinear, optimal, eq, minimum, operator, gradient_descent, condition, constant, derivative, quadratic...</td>\n",
       "      <td>612 \\nConstrained Differential Optimization \\nJohn C. Platt \\nAlan H. Ban' \\nCalifornia Institute of Technology, Pasadena, CA 91125 \\nAbstract \\nMany optimization models of neural networks need co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>741</td>\n",
       "      <td>7</td>\n",
       "      <td>62.82</td>\n",
       "      <td>search, task, experiment, table, instance, test, domain, target, query, feature, user, random, technique, run, accuracy, block, application, evaluation, strategy, important</td>\n",
       "      <td>When Will a Genetic Algorithm \\nOutperform Hill Climbing? \\nMelanie Mitchell \\nSanta Fe Institute \\n1660 Old Pecos Trail, Suite A \\nSanta Fe, NM 87501 \\nJohn H. Holland \\nDept. of Psychology \\nUni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1375</td>\n",
       "      <td>8</td>\n",
       "      <td>61.11</td>\n",
       "      <td>distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, ent...</td>\n",
       "      <td>Approximating Posterior Distributions \\nin Belief Networks using Mixtures \\nChristopher M. Bishop \\nNeil Lawrence \\nNeural Computing Research Group \\nDept. Computer Science &amp; Applied Mathematics \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>808</td>\n",
       "      <td>9</td>\n",
       "      <td>66.59</td>\n",
       "      <td>visual, motion, cell, response, stimulus, direction, receptive_field, map, spatial, orientation, unit, eye, field, activity, location, velocity, center, contrast, cortical, pattern</td>\n",
       "      <td>Development of Orientation and Ocular \\nDominance Columns in Infant Macaques \\nKlaus Obermayer \\nHoward Hughes Medical Institute \\nSMk-Institute \\nLa Jolla, CA 92037 \\nLynne Kiorpes \\nCenter for N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>74.86</td>\n",
       "      <td>neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate</td>\n",
       "      <td>82 \\nSIMULATIONS SUGGEST \\nINFORMATION PROCESSING ROLES \\nFOR THE DIVERSE CURRENTS IN \\nHIPPOCAMPAL NEURONS \\nLyle J. Borg-Graham \\nHarvard-MIT Division of Health Sciences and Technology and \\nCen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1128</td>\n",
       "      <td>11</td>\n",
       "      <td>49.68</td>\n",
       "      <td>state, sequence, step, recurrent, transition, stochastic, iteration, update, dynamic, probability, convergence, trajectory, xt, length, observation, continuous, rate, machine, current, string</td>\n",
       "      <td>Finite State Automata that Recurrent \\nCascade-Correlation Cannot Represent \\nStefan C. Kremer \\nDepartment of Computing Science \\nUniversity of Alberta \\nEdmonton, Alberta, CANADA T6H 5B5 \\nAbstr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1034</td>\n",
       "      <td>12</td>\n",
       "      <td>45.28</td>\n",
       "      <td>node, tree, structure, graph, code, level, bit, path, local, size, variable, stage, length, solution, edge, link, component, match, binary, coding</td>\n",
       "      <td>Prediction of Beta Sheets in Proteins \\nAnders Krogh \\nThe Sanger Centre \\nHinxton, Carnbs CB10 1RQ, UK. \\nEmail: krogh@sanger. ac.uk \\nSoren Kamaric Riis \\nElectronics Institute, Building 349 \\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>250</td>\n",
       "      <td>13</td>\n",
       "      <td>56.75</td>\n",
       "      <td>image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location</td>\n",
       "      <td>266 Zemel, Mozer and Hinton \\nTRAFFIC: Recognizing Objects Using \\nHierarchical Reference Frame Transformations \\nRichard S. Zemel \\nComputer Science Dept. \\nUniversity of Toronto \\nToronto, ONT M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>392</td>\n",
       "      <td>14</td>\n",
       "      <td>67.03</td>\n",
       "      <td>control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration</td>\n",
       "      <td>Integrated Modeling and Control \\nBased on Reinforcement Learning \\nand Dynamic Programming \\nRichard S. Sutton \\nGTE Laboratories Incorporated \\nWaltham, MA 02254 \\nAbstract \\nThis is a summary o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>277</td>\n",
       "      <td>15</td>\n",
       "      <td>62.31</td>\n",
       "      <td>unit, layer, training, hidden_unit, net, architecture, pattern, activation, trained, task, back_propagation, hidden_layer, connection, hidden, backpropagation, learn, training_set, epoch, simulati...</td>\n",
       "      <td>524 Fahlman and Lebiere \\nThe Cascade-Correlation Learning Architecture \\nScott E. Fahlman and Christian Lebiere \\nSchool of Computer Science \\nCarnegie-Mellon University \\nPittsburgh, PA 15213 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>895</td>\n",
       "      <td>16</td>\n",
       "      <td>70.96</td>\n",
       "      <td>circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor</td>\n",
       "      <td>Single Transistor Learning Synapses \\nPaul Hasler, Chris Diorio, Bradley A. Minch, Carver Mead \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\n(SlS) 95- 2S12 \\npaul@hobiecat.pcmp.calt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>518</td>\n",
       "      <td>17</td>\n",
       "      <td>58.33</td>\n",
       "      <td>rule, representation, module, structure, human, movement, motor, target, language, subject, connectionist, position, task, context, trajectory, hand, role, symbol, learned, theory</td>\n",
       "      <td>A Connectionist Learning Approach to Analyzing \\nLinguistic Stress \\nPrahlad Gupta \\nDepartment of Psychology \\nCarnegie Mellon University \\nPittsburgh, PA 15213 \\nDavid S. Touretzky \\nSchool of C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1362</td>\n",
       "      <td>18</td>\n",
       "      <td>55.02</td>\n",
       "      <td>vector, map, distance, cluster, local, dimension, clustering, mapping, dimensional, region, structure, center, rbf, pca, basis_function, linear, representation, global, principal_component, projec...</td>\n",
       "      <td>Mapping a manifold of perceptual observations \\nJoshua B. Tenenbaum \\nDepartment of Brain and Cognitive Sciences \\nMassachusetts Institute of Technology, Cambridge, MA 02139 \\nj bt @psyche. mi t. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>996</td>\n",
       "      <td>19</td>\n",
       "      <td>65.69</td>\n",
       "      <td>signal, filter, frequency, source, channel, noise, component, response, temporal, sound, auditory, detection, phase, ica, adaptation, amplitude, subject, eeg, change, correlation</td>\n",
       "      <td>Using Feedforward Neural Networks to \\nMonitor Alertness from Changes in EEG \\nCorrelation and Coherence \\nScott Makeig \\nNaval Health Research Center, P.O. Box 85122 \\nSan Diego, CA 92186-5122 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1249</td>\n",
       "      <td>20</td>\n",
       "      <td>64.87</td>\n",
       "      <td>prediction, training, estimate, regression, test, noise, selection, variance, training_set, sample, ensemble, estimation, average, nonlinear, linear, estimator, cross_validation, pruning, bias, risk</td>\n",
       "      <td>Balancing between bagging and bumping \\nTom Heskes \\nRWCP Novel Functions SNN Laboratory,* University of Nijmegen \\nGeert Grooteplein 21, 6525 EZ Nijmegen, The Netherlands \\ntom@mbfys.kun.nl \\nAbs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Document  Dominant Topic  Contribution %  \\\n",
       "Dominant Topic                                             \n",
       "1                   1138               1           61.01   \n",
       "2                    131               2           56.71   \n",
       "3                    681               3           67.58   \n",
       "4                   1570               4           73.69   \n",
       "5                    431               5           81.06   \n",
       "6                     82               6           57.12   \n",
       "7                    741               7           62.82   \n",
       "8                   1375               8           61.11   \n",
       "9                    808               9           66.59   \n",
       "10                    28              10           74.86   \n",
       "11                  1128              11           49.68   \n",
       "12                  1034              12           45.28   \n",
       "13                   250              13           56.75   \n",
       "14                   392              14           67.03   \n",
       "15                   277              15           62.31   \n",
       "16                   895              16           70.96   \n",
       "17                   518              17           58.33   \n",
       "18                  1362              18           55.02   \n",
       "19                   996              19           65.69   \n",
       "20                  1249              20           64.87   \n",
       "\n",
       "                                                                                                                                                                                                             Topic Desc  \\\n",
       "Dominant Topic                                                                                                                                                                                                            \n",
       "1               class, classification, classifier, training, pattern, feature, kernel, machine, training_set, test, sample, vector, database, error_rate, margin, experiment, support_vector, nearest_neighbor, deci...   \n",
       "2                     neuron, memory, pattern, dynamic, connection, phase, attractor, capacity, state, hopfield, neural, fixed_point, oscillator, delay, stable, fig, oscillation, associative_memory, behavior, stored   \n",
       "3                              word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level   \n",
       "4                                               noise, rate, equation, curve, average, correlation, rule, distribution, theory, limit, solution, optimal, eq, teacher, effect, size, temperature, student, line, random   \n",
       "5                           bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded   \n",
       "6               vector, matrix, linear, equation, solution, gradient, constraint, convergence, optimization, nonlinear, optimal, eq, minimum, operator, gradient_descent, condition, constant, derivative, quadratic...   \n",
       "7                                          search, task, experiment, table, instance, test, domain, target, query, feature, user, random, technique, run, accuracy, block, application, evaluation, strategy, important   \n",
       "8               distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, ent...   \n",
       "9                                  visual, motion, cell, response, stimulus, direction, receptive_field, map, spatial, orientation, unit, eye, field, activity, location, velocity, center, contrast, cortical, pattern   \n",
       "10                             neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate   \n",
       "11                      state, sequence, step, recurrent, transition, stochastic, iteration, update, dynamic, probability, convergence, trajectory, xt, length, observation, continuous, rate, machine, current, string   \n",
       "12                                                                   node, tree, structure, graph, code, level, bit, path, local, size, variable, stage, length, solution, edge, link, component, match, binary, coding   \n",
       "13                                               image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location   \n",
       "14                              control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration   \n",
       "15              unit, layer, training, hidden_unit, net, architecture, pattern, activation, trained, task, back_propagation, hidden_layer, connection, hidden, backpropagation, learn, training_set, epoch, simulati...   \n",
       "16                            circuit, chip, current, analog, voltage, implementation, processor, bit, design, device, computation, parallel, digital, operation, array, neural, synapse, element, hardware, transistor   \n",
       "17                                  rule, representation, module, structure, human, movement, motor, target, language, subject, connectionist, position, task, context, trajectory, hand, role, symbol, learned, theory   \n",
       "18              vector, map, distance, cluster, local, dimension, clustering, mapping, dimensional, region, structure, center, rbf, pca, basis_function, linear, representation, global, principal_component, projec...   \n",
       "19                                   signal, filter, frequency, source, channel, noise, component, response, temporal, sound, auditory, detection, phase, ica, adaptation, amplitude, subject, eeg, change, correlation   \n",
       "20               prediction, training, estimate, regression, test, noise, selection, variance, training_set, sample, ensemble, estimation, average, nonlinear, linear, estimator, cross_validation, pruning, bias, risk   \n",
       "\n",
       "                                                                                                                                                                                                                  Paper  \n",
       "Dominant Topic                                                                                                                                                                                                           \n",
       "1               Improving the Accuracy and Speed of \\nSupport Vector Machines \\nChris J.C. Burges \\nBell Laboratories \\nLucent Technologies, Room 3G429 \\n101 Crawford's Corner Road \\nHolmdel, NJ 07733-3030 \\nburg...  \n",
       "2               568 \\nDYNAMICS OF ANALOG NEURAL \\nNETWORKS WITH TIME DELAY \\nC.M. Marcus and R.M. Westervelt \\nDivision of Applied Sciences and Department of Physics \\nHarvard University, Cambridge Massachusetts ...  \n",
       "3               Connected Letter Recognition with a \\nMulti-State Time Delay Neural Network \\nHermann Hild and Alex Waibel \\nSchool of Computer Science \\nCarnegie Mellon University \\nPittsburgh, PA 15213-3891, US...  \n",
       "4               Dynamics of Supervised Learning with \\nRestricted Training Sets \\nA.C.C. Coolen \\nDept of Mathematics \\nKing's College London \\nStrand, London WC2R 2LS, UK \\ntcoolen @mth.kcl.ac.uk \\nD. Saad \\nNeu...  \n",
       "5               Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversi...  \n",
       "6               612 \\nConstrained Differential Optimization \\nJohn C. Platt \\nAlan H. Ban' \\nCalifornia Institute of Technology, Pasadena, CA 91125 \\nAbstract \\nMany optimization models of neural networks need co...  \n",
       "7               When Will a Genetic Algorithm \\nOutperform Hill Climbing? \\nMelanie Mitchell \\nSanta Fe Institute \\n1660 Old Pecos Trail, Suite A \\nSanta Fe, NM 87501 \\nJohn H. Holland \\nDept. of Psychology \\nUni...  \n",
       "8               Approximating Posterior Distributions \\nin Belief Networks using Mixtures \\nChristopher M. Bishop \\nNeil Lawrence \\nNeural Computing Research Group \\nDept. Computer Science & Applied Mathematics \\...  \n",
       "9               Development of Orientation and Ocular \\nDominance Columns in Infant Macaques \\nKlaus Obermayer \\nHoward Hughes Medical Institute \\nSMk-Institute \\nLa Jolla, CA 92037 \\nLynne Kiorpes \\nCenter for N...  \n",
       "10              82 \\nSIMULATIONS SUGGEST \\nINFORMATION PROCESSING ROLES \\nFOR THE DIVERSE CURRENTS IN \\nHIPPOCAMPAL NEURONS \\nLyle J. Borg-Graham \\nHarvard-MIT Division of Health Sciences and Technology and \\nCen...  \n",
       "11              Finite State Automata that Recurrent \\nCascade-Correlation Cannot Represent \\nStefan C. Kremer \\nDepartment of Computing Science \\nUniversity of Alberta \\nEdmonton, Alberta, CANADA T6H 5B5 \\nAbstr...  \n",
       "12              Prediction of Beta Sheets in Proteins \\nAnders Krogh \\nThe Sanger Centre \\nHinxton, Carnbs CB10 1RQ, UK. \\nEmail: krogh@sanger. ac.uk \\nSoren Kamaric Riis \\nElectronics Institute, Building 349 \\nT...  \n",
       "13              266 Zemel, Mozer and Hinton \\nTRAFFIC: Recognizing Objects Using \\nHierarchical Reference Frame Transformations \\nRichard S. Zemel \\nComputer Science Dept. \\nUniversity of Toronto \\nToronto, ONT M...  \n",
       "14              Integrated Modeling and Control \\nBased on Reinforcement Learning \\nand Dynamic Programming \\nRichard S. Sutton \\nGTE Laboratories Incorporated \\nWaltham, MA 02254 \\nAbstract \\nThis is a summary o...  \n",
       "15              524 Fahlman and Lebiere \\nThe Cascade-Correlation Learning Architecture \\nScott E. Fahlman and Christian Lebiere \\nSchool of Computer Science \\nCarnegie-Mellon University \\nPittsburgh, PA 15213 \\n...  \n",
       "16              Single Transistor Learning Synapses \\nPaul Hasler, Chris Diorio, Bradley A. Minch, Carver Mead \\nCalifornia Institute of Technology \\nPasadena, CA 91125 \\n(SlS) 95- 2S12 \\npaul@hobiecat.pcmp.calt...  \n",
       "17              A Connectionist Learning Approach to Analyzing \\nLinguistic Stress \\nPrahlad Gupta \\nDepartment of Psychology \\nCarnegie Mellon University \\nPittsburgh, PA 15213 \\nDavid S. Touretzky \\nSchool of C...  \n",
       "18              Mapping a manifold of perceptual observations \\nJoshua B. Tenenbaum \\nDepartment of Brain and Cognitive Sciences \\nMassachusetts Institute of Technology, Cambridge, MA 02139 \\nj bt @psyche. mi t. ...  \n",
       "19              Using Feedforward Neural Networks to \\nMonitor Alertness from Changes in EEG \\nCorrelation and Coherence \\nScott Makeig \\nNaval Health Research Center, P.O. Box 85122 \\nSan Diego, CA 92186-5122 \\n...  \n",
       "20              Balancing between bagging and bumping \\nTom Heskes \\nRWCP Novel Functions SNN Laboratory,* University of Nijmegen \\nGeert Grooteplein 21, 6525 EZ Nijmegen, The Netherlands \\ntom@mbfys.kun.nl \\nAbs...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topic_df.groupby('Dominant Topic').apply(lambda topic_set: (topic_set.sort_values(by=['Contribution %'], \n",
    "                                                                                         ascending=False)\n",
    "                                                                             .iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Topics for New Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total New Papers: 4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# papers manually downloaded from NIPS 16\n",
    "# https://papers.nips.cc/book/advances-in-neural-information-processing-systems-29-2016\n",
    "\n",
    "new_paper_files = glob.glob('nips16*.txt')\n",
    "new_papers = []\n",
    "for fn in new_paper_files:\n",
    "    with open(fn, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "        data = f.read()\n",
    "        new_papers.append(data)\n",
    "              \n",
    "print('Total New Papers:', len(new_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_pipeline(documents, normalizer_fn, bigram_model):\n",
    "    norm_docs = normalizer_fn(documents)\n",
    "    norm_docs_bigrams = bigram_model[norm_docs]\n",
    "    return norm_docs_bigrams\n",
    "\n",
    "def bow_features_pipeline(tokenized_docs, dictionary):\n",
    "    paper_bow_features = [dictionary.doc2bow(text) \n",
    "                              for text in tokenized_docs]\n",
    "    return paper_bow_features\n",
    "\n",
    "norm_new_papers = text_preprocessing_pipeline(documents=new_papers, normalizer_fn=normalize_corpus, \n",
    "                                              bigram_model=bigram_model)\n",
    "norm_bow_features = bow_features_pipeline(tokenized_docs=norm_new_papers, dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cooperative', 'graphical_model', 'josip', 'djolonga', 'dept_computer', 'science', 'eth', 'zurich', 'josipd', 'inf', 'ethz', 'ch', 'stefanie', 'jegelka', 'csail', 'mit', 'stefje', 'mit_edu', 'sebastian', 'tschiatschek', 'dept_computer', 'science', 'eth', 'zurich', 'stschia', 'inf', 'ethz', 'ch', 'andreas', 'krause']\n"
     ]
    }
   ],
   "source": [
    "print(norm_new_papers[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (6, 1), (17, 1), (18, 1), (19, 1), (25, 1), (31, 2), (36, 2), (38, 1), (39, 17), (41, 3), (43, 1), (45, 1), (49, 2), (50, 4), (51, 1), (52, 2), (54, 1), (60, 1), (65, 1), (66, 3), (68, 7), (71, 8), (76, 4), (77, 2), (87, 1), (88, 3), (105, 1), (106, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(norm_bow_features[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_predictions(topic_model, corpus, topn=3):\n",
    "    topic_predictions = topic_model[corpus]\n",
    "    best_topics = [[(topic, round(wt, 3)) \n",
    "                        for topic, wt in sorted(topic_predictions[i], \n",
    "                                                key=lambda row: -row[1])[:topn]] \n",
    "                            for i in range(len(topic_predictions))]\n",
    "    return best_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(7, 0.241), (4, 0.199)],\n",
       " [(13, 0.293), (4, 0.248)],\n",
       " [(12, 0.238), (9, 0.113)],\n",
       " [(2, 0.263), (12, 0.145)]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_preds = get_topic_predictions(topic_model=best_lda_model, \n",
    "                                    corpus=norm_bow_features, topn=2)\n",
    "topic_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df['Papers'] = range(1, len(new_papers)+1)\n",
    "results_df['Dominant Topics'] = [[topic_num+1 for topic_num, wt in item] for item in topic_preds]\n",
    "res = results_df.set_index(['Papers'])['Dominant Topics'].apply(pd.Series).stack().reset_index(level=1, drop=True)\n",
    "results_df = pd.DataFrame({'Dominant Topics': res.values}, index=res.index)\n",
    "results_df['Contribution %'] = [topic_wt for topic_list in \n",
    "                                        [[round(wt*100, 2) \n",
    "                                              for topic_num, wt in item] \n",
    "                                                 for item in topic_preds] \n",
    "                                    for topic_wt in topic_list]\n",
    "\n",
    "results_df['Topic Desc'] = [topics_df.iloc[t-1]['Terms per Topic'] for t in results_df['Dominant Topics'].values]\n",
    "results_df['Paper Desc'] = [new_papers[i-1][:200] for i in results_df.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topics</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper Desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Papers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, entropy</td>\n",
       "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer Science, ETH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded</td>\n",
       "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer Science, ETH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>29.3</td>\n",
       "      <td>control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration</td>\n",
       "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York, NY 10011\\na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>24.8</td>\n",
       "      <td>bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded</td>\n",
       "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York, NY 10011\\na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>23.8</td>\n",
       "      <td>image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location</td>\n",
       "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\nUniversit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>11.3</td>\n",
       "      <td>neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate</td>\n",
       "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\nUniversit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>26.3</td>\n",
       "      <td>word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level</td>\n",
       "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute of Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>14.5</td>\n",
       "      <td>image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location</td>\n",
       "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute of Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant Topics  Contribution %  \\\n",
       "Papers                                    \n",
       "1                     8            24.1   \n",
       "1                     5            19.9   \n",
       "2                    14            29.3   \n",
       "2                     5            24.8   \n",
       "3                    13            23.8   \n",
       "3                    10            11.3   \n",
       "4                     3            26.3   \n",
       "4                    13            14.5   \n",
       "\n",
       "                                                                                                                                                                                                      Topic Desc  \\\n",
       "Papers                                                                                                                                                                                                             \n",
       "1       distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, log, likelihood, sample, component, expert, em, posterior, probabilistic, estimation, entropy   \n",
       "1                    bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded   \n",
       "2                        control, action, state, policy, environment, controller, reinforcement_learning, task, optimal, robot, goal, step, reward, td, agent, adaptive, cost, reinforcement, trial, exploration   \n",
       "2                    bound, theorem, class, probability, size, threshold, proof, polynomial, theory, complexity, loss, approximation, linear, assume, definition, defined, hypothesis, constant, define, bounded   \n",
       "3                                         image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location   \n",
       "3                       neuron, cell, spike, synaptic, activity, response, stimulus, firing, synapsis, et_al, effect, neural, neuronal, current, pattern, inhibitory, connection, brain, simulation, firing_rate   \n",
       "4                       word, recognition, training, speech, character, context, hmm, letter, mlp, speaker, feature, frame, trained, speech_recognition, phoneme, experiment, hybrid, segmentation, vowel, level   \n",
       "4                                         image, object, feature, pixel, face, view, recognition, representation, shape, scale, part, visual, region, position, scene, surface, vision, frame, texture, location   \n",
       "\n",
       "                                                                                                                                                                                                              Paper Desc  \n",
       "Papers                                                                                                                                                                                                                    \n",
       "1       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer Science, ETH   \n",
       "1       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich ¨\\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer Science, ETH   \n",
       "2       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York, NY 10011\\na  \n",
       "2       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York, NY 10011\\na  \n",
       "3         Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\nUniversit  \n",
       "3         Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Sümbül\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\nUniversit  \n",
       "4           Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute of Tech  \n",
       "4           Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute of Tech  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 300)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
