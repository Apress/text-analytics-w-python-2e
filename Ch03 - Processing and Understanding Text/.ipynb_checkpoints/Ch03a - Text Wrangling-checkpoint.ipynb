{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'content=\"Ebookmaker 0.4.0a5 by Marcello Perathoner &lt;webmaster@gutenberg.org&gt;\" name=\"generator\"/>\\r\\n</head>\\r\\n  <body><p id=\"id00000\">Project Gutenberg EBook The Bible, King James, Book 1: Genesis</p>\\r\\n\\r\\n<p id=\"id00001\">Copyright laws are changing all over the world. Be sure to check the\\r\\ncopyright laws for your country before downloading or redistributing\\r\\nthis or any other Project Gutenberg eBook.</p>\\r\\n\\r\\n<p id=\"id00002\">This header should be the first thing seen when viewing this Project\\r\\nGutenberg file.  Please do not remove it.  Do not change or edit the\\r\\nheader without written permission.</p>\\r\\n\\r\\n<p id=\"id00003\">Please read the \"legal small print,\" and other information about the\\r\\neBook and Project Gutenberg at the bottom of this file.  Included is\\r\\nimportant information about your specific rights and restrictions in\\r\\nhow the file may be used.  You can also find out about how to make a\\r\\ndonation to Project Gutenberg, and how to get involved.</p>\\r\\n\\r\\n<p id=\"id00004\" style=\"margin-top: 2em\">**Welcome To The World of F'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "data = requests.get('http://www.gutenberg.org/cache/epub/8001/pg8001.html')\n",
    "content = data.content\n",
    "print(content[1163:2200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** START OF THE PROJECT GUTENBERG EBOOK, THE BIBLE, KING JAMES, BOOK 1***\n",
      "This eBook was produced by David Widger\n",
      "with the help of Derek Andrew's text from January 1992\n",
      "and the work of Bryan Taylor in November 2002.\n",
      "Book 01        Genesis\n",
      "01:001:001 In the beginning God created the heaven and the earth.\n",
      "01:001:002 And the earth was without form, and void; and darkness was\n",
      "           upon the face of the deep. And the Spirit of God moved upon\n",
      "           the face of the waters.\n",
      "01:001:003 And God said, Let there be light: and there was light.\n",
      "01:001:004 And God saw the light, that it was good: and God divided the\n",
      "           light from the darkness.\n",
      "01:001:005 And God called the light Day, and the darkness he called\n",
      "           Night. And the evening and the morning were the first day.\n",
      "01:001:006 And God said, Let there be a firmament in the midst of the\n",
      "           waters,\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text\n",
    "\n",
    "clean_content = strip_html_tags(content)\n",
    "print(clean_content[1163:2045])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "# loading text corpora\n",
    "alice = gutenberg.raw(fileids='carroll-alice.txt')\n",
    "sample_text = (\"US unveils world's most powerful supercomputer, beats China. \" \n",
    "               \"The US has unveiled the world's most powerful supercomputer called 'Summit', \" \n",
    "               \"beating the previous record-holder China's Sunway TaihuLight. With a peak performance \"\n",
    "               \"of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, \"\n",
    "               \"which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, \"\n",
    "               \"which reportedly take up the size of two tennis courts.\")\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144395"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total characters in Alice in Wonderland\n",
    "len(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I. Down the Rabbit-Hole\\n\\nAlice was\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 100 characters in the corpus\n",
    "alice[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in sample_text: 4\n",
      "Sample text sentences :-\n",
      "[\"US unveils world's most powerful supercomputer, beats China.\"\n",
      " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\"\n",
      " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.'\n",
      " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']\n",
      "\n",
      "Total sentences in alice: 1625\n",
      "First 5 sentences in alice:-\n",
      "[\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I.\"\n",
      " \"Down the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into the\\nbook her sister was reading, but it had no pictures or conversations in\\nit, 'and what is the use of a book,' thought Alice 'without pictures or\\nconversation?'\"\n",
      " 'So she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure\\nof making a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.'\n",
      " \"There was nothing so VERY remarkable in that; nor did Alice think it so\\nVERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\"\n",
      " 'Oh dear!']\n"
     ]
    }
   ],
   "source": [
    "default_st = nltk.sent_tokenize\n",
    "alice_sentences = default_st(text=alice)\n",
    "sample_sentences = default_st(text=sample_text)\n",
    "\n",
    "print('Total sentences in sample_text:', len(sample_sentences))\n",
    "print('Sample text sentences :-')\n",
    "print(np.array(sample_sentences))\n",
    "\n",
    "print('\\nTotal sentences in alice:', len(alice_sentences))\n",
    "print('First 5 sentences in alice:-')\n",
    "print(np.array(alice_sentences[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other languages sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157171\n",
      " \n",
      "Wiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sit\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import europarl_raw\n",
    "\n",
    "german_text = europarl_raw.german.raw(fileids='ep-00-01-17.de')\n",
    "# Total characters in the corpus\n",
    "print(len(german_text))\n",
    "# First 100 characters in the corpus\n",
    "print(german_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default sentence tokenizer \n",
    "german_sentences_def = default_st(text=german_text, language='german')\n",
    "\n",
    "# loading german text tokenizer into a PunktSentenceTokenizer instance  \n",
    "german_tokenizer = nltk.data.load(resource_url='tokenizers/punkt/german.pickle')\n",
    "german_sentences = german_tokenizer.tokenize(german_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.punkt.PunktSentenceTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "# verify the type of german_tokenizer\n",
    "# should be PunktSentenceTokenizer\n",
    "print(type(german_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if results of both tokenizers match \n",
    "# should be True\n",
    "print(german_sentences_def == german_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' \\nWiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen , wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe , daß Sie schöne Ferien hatten .'\n",
      " 'Wie Sie feststellen konnten , ist der gefürchtete \" Millenium-Bug \" nicht eingetreten .'\n",
      " 'Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden .'\n",
      " 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen .'\n",
      " 'Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen - , allen Opfern der Stürme , insbesondere in den verschiedenen Ländern der Europäischen Union , in einer Schweigeminute zu gedenken .']\n"
     ]
    }
   ],
   "source": [
    "# print first 5 sentences of the corpus\n",
    "print(np.array(german_sentences[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PunktSentenceTokenizer for sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"US unveils world's most powerful supercomputer, beats China.\"\n",
      " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\"\n",
      " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.'\n",
      " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']\n"
     ]
    }
   ],
   "source": [
    "punkt_st = nltk.tokenize.PunktSentenceTokenizer()\n",
    "sample_sentences = punkt_st.tokenize(sample_text)\n",
    "print(np.array(sample_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RegexpTokenizer for sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"US unveils world's most powerful supercomputer, beats China.\"\n",
      " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\"\n",
      " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.'\n",
      " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_TOKENS_PATTERN = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "regex_st = nltk.tokenize.RegexpTokenizer(\n",
    "            pattern=SENTENCE_TOKENS_PATTERN,\n",
    "            gaps=True)\n",
    "sample_sentences = regex_st.tokenize(sample_text)\n",
    "print(np.array(sample_sentences)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the',\n",
       "       'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight',\n",
       "       '.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_wt = nltk.word_tokenize\n",
    "words = default_wt(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treebank word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the',\n",
       "       'previous', 'record-holder', 'China', \"'s\", 'Sunway',\n",
       "       'TaihuLight.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank_wt = nltk.TreebankWordTokenizer()\n",
    "words = treebank_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TokTok Word Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'\", 'Summit', \"'\", ',', 'beating',\n",
       "       'the', 'previous', 'record-holder', 'China', \"'\", 's', 'Sunway',\n",
       "       'TaihuLight.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "words = tokenizer.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regexp word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', 's', 'most', 'powerful', 'supercomputer',\n",
       "       'beats', 'China', 'The', 'US', 'has', 'unveiled', 'the', 'world',\n",
       "       's', 'most', 'powerful', 'supercomputer', 'called', 'Summit',\n",
       "       'beating', 'the', 'previous', 'record', 'holder', 'China', 's',\n",
       "       'Sunway', 'TaihuLight', 'With', 'a', 'peak', 'performance', 'of',\n",
       "       '200', '000', 'trillion', 'calculations', 'per', 'second', 'it',\n",
       "       'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight',\n",
       "       'which', 'is', 'capable', 'of', '93', '000', 'trillion',\n",
       "       'calculations', 'per', 'second', 'Summit', 'has', '4', '608',\n",
       "       'servers', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts'], dtype='<U13')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_PATTERN = r'\\w+'        \n",
    "regex_wt = nltk.RegexpTokenizer(pattern=TOKEN_PATTERN,\n",
    "                                gaps=False)\n",
    "words = regex_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', \"world's\", 'most', 'powerful', 'supercomputer,',\n",
       "       'beats', 'China.', 'The', 'US', 'has', 'unveiled', 'the',\n",
       "       \"world's\", 'most', 'powerful', 'supercomputer', 'called',\n",
       "       \"'Summit',\", 'beating', 'the', 'previous', 'record-holder',\n",
       "       \"China's\", 'Sunway', 'TaihuLight.', 'With', 'a', 'peak',\n",
       "       'performance', 'of', '200,000', 'trillion', 'calculations', 'per',\n",
       "       'second,', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as',\n",
       "       'Sunway', 'TaihuLight,', 'which', 'is', 'capable', 'of', '93,000',\n",
       "       'trillion', 'calculations', 'per', 'second.', 'Summit', 'has',\n",
       "       '4,608', 'servers,', 'which', 'reportedly', 'take', 'up', 'the',\n",
       "       'size', 'of', 'two', 'tennis', 'courts.'], dtype='<U14')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAP_PATTERN = r'\\s+'        \n",
    "regex_wt = nltk.RegexpTokenizer(pattern=GAP_PATTERN,\n",
    "                                gaps=True)\n",
    "words = regex_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (3, 10), (11, 18), (19, 23), (24, 32), (33, 47), (48, 53), (54, 60), (61, 64), (65, 67), (68, 71), (72, 80), (81, 84), (85, 92), (93, 97), (98, 106), (107, 120), (121, 127), (128, 137), (138, 145), (146, 149), (150, 158), (159, 172), (173, 180), (181, 187), (188, 199), (200, 204), (205, 206), (207, 211), (212, 223), (224, 226), (227, 234), (235, 243), (244, 256), (257, 260), (261, 268), (269, 271), (272, 274), (275, 279), (280, 285), (286, 288), (289, 293), (294, 296), (297, 303), (304, 315), (316, 321), (322, 324), (325, 332), (333, 335), (336, 342), (343, 351), (352, 364), (365, 368), (369, 376), (377, 383), (384, 387), (388, 393), (394, 402), (403, 408), (409, 419), (420, 424), (425, 427), (428, 431), (432, 436), (437, 439), (440, 443), (444, 450), (451, 458)]\n",
      "['US' 'unveils' \"world's\" 'most' 'powerful' 'supercomputer,' 'beats'\n",
      " 'China.' 'The' 'US' 'has' 'unveiled' 'the' \"world's\" 'most' 'powerful'\n",
      " 'supercomputer' 'called' \"'Summit',\" 'beating' 'the' 'previous'\n",
      " 'record-holder' \"China's\" 'Sunway' 'TaihuLight.' 'With' 'a' 'peak'\n",
      " 'performance' 'of' '200,000' 'trillion' 'calculations' 'per' 'second,'\n",
      " 'it' 'is' 'over' 'twice' 'as' 'fast' 'as' 'Sunway' 'TaihuLight,' 'which'\n",
      " 'is' 'capable' 'of' '93,000' 'trillion' 'calculations' 'per' 'second.'\n",
      " 'Summit' 'has' '4,608' 'servers,' 'which' 'reportedly' 'take' 'up' 'the'\n",
      " 'size' 'of' 'two' 'tennis' 'courts.']\n"
     ]
    }
   ],
   "source": [
    "word_indices = list(regex_wt.span_tokenize(sample_text))\n",
    "print(word_indices)\n",
    "print(np.array([sample_text[start:end] for start, end in word_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived regex tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'\", 's', 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'\", 'Summit', \"',\", 'beating', 'the',\n",
       "       'previous', 'record', '-', 'holder', 'China', \"'\", 's', 'Sunway',\n",
       "       'TaihuLight', '.', 'With', 'a', 'peak', 'performance', 'of', '200',\n",
       "       ',', '000', 'trillion', 'calculations', 'per', 'second', ',', 'it',\n",
       "       'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight',\n",
       "       ',', 'which', 'is', 'capable', 'of', '93', ',', '000', 'trillion',\n",
       "       'calculations', 'per', 'second', '.', 'Summit', 'has', '4', ',',\n",
       "       '608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the',\n",
       "       'size', 'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunkt_wt = nltk.WordPunctTokenizer()\n",
    "words = wordpunkt_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', \"world's\", 'most', 'powerful', 'supercomputer,',\n",
       "       'beats', 'China.', 'The', 'US', 'has', 'unveiled', 'the',\n",
       "       \"world's\", 'most', 'powerful', 'supercomputer', 'called',\n",
       "       \"'Summit',\", 'beating', 'the', 'previous', 'record-holder',\n",
       "       \"China's\", 'Sunway', 'TaihuLight.', 'With', 'a', 'peak',\n",
       "       'performance', 'of', '200,000', 'trillion', 'calculations', 'per',\n",
       "       'second,', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as',\n",
       "       'Sunway', 'TaihuLight,', 'which', 'is', 'capable', 'of', '93,000',\n",
       "       'trillion', 'calculations', 'per', 'second.', 'Summit', 'has',\n",
       "       '4,608', 'servers,', 'which', 'reportedly', 'take', 'up', 'the',\n",
       "       'size', 'of', 'two', 'tennis', 'courts.'], dtype='<U14')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitespace_wt = nltk.WhitespaceTokenizer()\n",
    "words = whitespace_wt.tokenize(sample_text)\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Tokenizers with NLTK and spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['US', 'unveils', 'world', \"'s\", 'most', 'powerful', 'supercomputer', ',', 'beats', 'China', '.']),\n",
       "       list(['The', 'US', 'has', 'unveiled', 'the', 'world', \"'s\", 'most', 'powerful', 'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the', 'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight', '.']),\n",
       "       list(['With', 'a', 'peak', 'performance', 'of', '200,000', 'trillion', 'calculations', 'per', 'second', ',', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',', 'which', 'is', 'capable', 'of', '93,000', 'trillion', 'calculations', 'per', 'second', '.']),\n",
       "       list(['Summit', 'has', '4,608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size', 'of', 'two', 'tennis', 'courts', '.'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    word_tokens = [nltk.word_tokenize(sentence) for sentence in sentences] \n",
    "    return word_tokens\n",
    "\n",
    "sents = tokenize_text(sample_text)\n",
    "np.array(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the',\n",
       "       'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight',\n",
       "       '.', 'With', 'a', 'peak', 'performance', 'of', '200,000',\n",
       "       'trillion', 'calculations', 'per', 'second', ',', 'it', 'is',\n",
       "       'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',',\n",
       "       'which', 'is', 'capable', 'of', '93,000', 'trillion',\n",
       "       'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608',\n",
       "       'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size',\n",
       "       'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word for sentence in sents for word in sentence]\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core', parse = True, tag=True, entity=True)\n",
    "\n",
    "text_spacy = nlp(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([US unveils world's most powerful supercomputer, beats China.,\n",
       "       The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.,\n",
       "       With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.,\n",
       "       Summit has 4,608 servers, which reportedly take up the size of two tennis courts.],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = np.array(list(text_spacy.sents))\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['US', 'unveils', 'world', \"'s\", 'most', 'powerful', 'supercomputer', ',', 'beats', 'China', '.']),\n",
       "       list(['The', 'US', 'has', 'unveiled', 'the', 'world', \"'s\", 'most', 'powerful', 'supercomputer', 'called', \"'\", 'Summit', \"'\", ',', 'beating', 'the', 'previous', 'record', '-', 'holder', 'China', \"'s\", 'Sunway', 'TaihuLight', '.']),\n",
       "       list(['With', 'a', 'peak', 'performance', 'of', '200,000', 'trillion', 'calculations', 'per', 'second', ',', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',', 'which', 'is', 'capable', 'of', '93,000', 'trillion', 'calculations', 'per', 'second', '.']),\n",
       "       list(['Summit', 'has', '4,608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size', 'of', 'two', 'tennis', 'courts', '.'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_words = [[word.text for word in sent] for sent in sents]\n",
    "np.array(sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'unveils', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has',\n",
       "       'unveiled', 'the', 'world', \"'s\", 'most', 'powerful',\n",
       "       'supercomputer', 'called', \"'\", 'Summit', \"'\", ',', 'beating',\n",
       "       'the', 'previous', 'record', '-', 'holder', 'China', \"'s\",\n",
       "       'Sunway', 'TaihuLight', '.', 'With', 'a', 'peak', 'performance',\n",
       "       'of', '200,000', 'trillion', 'calculations', 'per', 'second', ',',\n",
       "       'it', 'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway',\n",
       "       'TaihuLight', ',', 'which', 'is', 'capable', 'of', '93,000',\n",
       "       'trillion', 'calculations', 'per', 'second', '.', 'Summit', 'has',\n",
       "       '4,608', 'servers', ',', 'which', 'reportedly', 'take', 'up',\n",
       "       'the', 'size', 'of', 'two', 'tennis', 'courts', '.'], dtype='<U13')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word.text for word in text_spacy]\n",
    "np.array(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Accented Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Accented text'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "remove_accented_chars('Sómě Áccěntěd těxt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contractions import CONTRACTION_MAP\n",
    "import re\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You all cannot expand contractions I would think'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(\"Y'all can't expand contractions I'd think\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@!\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox jumped over the big dog'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The quick brown fox jumped over The Big Dog'\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE QUICK BROWN FOX JUMPED OVER THE BIG DOG'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Quick Brown Fox Jumped Over The Big Dog'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting repeating characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Step: 4 Word: finaly\n",
      "Final word: finaly\n"
     ]
    }
   ],
   "source": [
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    "\n",
    "while True:\n",
    "    # remove one repeated character\n",
    "    new_word = repeat_pattern.sub(match_substitution,\n",
    "                                  old_word)\n",
    "    if new_word != old_word:\n",
    "         print('Step: {} Word: {}'.format(step, new_word))\n",
    "         step += 1 # update step\n",
    "         # update old word to last substituted state\n",
    "         old_word = new_word  \n",
    "         continue\n",
    "    else:\n",
    "         print(\"Final word:\", new_word)\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Final correct word: finally\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    " \n",
    "while True:\n",
    "    # check for semantically correct word\n",
    "    if wordnet.synsets(old_word):\n",
    "        print(\"Final correct word:\", old_word)\n",
    "        break\n",
    "    # remove one repeated character\n",
    "    new_word = repeat_pattern.sub(match_substitution,\n",
    "                                  old_word)\n",
    "    if new_word != old_word:\n",
    "        print('Step: {} Word: {}'.format(step, new_word))\n",
    "        step += 1 # update step\n",
    "        # update old word to last substituted state\n",
    "        old_word = new_word  \n",
    "        continue\n",
    "    else:\n",
    "        print(\"Final word:\", new_word)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def remove_repeated_characters(tokens):\n",
    "    repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "    match_substitution = r'\\1\\2\\3'\n",
    "    def replace(old_word):\n",
    "        if wordnet.synsets(old_word):\n",
    "            return old_word\n",
    "        new_word = repeat_pattern.sub(match_substitution, old_word)\n",
    "        return replace(new_word) if new_word != old_word else new_word\n",
    "            \n",
    "    correct_tokens = [replace(word) for word in tokens]\n",
    "    return correct_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My school is really amazing'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = 'My schooool is realllllyyy amaaazingggg'\n",
    "correct_tokens = remove_repeated_characters(nltk.word_tokenize(sample_sentence))\n",
    "' '.join(correct_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 80030),\n",
       " ('of', 40025),\n",
       " ('and', 38313),\n",
       " ('to', 28766),\n",
       " ('in', 22050),\n",
       " ('a', 21155),\n",
       " ('that', 12512),\n",
       " ('he', 12401),\n",
       " ('was', 11410),\n",
       " ('it', 10681)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, collections\n",
    "\n",
    "def tokens(text): \n",
    "    \"\"\"\n",
    "    Get all words from the corpus\n",
    "    \"\"\"\n",
    "    return re.findall('[a-z]+', text.lower()) \n",
    "\n",
    "WORDS = tokens(open('big.txt').read())\n",
    "WORD_COUNTS = collections.Counter(WORDS)\n",
    "# top 10 words in corpus\n",
    "WORD_COUNTS.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits0(word): \n",
    "    \"\"\"\n",
    "    Return all strings that are zero edits away \n",
    "    from the input word (i.e., the word itself).\n",
    "    \"\"\"\n",
    "    return {word}\n",
    "\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"\"\"\n",
    "    Return all strings that are one edit away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    def splits(word):\n",
    "        \"\"\"\n",
    "        Return a list of all possible (first, rest) pairs \n",
    "        that the input word is made of.\n",
    "        \"\"\"\n",
    "        return [(word[:i], word[i:]) \n",
    "                for i in range(len(word)+1)]\n",
    "                \n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "\n",
    "def edits2(word):\n",
    "    \"\"\"Return all strings that are two edits away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"\"\"\n",
    "    Return the subset of words that are actually \n",
    "    in our WORD_COUNTS dictionary.\n",
    "    \"\"\"\n",
    "    return {w for w in words if w in WORD_COUNTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fianlly'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input word\n",
    "In [409]: word = 'fianlly'\n",
    "\n",
    "# zero edit distance from input word\n",
    "edits0(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns null set since it is not a valid word\n",
    "known(edits0(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afianlly',\n",
       " 'aianlly',\n",
       " 'bfianlly',\n",
       " 'bianlly',\n",
       " 'cfianlly',\n",
       " 'cianlly',\n",
       " 'dfianlly',\n",
       " 'dianlly',\n",
       " 'efianlly',\n",
       " 'eianlly',\n",
       " 'faanlly',\n",
       " 'faianlly',\n",
       " 'fainlly',\n",
       " 'fanlly',\n",
       " 'fbanlly',\n",
       " 'fbianlly',\n",
       " 'fcanlly',\n",
       " 'fcianlly',\n",
       " 'fdanlly',\n",
       " 'fdianlly',\n",
       " 'feanlly',\n",
       " 'feianlly',\n",
       " 'ffanlly',\n",
       " 'ffianlly',\n",
       " 'fganlly',\n",
       " 'fgianlly',\n",
       " 'fhanlly',\n",
       " 'fhianlly',\n",
       " 'fiaally',\n",
       " 'fiaanlly',\n",
       " 'fiablly',\n",
       " 'fiabnlly',\n",
       " 'fiaclly',\n",
       " 'fiacnlly',\n",
       " 'fiadlly',\n",
       " 'fiadnlly',\n",
       " 'fiaelly',\n",
       " 'fiaenlly',\n",
       " 'fiaflly',\n",
       " 'fiafnlly',\n",
       " 'fiaglly',\n",
       " 'fiagnlly',\n",
       " 'fiahlly',\n",
       " 'fiahnlly',\n",
       " 'fiailly',\n",
       " 'fiainlly',\n",
       " 'fiajlly',\n",
       " 'fiajnlly',\n",
       " 'fiaklly',\n",
       " 'fiaknlly',\n",
       " 'fiallly',\n",
       " 'fially',\n",
       " 'fialnlly',\n",
       " 'fialnly',\n",
       " 'fiamlly',\n",
       " 'fiamnlly',\n",
       " 'fianally',\n",
       " 'fianaly',\n",
       " 'fianblly',\n",
       " 'fianbly',\n",
       " 'fianclly',\n",
       " 'fiancly',\n",
       " 'fiandlly',\n",
       " 'fiandly',\n",
       " 'fianelly',\n",
       " 'fianely',\n",
       " 'fianflly',\n",
       " 'fianfly',\n",
       " 'fianglly',\n",
       " 'fiangly',\n",
       " 'fianhlly',\n",
       " 'fianhly',\n",
       " 'fianilly',\n",
       " 'fianily',\n",
       " 'fianjlly',\n",
       " 'fianjly',\n",
       " 'fianklly',\n",
       " 'fiankly',\n",
       " 'fianlaly',\n",
       " 'fianlay',\n",
       " 'fianlbly',\n",
       " 'fianlby',\n",
       " 'fianlcly',\n",
       " 'fianlcy',\n",
       " 'fianldly',\n",
       " 'fianldy',\n",
       " 'fianlely',\n",
       " 'fianley',\n",
       " 'fianlfly',\n",
       " 'fianlfy',\n",
       " 'fianlgly',\n",
       " 'fianlgy',\n",
       " 'fianlhly',\n",
       " 'fianlhy',\n",
       " 'fianlily',\n",
       " 'fianliy',\n",
       " 'fianljly',\n",
       " 'fianljy',\n",
       " 'fianlkly',\n",
       " 'fianlky',\n",
       " 'fianll',\n",
       " 'fianlla',\n",
       " 'fianllay',\n",
       " 'fianllb',\n",
       " 'fianllby',\n",
       " 'fianllc',\n",
       " 'fianllcy',\n",
       " 'fianlld',\n",
       " 'fianlldy',\n",
       " 'fianlle',\n",
       " 'fianlley',\n",
       " 'fianllf',\n",
       " 'fianllfy',\n",
       " 'fianllg',\n",
       " 'fianllgy',\n",
       " 'fianllh',\n",
       " 'fianllhy',\n",
       " 'fianlli',\n",
       " 'fianlliy',\n",
       " 'fianllj',\n",
       " 'fianlljy',\n",
       " 'fianllk',\n",
       " 'fianllky',\n",
       " 'fianlll',\n",
       " 'fianllly',\n",
       " 'fianllm',\n",
       " 'fianllmy',\n",
       " 'fianlln',\n",
       " 'fianllny',\n",
       " 'fianllo',\n",
       " 'fianlloy',\n",
       " 'fianllp',\n",
       " 'fianllpy',\n",
       " 'fianllq',\n",
       " 'fianllqy',\n",
       " 'fianllr',\n",
       " 'fianllry',\n",
       " 'fianlls',\n",
       " 'fianllsy',\n",
       " 'fianllt',\n",
       " 'fianllty',\n",
       " 'fianllu',\n",
       " 'fianlluy',\n",
       " 'fianllv',\n",
       " 'fianllvy',\n",
       " 'fianllw',\n",
       " 'fianllwy',\n",
       " 'fianllx',\n",
       " 'fianllxy',\n",
       " 'fianlly',\n",
       " 'fianllya',\n",
       " 'fianllyb',\n",
       " 'fianllyc',\n",
       " 'fianllyd',\n",
       " 'fianllye',\n",
       " 'fianllyf',\n",
       " 'fianllyg',\n",
       " 'fianllyh',\n",
       " 'fianllyi',\n",
       " 'fianllyj',\n",
       " 'fianllyk',\n",
       " 'fianllyl',\n",
       " 'fianllym',\n",
       " 'fianllyn',\n",
       " 'fianllyo',\n",
       " 'fianllyp',\n",
       " 'fianllyq',\n",
       " 'fianllyr',\n",
       " 'fianllys',\n",
       " 'fianllyt',\n",
       " 'fianllyu',\n",
       " 'fianllyv',\n",
       " 'fianllyw',\n",
       " 'fianllyx',\n",
       " 'fianllyy',\n",
       " 'fianllyz',\n",
       " 'fianllz',\n",
       " 'fianllzy',\n",
       " 'fianlmly',\n",
       " 'fianlmy',\n",
       " 'fianlnly',\n",
       " 'fianlny',\n",
       " 'fianloly',\n",
       " 'fianloy',\n",
       " 'fianlply',\n",
       " 'fianlpy',\n",
       " 'fianlqly',\n",
       " 'fianlqy',\n",
       " 'fianlrly',\n",
       " 'fianlry',\n",
       " 'fianlsly',\n",
       " 'fianlsy',\n",
       " 'fianltly',\n",
       " 'fianlty',\n",
       " 'fianluly',\n",
       " 'fianluy',\n",
       " 'fianlvly',\n",
       " 'fianlvy',\n",
       " 'fianlwly',\n",
       " 'fianlwy',\n",
       " 'fianlxly',\n",
       " 'fianlxy',\n",
       " 'fianly',\n",
       " 'fianlyl',\n",
       " 'fianlyly',\n",
       " 'fianlyy',\n",
       " 'fianlzly',\n",
       " 'fianlzy',\n",
       " 'fianmlly',\n",
       " 'fianmly',\n",
       " 'fiannlly',\n",
       " 'fiannly',\n",
       " 'fianolly',\n",
       " 'fianoly',\n",
       " 'fianplly',\n",
       " 'fianply',\n",
       " 'fianqlly',\n",
       " 'fianqly',\n",
       " 'fianrlly',\n",
       " 'fianrly',\n",
       " 'fianslly',\n",
       " 'fiansly',\n",
       " 'fiantlly',\n",
       " 'fiantly',\n",
       " 'fianully',\n",
       " 'fianuly',\n",
       " 'fianvlly',\n",
       " 'fianvly',\n",
       " 'fianwlly',\n",
       " 'fianwly',\n",
       " 'fianxlly',\n",
       " 'fianxly',\n",
       " 'fianylly',\n",
       " 'fianyly',\n",
       " 'fianzlly',\n",
       " 'fianzly',\n",
       " 'fiaolly',\n",
       " 'fiaonlly',\n",
       " 'fiaplly',\n",
       " 'fiapnlly',\n",
       " 'fiaqlly',\n",
       " 'fiaqnlly',\n",
       " 'fiarlly',\n",
       " 'fiarnlly',\n",
       " 'fiaslly',\n",
       " 'fiasnlly',\n",
       " 'fiatlly',\n",
       " 'fiatnlly',\n",
       " 'fiaully',\n",
       " 'fiaunlly',\n",
       " 'fiavlly',\n",
       " 'fiavnlly',\n",
       " 'fiawlly',\n",
       " 'fiawnlly',\n",
       " 'fiaxlly',\n",
       " 'fiaxnlly',\n",
       " 'fiaylly',\n",
       " 'fiaynlly',\n",
       " 'fiazlly',\n",
       " 'fiaznlly',\n",
       " 'fibanlly',\n",
       " 'fibnlly',\n",
       " 'ficanlly',\n",
       " 'ficnlly',\n",
       " 'fidanlly',\n",
       " 'fidnlly',\n",
       " 'fieanlly',\n",
       " 'fienlly',\n",
       " 'fifanlly',\n",
       " 'fifnlly',\n",
       " 'figanlly',\n",
       " 'fignlly',\n",
       " 'fihanlly',\n",
       " 'fihnlly',\n",
       " 'fiianlly',\n",
       " 'fiinlly',\n",
       " 'fijanlly',\n",
       " 'fijnlly',\n",
       " 'fikanlly',\n",
       " 'fiknlly',\n",
       " 'filanlly',\n",
       " 'filnlly',\n",
       " 'fimanlly',\n",
       " 'fimnlly',\n",
       " 'finally',\n",
       " 'finanlly',\n",
       " 'finlly',\n",
       " 'finnlly',\n",
       " 'fioanlly',\n",
       " 'fionlly',\n",
       " 'fipanlly',\n",
       " 'fipnlly',\n",
       " 'fiqanlly',\n",
       " 'fiqnlly',\n",
       " 'firanlly',\n",
       " 'firnlly',\n",
       " 'fisanlly',\n",
       " 'fisnlly',\n",
       " 'fitanlly',\n",
       " 'fitnlly',\n",
       " 'fiuanlly',\n",
       " 'fiunlly',\n",
       " 'fivanlly',\n",
       " 'fivnlly',\n",
       " 'fiwanlly',\n",
       " 'fiwnlly',\n",
       " 'fixanlly',\n",
       " 'fixnlly',\n",
       " 'fiyanlly',\n",
       " 'fiynlly',\n",
       " 'fizanlly',\n",
       " 'fiznlly',\n",
       " 'fjanlly',\n",
       " 'fjianlly',\n",
       " 'fkanlly',\n",
       " 'fkianlly',\n",
       " 'flanlly',\n",
       " 'flianlly',\n",
       " 'fmanlly',\n",
       " 'fmianlly',\n",
       " 'fnanlly',\n",
       " 'fnianlly',\n",
       " 'foanlly',\n",
       " 'foianlly',\n",
       " 'fpanlly',\n",
       " 'fpianlly',\n",
       " 'fqanlly',\n",
       " 'fqianlly',\n",
       " 'franlly',\n",
       " 'frianlly',\n",
       " 'fsanlly',\n",
       " 'fsianlly',\n",
       " 'ftanlly',\n",
       " 'ftianlly',\n",
       " 'fuanlly',\n",
       " 'fuianlly',\n",
       " 'fvanlly',\n",
       " 'fvianlly',\n",
       " 'fwanlly',\n",
       " 'fwianlly',\n",
       " 'fxanlly',\n",
       " 'fxianlly',\n",
       " 'fyanlly',\n",
       " 'fyianlly',\n",
       " 'fzanlly',\n",
       " 'fzianlly',\n",
       " 'gfianlly',\n",
       " 'gianlly',\n",
       " 'hfianlly',\n",
       " 'hianlly',\n",
       " 'ianlly',\n",
       " 'ifanlly',\n",
       " 'ifianlly',\n",
       " 'iianlly',\n",
       " 'jfianlly',\n",
       " 'jianlly',\n",
       " 'kfianlly',\n",
       " 'kianlly',\n",
       " 'lfianlly',\n",
       " 'lianlly',\n",
       " 'mfianlly',\n",
       " 'mianlly',\n",
       " 'nfianlly',\n",
       " 'nianlly',\n",
       " 'ofianlly',\n",
       " 'oianlly',\n",
       " 'pfianlly',\n",
       " 'pianlly',\n",
       " 'qfianlly',\n",
       " 'qianlly',\n",
       " 'rfianlly',\n",
       " 'rianlly',\n",
       " 'sfianlly',\n",
       " 'sianlly',\n",
       " 'tfianlly',\n",
       " 'tianlly',\n",
       " 'ufianlly',\n",
       " 'uianlly',\n",
       " 'vfianlly',\n",
       " 'vianlly',\n",
       " 'wfianlly',\n",
       " 'wianlly',\n",
       " 'xfianlly',\n",
       " 'xianlly',\n",
       " 'yfianlly',\n",
       " 'yianlly',\n",
       " 'zfianlly',\n",
       " 'zianlly'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one edit distance from input word\n",
    "edits1(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits1(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fvikanlly',\n",
       " 'fiaqnlcly',\n",
       " 'fiaflle',\n",
       " 'afianlely',\n",
       " 'yfiynlly',\n",
       " 'fizanwly',\n",
       " 'gijanlly',\n",
       " 'fisanlluy',\n",
       " 'fcangly',\n",
       " 'fianlgyu',\n",
       " 'fyanllfy',\n",
       " 'bfiansly',\n",
       " 'vfijnlly',\n",
       " 'rifanlly',\n",
       " 'fianlqlny',\n",
       " 'fiatllyt',\n",
       " 'xfianllyj',\n",
       " 'gfianllyb',\n",
       " 'fianllyct',\n",
       " 'fiazlnly',\n",
       " 'fwanllye',\n",
       " 'fiankldly',\n",
       " 'fianlnlf',\n",
       " 'kfianlqly',\n",
       " 'fiznlxly',\n",
       " 'fbanzly',\n",
       " 'fhiaklly',\n",
       " 'yianllyr',\n",
       " 'fidarnlly',\n",
       " 'fiagly',\n",
       " 'fiunwly',\n",
       " 'fianalx',\n",
       " 'fijnfly',\n",
       " 'fhihanlly',\n",
       " 'fisanllk',\n",
       " 'wfsianlly',\n",
       " 'xiawnlly',\n",
       " 'fianllgyz',\n",
       " 'fianlaky',\n",
       " 'fianlelyq',\n",
       " 'fianrlpy',\n",
       " 'dianlely',\n",
       " 'fianlgply',\n",
       " 'ftiianlly',\n",
       " 'fimanlay',\n",
       " 'fianzply',\n",
       " 'kfijnlly',\n",
       " 'fiaknllh',\n",
       " 'fiandtly',\n",
       " 'fianltfly',\n",
       " 'dfcanlly',\n",
       " 'mimnlly',\n",
       " 'fiapnlzly',\n",
       " 'fianlpl',\n",
       " 'oianrly',\n",
       " 'fitnljly',\n",
       " 'fiaxnlbly',\n",
       " 'fqandlly',\n",
       " 'fiawyly',\n",
       " 'liancly',\n",
       " 'fiaewly',\n",
       " 'fvianll',\n",
       " 'fjiabnlly',\n",
       " 'fhxanlly',\n",
       " 'firanllyn',\n",
       " 'fiaunltly',\n",
       " 'ftanllly',\n",
       " 'fialnllky',\n",
       " 'flaylly',\n",
       " 'fnajlly',\n",
       " 'fiaenloy',\n",
       " 'mifanlly',\n",
       " 'zianllzy',\n",
       " 'fgaxlly',\n",
       " 'gianlwy',\n",
       " 'ofianjlly',\n",
       " 'fbianvlly',\n",
       " 'fpianplly',\n",
       " 'fbanlll',\n",
       " 'cqfianlly',\n",
       " 'ifianlloy',\n",
       " 'pfkianlly',\n",
       " 'fianllybm',\n",
       " 'fianeyly',\n",
       " 'foanljly',\n",
       " 'xfilnlly',\n",
       " 'cianllyx',\n",
       " 'ftanlloy',\n",
       " 'fianxolly',\n",
       " 'vfianllk',\n",
       " 'faanllpy',\n",
       " 'fhmanlly',\n",
       " 'fiapllyt',\n",
       " 'fioanlny',\n",
       " 'fiaynlhy',\n",
       " 'fianlylye',\n",
       " 'fwanmly',\n",
       " 'fqacnlly',\n",
       " 'fsanely',\n",
       " 'fixanllz',\n",
       " 'rfianqlly',\n",
       " 'fianllfc',\n",
       " 'fitolly',\n",
       " 'fianlilk',\n",
       " 'fianljlgy',\n",
       " 'fiazllx',\n",
       " 'dfianwlly',\n",
       " 'gianlhy',\n",
       " 'gfianlby',\n",
       " 'fianxlry',\n",
       " 'firanllw',\n",
       " 'fianllmyh',\n",
       " 'fiqanwlly',\n",
       " 'fianvgy',\n",
       " 'fianlltpy',\n",
       " 'fmianlln',\n",
       " 'diatnlly',\n",
       " 'fiakhlly',\n",
       " 'qienlly',\n",
       " 'fiabllny',\n",
       " 'ftanllu',\n",
       " 'fibaslly',\n",
       " 'ufiaanlly',\n",
       " 'liandlly',\n",
       " 'fiancsly',\n",
       " 'fianrlyp',\n",
       " 'fianlglxy',\n",
       " 'qiarlly',\n",
       " 'tfianllyl',\n",
       " 'fianlzg',\n",
       " 'ufianllny',\n",
       " 'qfianlmy',\n",
       " 'fianjlyj',\n",
       " 'fiansllyr',\n",
       " 'fiaanllmy',\n",
       " 'fgaglly',\n",
       " 'fianllvyk',\n",
       " 'fhanllyb',\n",
       " 'fdaenlly',\n",
       " 'fdanlbly',\n",
       " 'fiadnllvy',\n",
       " 'fiynllyo',\n",
       " 'dfianllmy',\n",
       " 'siaylly',\n",
       " 'fvaanlly',\n",
       " 'fianplny',\n",
       " 'sqfianlly',\n",
       " 'uianlxy',\n",
       " 'fllnlly',\n",
       " 'fyanllay',\n",
       " 'fisnllyr',\n",
       " 'fianwzly',\n",
       " 'fianllynm',\n",
       " 'fianlelf',\n",
       " 'fxahnlly',\n",
       " 'fiancvlly',\n",
       " 'fvanluly',\n",
       " 'ffianllb',\n",
       " 'fiuanlxly',\n",
       " 'pfianhlly',\n",
       " 'fwianloy',\n",
       " 'fpanlny',\n",
       " 'fiaklely',\n",
       " 'hfianlkly',\n",
       " 'siaynlly',\n",
       " 'firanwly',\n",
       " 'fiknlle',\n",
       " 'fiasnlvy',\n",
       " 'fiaqlyy',\n",
       " 'fiafgnlly',\n",
       " 'hfiaslly',\n",
       " 'fianlluyc',\n",
       " 'zfinanlly',\n",
       " 'fiuqlly',\n",
       " 'oianlsly',\n",
       " 'fianljye',\n",
       " 'fimnluly',\n",
       " 'fienllb',\n",
       " 'fibanlely',\n",
       " 'fiaglgy',\n",
       " 'finnlly',\n",
       " 'fiianllyt',\n",
       " 'fwqianlly',\n",
       " 'fiiazlly',\n",
       " 'fnianllay',\n",
       " 'fcianbly',\n",
       " 'fianpllb',\n",
       " 'ficanlply',\n",
       " 'fiaalhy',\n",
       " 'pfsianlly',\n",
       " 'vfinally',\n",
       " 'fqiazlly',\n",
       " 'fsianllv',\n",
       " 'fibnlloy',\n",
       " 'fieqanlly',\n",
       " 'ifanllk',\n",
       " 'sfianlxly',\n",
       " 'fmiankly',\n",
       " 'fianvllt',\n",
       " 'fimnklly',\n",
       " 'fiaonly',\n",
       " 'fxlnlly',\n",
       " 'frianllyo',\n",
       " 'fianllhf',\n",
       " 'fvallly',\n",
       " 'fiaqnmly',\n",
       " 'tianllyu',\n",
       " 'fiatynlly',\n",
       " 'fidnclly',\n",
       " 'aoianlly',\n",
       " 'fiapslly',\n",
       " 'fianfluy',\n",
       " 'fianllnh',\n",
       " 'ffianltly',\n",
       " 'fianjlyx',\n",
       " 'fiancllhy',\n",
       " 'fianloyv',\n",
       " 'fiayllly',\n",
       " 'fsanllwy',\n",
       " 'fianultly',\n",
       " 'fiaxcnlly',\n",
       " 'fiavlkly',\n",
       " 'fianltdly',\n",
       " 'fiacllyk',\n",
       " 'fianslzy',\n",
       " 'frianllyw',\n",
       " 'fiamlhy',\n",
       " 'pftianlly',\n",
       " 'fkanelly',\n",
       " 'fiauloy',\n",
       " 'fihnhlly',\n",
       " 'qfgianlly',\n",
       " 'tfiwanlly',\n",
       " 'efitanlly',\n",
       " 'fibnilly',\n",
       " 'fdanlmy',\n",
       " 'fianlcp',\n",
       " 'fsianlty',\n",
       " 'flanll',\n",
       " 'ifanllm',\n",
       " 'fiaqnllyv',\n",
       " 'fnanlxy',\n",
       " 'qfianllv',\n",
       " 'fcaxnlly',\n",
       " 'fvianllyp',\n",
       " 'feinlly',\n",
       " 'hfianclly',\n",
       " 'fiajnllys',\n",
       " 'fisanlfly',\n",
       " 'efiarnlly',\n",
       " 'yiandlly',\n",
       " 'fiqanfly',\n",
       " 'aianzlly',\n",
       " 'wfianllp',\n",
       " 'fianllupy',\n",
       " 'feahlly',\n",
       " 'fianlilzy',\n",
       " 'fsfianlly',\n",
       " 'zfiwnlly',\n",
       " 'fainly',\n",
       " 'tqianlly',\n",
       " 'bfjianlly',\n",
       " 'fianlils',\n",
       " 'kianklly',\n",
       " 'fiapqly',\n",
       " 'fianpoly',\n",
       " 'wianllyu',\n",
       " 'fienvly',\n",
       " 'fiyanlzly',\n",
       " 'bfiwanlly',\n",
       " 'fmanlloy',\n",
       " 'bianlvy',\n",
       " 'fiajylly',\n",
       " 'fianleply',\n",
       " 'fkifanlly',\n",
       " 'fiawllyz',\n",
       " 'kfianllr',\n",
       " 'fwancly',\n",
       " 'fianlay',\n",
       " 'ofiacnlly',\n",
       " 'kiacnlly',\n",
       " 'fyiaully',\n",
       " 'filnilly',\n",
       " 'fianllyul',\n",
       " 'fiapnlyl',\n",
       " 'fiwanlmy',\n",
       " 'fianwlll',\n",
       " 'fcianvlly',\n",
       " 'fipmanlly',\n",
       " 'fisanlcly',\n",
       " 'wiavnlly',\n",
       " 'fivnlny',\n",
       " 'finalxly',\n",
       " 'firnxlly',\n",
       " 'fnianllp',\n",
       " 'fihnmly',\n",
       " 'fisancly',\n",
       " 'flianply',\n",
       " 'finanflly',\n",
       " 'fiazllg',\n",
       " 'vibnlly',\n",
       " 'fiaznllh',\n",
       " 'fianblloy',\n",
       " 'fiancmlly',\n",
       " 'fgamlly',\n",
       " 'feanlld',\n",
       " 'fianpllr',\n",
       " 'fzanldy',\n",
       " 'fijanllp',\n",
       " 'gianldy',\n",
       " 'fianflqly',\n",
       " 'fivanllb',\n",
       " 'rfainlly',\n",
       " 'fikancly',\n",
       " 'oianllyc',\n",
       " 'fnamnlly',\n",
       " 'aianqly',\n",
       " 'uianllwy',\n",
       " 'iwnlly',\n",
       " 'fianllykk',\n",
       " 'fiandlzy',\n",
       " 'ifiangly',\n",
       " 'fqcnlly',\n",
       " 'yiarlly',\n",
       " 'fignaly',\n",
       " 'fiexlly',\n",
       " 'nianlqy',\n",
       " 'fiaelzy',\n",
       " 'fiatoly',\n",
       " 'fiianllky',\n",
       " 'fianzty',\n",
       " 'fianuly',\n",
       " 'fianlwyp',\n",
       " 'fianlday',\n",
       " 'nanlly',\n",
       " 'ofinanlly',\n",
       " 'dianlny',\n",
       " 'fiajlmy',\n",
       " 'oienlly',\n",
       " 'fianyllhy',\n",
       " 'bianlky',\n",
       " 'fjiaqnlly',\n",
       " 'fpianllny',\n",
       " 'fiamnllr',\n",
       " 'fisaflly',\n",
       " 'fiancy',\n",
       " 'fiaqnlluy',\n",
       " 'fiawlloy',\n",
       " 'fianyzly',\n",
       " 'fiknllyp',\n",
       " 'fqicnlly',\n",
       " 'ficnrlly',\n",
       " 'fviailly',\n",
       " 'fiaunlsly',\n",
       " 'fianllwly',\n",
       " 'fuhianlly',\n",
       " 'rianlmly',\n",
       " 'fianliyn',\n",
       " 'ofbanlly',\n",
       " 'fganllyb',\n",
       " 'pfvianlly',\n",
       " 'firnllg',\n",
       " 'fianlola',\n",
       " 'fiagldly',\n",
       " 'fianllsny',\n",
       " 'fiapllm',\n",
       " 'feanwlly',\n",
       " 'fkanlli',\n",
       " 'tfiablly',\n",
       " 'faanllys',\n",
       " 'fwiantlly',\n",
       " 'fianllrhy',\n",
       " 'fianlemly',\n",
       " 'fqxnlly',\n",
       " 'sfianllgy',\n",
       " 'fiaallry',\n",
       " 'fioaynlly',\n",
       " 'fiahnllq',\n",
       " 'fiannllym',\n",
       " 'fiqnlyly',\n",
       " 'fiadllcy',\n",
       " 'ftapnlly',\n",
       " 'zfianllys',\n",
       " 'fnanilly',\n",
       " 'fiaonllf',\n",
       " 'kianwlly',\n",
       " 'fianlslxy',\n",
       " 'fiaallw',\n",
       " 'fiaenlle',\n",
       " 'fiajnilly',\n",
       " 'fiavnllj',\n",
       " 'ftianllyl',\n",
       " 'dianllr',\n",
       " 'fbavnlly',\n",
       " 'qfuanlly',\n",
       " 'ifyanlly',\n",
       " 'rfiajnlly',\n",
       " 'fianllykl',\n",
       " 'fiaenlmy',\n",
       " 'fiacllyt',\n",
       " 'fianllyng',\n",
       " 'fsanlrly',\n",
       " 'fsiqanlly',\n",
       " 'fiaynxlly',\n",
       " 'fiananlly',\n",
       " 'mfianllt',\n",
       " 'ifiahnlly',\n",
       " 'fianlphy',\n",
       " 'fiankllvy',\n",
       " 'fhanlljy',\n",
       " 'fiaallyo',\n",
       " 'yianrly',\n",
       " 'gjfianlly',\n",
       " 'tianlkly',\n",
       " 'fianliyj',\n",
       " 'fianlnk',\n",
       " 'fxanllb',\n",
       " 'figanllyz',\n",
       " 'fieelly',\n",
       " 'fianilyy',\n",
       " 'fiaynhly',\n",
       " 'gainlly',\n",
       " 'fimnlldy',\n",
       " 'fiycnlly',\n",
       " 'fbianzly',\n",
       " 'fivjnlly',\n",
       " 'fiazlty',\n",
       " 'nfidnlly',\n",
       " 'cafianlly',\n",
       " 'ftanlcy',\n",
       " 'fuanluly',\n",
       " 'fianlilyt',\n",
       " 'fitandly',\n",
       " 'fianllytp',\n",
       " 'fixanlli',\n",
       " 'aianglly',\n",
       " 'fsanmly',\n",
       " 'fiandply',\n",
       " 'fiianjlly',\n",
       " 'fcianvly',\n",
       " 'fianillyu',\n",
       " 'pianlzly',\n",
       " 'fiallxy',\n",
       " 'fianhlyj',\n",
       " 'vfqanlly',\n",
       " 'zianluly',\n",
       " 'aianllby',\n",
       " 'fkanklly',\n",
       " 'fxianlbly',\n",
       " 'fianllpyr',\n",
       " 'fisnllyj',\n",
       " 'eianllh',\n",
       " 'fwiadlly',\n",
       " 'vfiaynlly',\n",
       " 'fiandlla',\n",
       " 'fiahnlvy',\n",
       " 'qiandlly',\n",
       " 'ifiahlly',\n",
       " 'fiandally',\n",
       " 'fijnllc',\n",
       " 'dfianllay',\n",
       " 'fianlala',\n",
       " 'fianluya',\n",
       " 'fiuunlly',\n",
       " 'fianlbldy',\n",
       " 'fiatnllyf',\n",
       " 'fiqlly',\n",
       " 'fianlyv',\n",
       " 'lianllyv',\n",
       " 'fiaenjlly',\n",
       " 'mfiantlly',\n",
       " 'tipanlly',\n",
       " 'fiagnllf',\n",
       " 'kfifnlly',\n",
       " 'fiabll',\n",
       " 'fiavxnlly',\n",
       " 'fidnyly',\n",
       " 'fiaqnllyz',\n",
       " 'franltly',\n",
       " 'fiandjlly',\n",
       " 'biganlly',\n",
       " 'feanllm',\n",
       " 'fianilvly',\n",
       " 'fialnlyb',\n",
       " 'fiacnnly',\n",
       " 'fianlki',\n",
       " 'flihnlly',\n",
       " 'lianlcly',\n",
       " 'fqianllp',\n",
       " 'fiwanllyf',\n",
       " 'finlvy',\n",
       " 'lianlply',\n",
       " 'fipnllyq',\n",
       " 'fsanlyl',\n",
       " 'pianlrly',\n",
       " 'fipnoly',\n",
       " 'fianlelzy',\n",
       " 'qjfianlly',\n",
       " 'fiablwy',\n",
       " 'fwianluly',\n",
       " 'kganlly',\n",
       " 'ftiaclly',\n",
       " 'fiynlfy',\n",
       " 'efianwlly',\n",
       " 'fiarlkly',\n",
       " 'fivanlzly',\n",
       " 'hfikanlly',\n",
       " 'fianflny',\n",
       " 'fianrllo',\n",
       " 'lianlle',\n",
       " 'kiaonlly',\n",
       " 'fianlblg',\n",
       " 'fibahlly',\n",
       " 'fxalnly',\n",
       " 'fqiafnlly',\n",
       " 'fxiabnlly',\n",
       " 'bianlwy',\n",
       " 'fuaknlly',\n",
       " 'bfzanlly',\n",
       " 'fgiaflly',\n",
       " 'jfaanlly',\n",
       " 'finntlly',\n",
       " 'fianvlmy',\n",
       " 'fimanlby',\n",
       " 'fobanlly',\n",
       " 'fianillfy',\n",
       " 'ofiailly',\n",
       " 'zeianlly',\n",
       " 'fianlljyl',\n",
       " 'mfizanlly',\n",
       " 'tianllj',\n",
       " 'fiznllyi',\n",
       " 'franlply',\n",
       " 'fianlwty',\n",
       " 'ftianzly',\n",
       " 'nianlrly',\n",
       " 'fiancllp',\n",
       " 'fianvllo',\n",
       " 'fikanlxly',\n",
       " 'fiazllhy',\n",
       " 'yfianllfy',\n",
       " 'fiianlcly',\n",
       " 'foanvlly',\n",
       " 'fimaenlly',\n",
       " 'fivanflly',\n",
       " 'fifanhly',\n",
       " 'finallly',\n",
       " 'ifdanlly',\n",
       " 'ffizanlly',\n",
       " 'fianlklwy',\n",
       " 'fzianllym',\n",
       " 'faianllz',\n",
       " 'afqanlly',\n",
       " 'fianqwy',\n",
       " 'kfianrly',\n",
       " 'fianlliyj',\n",
       " 'fcianll',\n",
       " 'fiatlldy',\n",
       " 'fixanllt',\n",
       " 'feaynlly',\n",
       " 'fianllnjy',\n",
       " 'fjanluy',\n",
       " 'fianqlloy',\n",
       " 'fiasnllj',\n",
       " 'fianvlpy',\n",
       " 'fmiacnlly',\n",
       " 'xoanlly',\n",
       " 'fiaslxy',\n",
       " 'fianllcg',\n",
       " 'fiazwnlly',\n",
       " 'fiafllhy',\n",
       " 'yfiailly',\n",
       " 'foanglly',\n",
       " 'fiancally',\n",
       " 'fiadqlly',\n",
       " 'fjianqlly',\n",
       " 'bianlld',\n",
       " 'fianlnlyi',\n",
       " 'vianllyw',\n",
       " 'fiahllo',\n",
       " 'fianrfly',\n",
       " 'fiuajlly',\n",
       " 'fhianllw',\n",
       " 'vvanlly',\n",
       " 'fiabnllyh',\n",
       " 'fiatnlls',\n",
       " 'esanlly',\n",
       " 'fianlqlq',\n",
       " 'fianlqlyq',\n",
       " 'mianlxy',\n",
       " 'fqianllym',\n",
       " 'fianldlyq',\n",
       " 'fsxnlly',\n",
       " 'fifnlwy',\n",
       " 'uyanlly',\n",
       " 'fcagnlly',\n",
       " 'fiagtlly',\n",
       " 'nfiranlly',\n",
       " 'fiarlnlly',\n",
       " 'fbantlly',\n",
       " 'flanxly',\n",
       " 'fikanlnly',\n",
       " 'fiandlliy',\n",
       " 'fiailty',\n",
       " 'fioznlly',\n",
       " 'fwdianlly',\n",
       " 'srianlly',\n",
       " 'fignlnly',\n",
       " 'fiaslvly',\n",
       " 'fganlli',\n",
       " 'fivanely',\n",
       " 'fiaonklly',\n",
       " 'fbialnlly',\n",
       " 'fianlldyq',\n",
       " 'fianllxw',\n",
       " 'fjxnlly',\n",
       " 'iacnlly',\n",
       " 'fiwanlloy',\n",
       " 'fiapflly',\n",
       " 'ffiwnlly',\n",
       " 'ftzianlly',\n",
       " 'efianlply',\n",
       " 'ofianlkly',\n",
       " 'aimanlly',\n",
       " 'fihanllyi',\n",
       " 'fiakllyi',\n",
       " 'qfianlqly',\n",
       " 'failly',\n",
       " 'fianllcr',\n",
       " 'fuianllz',\n",
       " 'gsanlly',\n",
       " 'ftanllgy',\n",
       " 'dianley',\n",
       " 'sfianluy',\n",
       " 'feianhly',\n",
       " 'fianlvuy',\n",
       " 'fkianlley',\n",
       " 'fianlmyl',\n",
       " 'qiamlly',\n",
       " 'fpianlhly',\n",
       " 'faanllyo',\n",
       " 'fbianlqy',\n",
       " 'aafianlly',\n",
       " 'fianhklly',\n",
       " 'fianwllyl',\n",
       " 'fianllyv',\n",
       " 'fianluyr',\n",
       " 'afiantly',\n",
       " 'fianlfyx',\n",
       " 'fianlrys',\n",
       " 'fimnllay',\n",
       " 'mfianllgy',\n",
       " 'fdnnlly',\n",
       " 'nipnlly',\n",
       " 'fiannla',\n",
       " 'fainllty',\n",
       " 'fiavnlll',\n",
       " 'jfianldly',\n",
       " 'fzianllry',\n",
       " 'qinanlly',\n",
       " 'fyaolly',\n",
       " 'fiiianlly',\n",
       " 'vianhlly',\n",
       " 'fioanzlly',\n",
       " 'fdianllyn',\n",
       " 'fimanklly',\n",
       " 'fiajnhlly',\n",
       " 'rfianlldy',\n",
       " 'uianllyv',\n",
       " 'pianvlly',\n",
       " 'dyianlly',\n",
       " 'fiiailly',\n",
       " 'finnlhly',\n",
       " 'fiajhlly',\n",
       " 'fkianllyl',\n",
       " 'finallwy',\n",
       " 'fiknsly',\n",
       " 'tignlly',\n",
       " 'francly',\n",
       " 'finlply',\n",
       " 'fqianljy',\n",
       " 'fianwlcy',\n",
       " 'fipanllay',\n",
       " 'fiacnllu',\n",
       " 'fianrxlly',\n",
       " 'pianllyr',\n",
       " 'fianlmlo',\n",
       " 'ofoianlly',\n",
       " 'fijanklly',\n",
       " 'fiaintlly',\n",
       " 'fiavljly',\n",
       " 'ftianlley',\n",
       " 'lfianjlly',\n",
       " 'fiacnqlly',\n",
       " 'cianlty',\n",
       " 'feiuanlly',\n",
       " 'kfianllyg',\n",
       " 'fjianllyh',\n",
       " 'fpaklly',\n",
       " 'fkanllyk',\n",
       " 'hianily',\n",
       " 'fihanlluy',\n",
       " 'fxianllv',\n",
       " 'fiansllyf',\n",
       " 'fianlklym',\n",
       " 'ifanlzy',\n",
       " 'ofiajlly',\n",
       " 'fikdanlly',\n",
       " 'xiaflly',\n",
       " 'xfianlwly',\n",
       " 'fianlut',\n",
       " 'fiznmlly',\n",
       " 'fivndly',\n",
       " 'fuianldly',\n",
       " 'zfianlyy',\n",
       " 'fhiajlly',\n",
       " 'xiallly',\n",
       " 'fjianllyd',\n",
       " 'ofiangly',\n",
       " 'sianllyl',\n",
       " 'pfianlfly',\n",
       " 'hiasnlly',\n",
       " 'fianflld',\n",
       " 'fianllkhy',\n",
       " 'fiantlk',\n",
       " 'fpianllx',\n",
       " 'fiawlhy',\n",
       " 'fianfslly',\n",
       " 'fxianlvly',\n",
       " 'fiadnylly',\n",
       " 'fiannllyy',\n",
       " 'ibnlly',\n",
       " 'fjianllgy',\n",
       " 'uianllj',\n",
       " 'mianplly',\n",
       " 'fianjllb',\n",
       " 'fwikanlly',\n",
       " 'kianlkly',\n",
       " 'fiansvy',\n",
       " 'dixnlly',\n",
       " 'fdanltly',\n",
       " 'fiknllyt',\n",
       " 'vfianllyi',\n",
       " 'fiamnlyy',\n",
       " 'viafnlly',\n",
       " 'fionllyg',\n",
       " 'fciwnlly',\n",
       " 'ziatlly',\n",
       " 'fvisanlly',\n",
       " 'ftaflly',\n",
       " 'sfianllys',\n",
       " 'fhuianlly',\n",
       " 'fvidnlly',\n",
       " 'ufiannlly',\n",
       " 'fkianllh',\n",
       " 'fifnllw',\n",
       " 'lihanlly',\n",
       " 'fianflyl',\n",
       " 'wfianlmly',\n",
       " 'fmcanlly',\n",
       " 'fipnllxy',\n",
       " 'fiadnllyz',\n",
       " 'rianley',\n",
       " 'figngly',\n",
       " 'fiamllfy',\n",
       " 'fkanlhly',\n",
       " 'fiilly',\n",
       " 'fianllkn',\n",
       " 'fiafaly',\n",
       " 'fnanlsly',\n",
       " 'fiatnllc',\n",
       " 'vuanlly',\n",
       " 'ffiantlly',\n",
       " 'wfiaunlly',\n",
       " 'fianhlldy',\n",
       " 'fihanlfy',\n",
       " 'fiaonloly',\n",
       " 'fhnanlly',\n",
       " 'fiangjly',\n",
       " 'fpamnlly',\n",
       " 'finrally',\n",
       " 'fsanllyn',\n",
       " 'fxianlsy',\n",
       " 'ftanlldy',\n",
       " 'fianllyu',\n",
       " 'ficblly',\n",
       " 'fiwaynlly',\n",
       " 'fiaiflly',\n",
       " 'fianrllyz',\n",
       " 'fiathlly',\n",
       " 'fianljlyq',\n",
       " 'figanlbly',\n",
       " 'fniailly',\n",
       " 'fianlzlyx',\n",
       " 'ficnllyg',\n",
       " 'gfiajnlly',\n",
       " 'cienlly',\n",
       " 'fianflyk',\n",
       " 'faanlyly',\n",
       " 'cfiaully',\n",
       " 'fimamnlly',\n",
       " 'fihanlxy',\n",
       " 'fliahnlly',\n",
       " 'ofianwly',\n",
       " 'fyiallly',\n",
       " 'pianlll',\n",
       " 'fnaflly',\n",
       " 'cianlnly',\n",
       " 'fihqanlly',\n",
       " 'fianzlhy',\n",
       " 'foiainlly',\n",
       " 'iarlly',\n",
       " 'lfiaally',\n",
       " 'fjianly',\n",
       " 'mflianlly',\n",
       " 'cianlluy',\n",
       " 'frianyly',\n",
       " 'fiankklly',\n",
       " 'fiasnlljy',\n",
       " 'fianlapy',\n",
       " 'hainlly',\n",
       " 'oiaclly',\n",
       " 'ufiavlly',\n",
       " 'fiawnllyj',\n",
       " 'franxlly',\n",
       " 'edianlly',\n",
       " 'fiagply',\n",
       " 'fcanllr',\n",
       " 'fimnllyu',\n",
       " 'fidanllyu',\n",
       " 'zfjianlly',\n",
       " 'ufqianlly',\n",
       " 'fianllcoy',\n",
       " 'fkaflly',\n",
       " 'tfiavnlly',\n",
       " 'fzanqly',\n",
       " 'fioablly',\n",
       " 'fiuyanlly',\n",
       " 'firnllw',\n",
       " 'fianlill',\n",
       " 'firanllry',\n",
       " 'fianrljy',\n",
       " 'fianlhyj',\n",
       " 'pfialnlly',\n",
       " 'fianollyy',\n",
       " 'fmankly',\n",
       " 'fikanrly',\n",
       " 'fiwnklly',\n",
       " 'pianrly',\n",
       " 'filanolly',\n",
       " 'tfianlhly',\n",
       " 'fianmlzy',\n",
       " 'fhanllmy',\n",
       " 'gfhianlly',\n",
       " 'fiahnllv',\n",
       " 'fqianlcy',\n",
       " 'kianllgy',\n",
       " 'fitnllm',\n",
       " 'fqianllyp',\n",
       " 'fiaelzly',\n",
       " 'fianlmbly',\n",
       " 'fiabllhy',\n",
       " 'fiainlloy',\n",
       " 'fikaelly',\n",
       " 'qfwianlly',\n",
       " 'fiaqnllhy',\n",
       " 'efiagnlly',\n",
       " 'fiamnllyw',\n",
       " 'zianlqy',\n",
       " 'fmianllyc',\n",
       " 'fiaunllmy',\n",
       " 'fiasnllya',\n",
       " 'fiwfnlly',\n",
       " 'omianlly',\n",
       " 'fizanllyw',\n",
       " 'fiadhnlly',\n",
       " 'iianlvly',\n",
       " 'fianllqsy',\n",
       " 'fiynllyd',\n",
       " 'bfiahnlly',\n",
       " 'fianlolf',\n",
       " 'fiavllw',\n",
       " 'ozianlly',\n",
       " 'vianely',\n",
       " 'fianpllye',\n",
       " 'bfianljy',\n",
       " 'fpiandly',\n",
       " 'fivanllyl',\n",
       " 'fianllob',\n",
       " 'fiansllv',\n",
       " 'filnllyt',\n",
       " 'fzanllsy',\n",
       " 'fiyangly',\n",
       " 'fitnllyg',\n",
       " 'hisnlly',\n",
       " 'fianldyk',\n",
       " 'fipanllgy',\n",
       " 'frranlly',\n",
       " 'qlianlly',\n",
       " 'fiaaclly',\n",
       " 'jianily',\n",
       " 'fianaay',\n",
       " 'mfianhly',\n",
       " 'frianrly',\n",
       " 'fuianlcly',\n",
       " 'fviamlly',\n",
       " 'feianllmy',\n",
       " 'fiajnally',\n",
       " 'fianlcply',\n",
       " 'fikanllj',\n",
       " 'qnanlly',\n",
       " 'emanlly',\n",
       " 'fzmianlly',\n",
       " 'efianlzy',\n",
       " 'finlpy',\n",
       " 'fiahuly',\n",
       " 'fianlnyg',\n",
       " 'fjajnlly',\n",
       " 'fianxl',\n",
       " 'ifiasnlly',\n",
       " 'fiadtlly',\n",
       " 'fsanlloy',\n",
       " 'fijanmly',\n",
       " 'pianllf',\n",
       " 'fganlqy',\n",
       " 'figjlly',\n",
       " 'fdifnlly',\n",
       " 'fijnilly',\n",
       " 'fiaotnlly',\n",
       " 'fiinloy',\n",
       " 'mbfianlly',\n",
       " 'faanlvy',\n",
       " 'fiaxllj',\n",
       " 'fsimanlly',\n",
       " 'fiannllg',\n",
       " 'fiaejly',\n",
       " 'fqianllya',\n",
       " 'fianllxys',\n",
       " 'fiaznllyo',\n",
       " 'fihlanlly',\n",
       " 'fianldb',\n",
       " 'fifmnlly',\n",
       " 'tfianlbly',\n",
       " 'fianmvlly',\n",
       " 'fianllxg',\n",
       " 'fianlsoy',\n",
       " 'fianlzlj',\n",
       " 'wianlfly',\n",
       " 'fiantfly',\n",
       " 'fimnhly',\n",
       " 'dfeianlly',\n",
       " 'fianlpd',\n",
       " 'mfisanlly',\n",
       " 'nbanlly',\n",
       " 'fcanlle',\n",
       " 'filanlli',\n",
       " 'fnanluy',\n",
       " 'fixnully',\n",
       " 'fiinllfy',\n",
       " 'fliazlly',\n",
       " 'fianllyrs',\n",
       " 'fianeyy',\n",
       " 'fiadmnlly',\n",
       " 'ftanully',\n",
       " 'fiankllzy',\n",
       " 'fvanlxy',\n",
       " 'fitanlld',\n",
       " 'gfianlhly',\n",
       " 'dfianlfy',\n",
       " 'diamlly',\n",
       " 'leanlly',\n",
       " 'aianaly',\n",
       " 'fianlcqly',\n",
       " 'fialplly',\n",
       " 'fihanolly',\n",
       " 'fixnllym',\n",
       " 'efiancly',\n",
       " 'clanlly',\n",
       " 'cfiqanlly',\n",
       " 'fiafnlsy',\n",
       " 'fiabllyr',\n",
       " 'mianqlly',\n",
       " 'fjanlliy',\n",
       " 'kifnlly',\n",
       " 'fuianlldy',\n",
       " 'eiajlly',\n",
       " 'fanluly',\n",
       " 'fiagvnlly',\n",
       " 'filnloy',\n",
       " 'lianqly',\n",
       " 'fiayplly',\n",
       " 'foilanlly',\n",
       " 'lfianllyb',\n",
       " 'fiafxly',\n",
       " 'finallyd',\n",
       " 'bibnlly',\n",
       " 'biuanlly',\n",
       " 'gfianlnly',\n",
       " 'fiaolle',\n",
       " 'fhianily',\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two edit distances from input word\n",
    "edits2(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits1(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fvikanlly',\n",
       " 'fiaqnlcly',\n",
       " 'fiaflle',\n",
       " 'afianlely',\n",
       " 'yfiynlly',\n",
       " 'fizanwly',\n",
       " 'gijanlly',\n",
       " 'fisanlluy',\n",
       " 'fcangly',\n",
       " 'fianlgyu',\n",
       " 'fyanllfy',\n",
       " 'bfiansly',\n",
       " 'vfijnlly',\n",
       " 'rifanlly',\n",
       " 'fianlqlny',\n",
       " 'fiatllyt',\n",
       " 'xfianllyj',\n",
       " 'gfianllyb',\n",
       " 'fianllyct',\n",
       " 'fiazlnly',\n",
       " 'fwanllye',\n",
       " 'fiankldly',\n",
       " 'fianlnlf',\n",
       " 'kfianlqly',\n",
       " 'fiznlxly',\n",
       " 'fbanzly',\n",
       " 'fhiaklly',\n",
       " 'yianllyr',\n",
       " 'fidarnlly',\n",
       " 'fiagly',\n",
       " 'fiunwly',\n",
       " 'fianalx',\n",
       " 'fijnfly',\n",
       " 'fhihanlly',\n",
       " 'fisanllk',\n",
       " 'wfsianlly',\n",
       " 'xiawnlly',\n",
       " 'fianllgyz',\n",
       " 'fianlaky',\n",
       " 'fianlelyq',\n",
       " 'fianrlpy',\n",
       " 'dianlely',\n",
       " 'fianlgply',\n",
       " 'ftiianlly',\n",
       " 'fimanlay',\n",
       " 'fianzply',\n",
       " 'kfijnlly',\n",
       " 'fiaknllh',\n",
       " 'fiandtly',\n",
       " 'fianltfly',\n",
       " 'dfcanlly',\n",
       " 'mimnlly',\n",
       " 'fiapnlzly',\n",
       " 'fianlpl',\n",
       " 'oianrly',\n",
       " 'fitnljly',\n",
       " 'fiaxnlbly',\n",
       " 'fqandlly',\n",
       " 'fiawyly',\n",
       " 'liancly',\n",
       " 'fiaewly',\n",
       " 'fvianll',\n",
       " 'fjiabnlly',\n",
       " 'fhxanlly',\n",
       " 'firanllyn',\n",
       " 'fiaunltly',\n",
       " 'ftanllly',\n",
       " 'fialnllky',\n",
       " 'flaylly',\n",
       " 'fnajlly',\n",
       " 'fiaenloy',\n",
       " 'mifanlly',\n",
       " 'zianllzy',\n",
       " 'fgaxlly',\n",
       " 'gianlwy',\n",
       " 'ofianjlly',\n",
       " 'fbianvlly',\n",
       " 'fpianplly',\n",
       " 'fbanlll',\n",
       " 'cqfianlly',\n",
       " 'ifianlloy',\n",
       " 'pfkianlly',\n",
       " 'fianllybm',\n",
       " 'fianeyly',\n",
       " 'foanljly',\n",
       " 'xfilnlly',\n",
       " 'cianllyx',\n",
       " 'ftanlloy',\n",
       " 'fianxolly',\n",
       " 'vfianllk',\n",
       " 'faanllpy',\n",
       " 'fhmanlly',\n",
       " 'fiapllyt',\n",
       " 'fioanlny',\n",
       " 'fiaynlhy',\n",
       " 'fianlylye',\n",
       " 'fwanmly',\n",
       " 'fqacnlly',\n",
       " 'fsanely',\n",
       " 'fixanllz',\n",
       " 'rfianqlly',\n",
       " 'fianllfc',\n",
       " 'fitolly',\n",
       " 'fianlilk',\n",
       " 'fianljlgy',\n",
       " 'fiazllx',\n",
       " 'dfianwlly',\n",
       " 'gianlhy',\n",
       " 'gfianlby',\n",
       " 'fianxlry',\n",
       " 'firanllw',\n",
       " 'fianllmyh',\n",
       " 'fiqanwlly',\n",
       " 'fianvgy',\n",
       " 'fianlltpy',\n",
       " 'fmianlln',\n",
       " 'diatnlly',\n",
       " 'fiakhlly',\n",
       " 'qienlly',\n",
       " 'fiabllny',\n",
       " 'ftanllu',\n",
       " 'fibaslly',\n",
       " 'ufiaanlly',\n",
       " 'liandlly',\n",
       " 'fiancsly',\n",
       " 'fianrlyp',\n",
       " 'fianlglxy',\n",
       " 'qiarlly',\n",
       " 'tfianllyl',\n",
       " 'fianlzg',\n",
       " 'ufianllny',\n",
       " 'qfianlmy',\n",
       " 'fianjlyj',\n",
       " 'fiansllyr',\n",
       " 'fiaanllmy',\n",
       " 'fgaglly',\n",
       " 'fianllvyk',\n",
       " 'fhanllyb',\n",
       " 'fdaenlly',\n",
       " 'fdanlbly',\n",
       " 'fiadnllvy',\n",
       " 'fiynllyo',\n",
       " 'dfianllmy',\n",
       " 'siaylly',\n",
       " 'fvaanlly',\n",
       " 'fianplny',\n",
       " 'sqfianlly',\n",
       " 'uianlxy',\n",
       " 'fllnlly',\n",
       " 'fyanllay',\n",
       " 'fisnllyr',\n",
       " 'fianwzly',\n",
       " 'fianllynm',\n",
       " 'fianlelf',\n",
       " 'fxahnlly',\n",
       " 'fiancvlly',\n",
       " 'fvanluly',\n",
       " 'ffianllb',\n",
       " 'fiuanlxly',\n",
       " 'pfianhlly',\n",
       " 'fwianloy',\n",
       " 'fpanlny',\n",
       " 'fiaklely',\n",
       " 'hfianlkly',\n",
       " 'siaynlly',\n",
       " 'firanwly',\n",
       " 'fiknlle',\n",
       " 'fiasnlvy',\n",
       " 'fiaqlyy',\n",
       " 'fiafgnlly',\n",
       " 'hfiaslly',\n",
       " 'fianlluyc',\n",
       " 'zfinanlly',\n",
       " 'fiuqlly',\n",
       " 'oianlsly',\n",
       " 'fianljye',\n",
       " 'fimnluly',\n",
       " 'fienllb',\n",
       " 'fibanlely',\n",
       " 'fiaglgy',\n",
       " 'finnlly',\n",
       " 'fiianllyt',\n",
       " 'fwqianlly',\n",
       " 'fiiazlly',\n",
       " 'fnianllay',\n",
       " 'fcianbly',\n",
       " 'fianpllb',\n",
       " 'ficanlply',\n",
       " 'fiaalhy',\n",
       " 'pfsianlly',\n",
       " 'vfinally',\n",
       " 'fqiazlly',\n",
       " 'fsianllv',\n",
       " 'fibnlloy',\n",
       " 'fieqanlly',\n",
       " 'ifanllk',\n",
       " 'sfianlxly',\n",
       " 'fmiankly',\n",
       " 'fianvllt',\n",
       " 'fimnklly',\n",
       " 'fiaonly',\n",
       " 'fxlnlly',\n",
       " 'frianllyo',\n",
       " 'fianllhf',\n",
       " 'fvallly',\n",
       " 'fiaqnmly',\n",
       " 'tianllyu',\n",
       " 'fiatynlly',\n",
       " 'fidnclly',\n",
       " 'aoianlly',\n",
       " 'fiapslly',\n",
       " 'fianfluy',\n",
       " 'fianllnh',\n",
       " 'ffianltly',\n",
       " 'fianjlyx',\n",
       " 'fiancllhy',\n",
       " 'fianloyv',\n",
       " 'fiayllly',\n",
       " 'fsanllwy',\n",
       " 'fianultly',\n",
       " 'fiaxcnlly',\n",
       " 'fiavlkly',\n",
       " 'fianltdly',\n",
       " 'fiacllyk',\n",
       " 'fianslzy',\n",
       " 'frianllyw',\n",
       " 'fiamlhy',\n",
       " 'pftianlly',\n",
       " 'fkanelly',\n",
       " 'fiauloy',\n",
       " 'fihnhlly',\n",
       " 'qfgianlly',\n",
       " 'tfiwanlly',\n",
       " 'efitanlly',\n",
       " 'fibnilly',\n",
       " 'fdanlmy',\n",
       " 'fianlcp',\n",
       " 'fsianlty',\n",
       " 'flanll',\n",
       " 'ifanllm',\n",
       " 'fiaqnllyv',\n",
       " 'fnanlxy',\n",
       " 'qfianllv',\n",
       " 'fcaxnlly',\n",
       " 'fvianllyp',\n",
       " 'feinlly',\n",
       " 'hfianclly',\n",
       " 'fiajnllys',\n",
       " 'fisanlfly',\n",
       " 'efiarnlly',\n",
       " 'yiandlly',\n",
       " 'fiqanfly',\n",
       " 'aianzlly',\n",
       " 'wfianllp',\n",
       " 'fianllupy',\n",
       " 'feahlly',\n",
       " 'fianlilzy',\n",
       " 'fsfianlly',\n",
       " 'zfiwnlly',\n",
       " 'fainly',\n",
       " 'tqianlly',\n",
       " 'bfjianlly',\n",
       " 'fianlils',\n",
       " 'kianklly',\n",
       " 'fiapqly',\n",
       " 'fianpoly',\n",
       " 'wianllyu',\n",
       " 'fienvly',\n",
       " 'fiyanlzly',\n",
       " 'bfiwanlly',\n",
       " 'fmanlloy',\n",
       " 'bianlvy',\n",
       " 'fiajylly',\n",
       " 'fianleply',\n",
       " 'fkifanlly',\n",
       " 'fiawllyz',\n",
       " 'kfianllr',\n",
       " 'fwancly',\n",
       " 'fianlay',\n",
       " 'ofiacnlly',\n",
       " 'kiacnlly',\n",
       " 'fyiaully',\n",
       " 'filnilly',\n",
       " 'fianllyul',\n",
       " 'fiapnlyl',\n",
       " 'fiwanlmy',\n",
       " 'fianwlll',\n",
       " 'fcianvlly',\n",
       " 'fipmanlly',\n",
       " 'fisanlcly',\n",
       " 'wiavnlly',\n",
       " 'fivnlny',\n",
       " 'finalxly',\n",
       " 'firnxlly',\n",
       " 'fnianllp',\n",
       " 'fihnmly',\n",
       " 'fisancly',\n",
       " 'flianply',\n",
       " 'finanflly',\n",
       " 'fiazllg',\n",
       " 'vibnlly',\n",
       " 'fiaznllh',\n",
       " 'fianblloy',\n",
       " 'fiancmlly',\n",
       " 'fgamlly',\n",
       " 'feanlld',\n",
       " 'fianpllr',\n",
       " 'fzanldy',\n",
       " 'fijanllp',\n",
       " 'gianldy',\n",
       " 'fianflqly',\n",
       " 'fivanllb',\n",
       " 'rfainlly',\n",
       " 'fikancly',\n",
       " 'oianllyc',\n",
       " 'fnamnlly',\n",
       " 'aianqly',\n",
       " 'uianllwy',\n",
       " 'iwnlly',\n",
       " 'fianllykk',\n",
       " 'fiandlzy',\n",
       " 'ifiangly',\n",
       " 'fqcnlly',\n",
       " 'yiarlly',\n",
       " 'fignaly',\n",
       " 'fiexlly',\n",
       " 'nianlqy',\n",
       " 'fiaelzy',\n",
       " 'fiatoly',\n",
       " 'fiianllky',\n",
       " 'fianzty',\n",
       " 'fianuly',\n",
       " 'fianlwyp',\n",
       " 'fianlday',\n",
       " 'nanlly',\n",
       " 'ofinanlly',\n",
       " 'dianlny',\n",
       " 'fiajlmy',\n",
       " 'oienlly',\n",
       " 'fianyllhy',\n",
       " 'bianlky',\n",
       " 'fjiaqnlly',\n",
       " 'fpianllny',\n",
       " 'fiamnllr',\n",
       " 'fisaflly',\n",
       " 'fiancy',\n",
       " 'fiaqnlluy',\n",
       " 'fiawlloy',\n",
       " 'fianyzly',\n",
       " 'fiknllyp',\n",
       " 'fqicnlly',\n",
       " 'ficnrlly',\n",
       " 'fviailly',\n",
       " 'fiaunlsly',\n",
       " 'fianllwly',\n",
       " 'fuhianlly',\n",
       " 'rianlmly',\n",
       " 'fianliyn',\n",
       " 'ofbanlly',\n",
       " 'fganllyb',\n",
       " 'pfvianlly',\n",
       " 'firnllg',\n",
       " 'fianlola',\n",
       " 'fiagldly',\n",
       " 'fianllsny',\n",
       " 'fiapllm',\n",
       " 'feanwlly',\n",
       " 'fkanlli',\n",
       " 'tfiablly',\n",
       " 'faanllys',\n",
       " 'fwiantlly',\n",
       " 'fianllrhy',\n",
       " 'fianlemly',\n",
       " 'fqxnlly',\n",
       " 'sfianllgy',\n",
       " 'fiaallry',\n",
       " 'fioaynlly',\n",
       " 'fiahnllq',\n",
       " 'fiannllym',\n",
       " 'fiqnlyly',\n",
       " 'fiadllcy',\n",
       " 'ftapnlly',\n",
       " 'zfianllys',\n",
       " 'fnanilly',\n",
       " 'fiaonllf',\n",
       " 'kianwlly',\n",
       " 'fianlslxy',\n",
       " 'fiaallw',\n",
       " 'fiaenlle',\n",
       " 'fiajnilly',\n",
       " 'fiavnllj',\n",
       " 'ftianllyl',\n",
       " 'dianllr',\n",
       " 'fbavnlly',\n",
       " 'qfuanlly',\n",
       " 'ifyanlly',\n",
       " 'rfiajnlly',\n",
       " 'fianllykl',\n",
       " 'fiaenlmy',\n",
       " 'fiacllyt',\n",
       " 'fianllyng',\n",
       " 'fsanlrly',\n",
       " 'fsiqanlly',\n",
       " 'fiaynxlly',\n",
       " 'fiananlly',\n",
       " 'mfianllt',\n",
       " 'ifiahnlly',\n",
       " 'fianlphy',\n",
       " 'fiankllvy',\n",
       " 'fhanlljy',\n",
       " 'fiaallyo',\n",
       " 'yianrly',\n",
       " 'gjfianlly',\n",
       " 'tianlkly',\n",
       " 'fianliyj',\n",
       " 'fianlnk',\n",
       " 'fxanllb',\n",
       " 'figanllyz',\n",
       " 'fieelly',\n",
       " 'fianilyy',\n",
       " 'fiaynhly',\n",
       " 'gainlly',\n",
       " 'fimnlldy',\n",
       " 'fiycnlly',\n",
       " 'fbianzly',\n",
       " 'fivjnlly',\n",
       " 'fiazlty',\n",
       " 'nfidnlly',\n",
       " 'cafianlly',\n",
       " 'ftanlcy',\n",
       " 'fuanluly',\n",
       " 'fianlilyt',\n",
       " 'fitandly',\n",
       " 'fianllytp',\n",
       " 'fixanlli',\n",
       " 'aianglly',\n",
       " 'fsanmly',\n",
       " 'fiandply',\n",
       " 'fiianjlly',\n",
       " 'fcianvly',\n",
       " 'fianillyu',\n",
       " 'pianlzly',\n",
       " 'fiallxy',\n",
       " 'fianhlyj',\n",
       " 'vfqanlly',\n",
       " 'zianluly',\n",
       " 'aianllby',\n",
       " 'fkanklly',\n",
       " 'fxianlbly',\n",
       " 'fianllpyr',\n",
       " 'fisnllyj',\n",
       " 'eianllh',\n",
       " 'fwiadlly',\n",
       " 'vfiaynlly',\n",
       " 'fiandlla',\n",
       " 'fiahnlvy',\n",
       " 'qiandlly',\n",
       " 'ifiahlly',\n",
       " 'fiandally',\n",
       " 'fijnllc',\n",
       " 'dfianllay',\n",
       " 'fianlala',\n",
       " 'fianluya',\n",
       " 'fiuunlly',\n",
       " 'fianlbldy',\n",
       " 'fiatnllyf',\n",
       " 'fiqlly',\n",
       " 'fianlyv',\n",
       " 'lianllyv',\n",
       " 'fiaenjlly',\n",
       " 'mfiantlly',\n",
       " 'tipanlly',\n",
       " 'fiagnllf',\n",
       " 'kfifnlly',\n",
       " 'fiabll',\n",
       " 'fiavxnlly',\n",
       " 'fidnyly',\n",
       " 'fiaqnllyz',\n",
       " 'franltly',\n",
       " 'fiandjlly',\n",
       " 'biganlly',\n",
       " 'feanllm',\n",
       " 'fianilvly',\n",
       " 'fialnlyb',\n",
       " 'fiacnnly',\n",
       " 'fianlki',\n",
       " 'flihnlly',\n",
       " 'lianlcly',\n",
       " 'fqianllp',\n",
       " 'fiwanllyf',\n",
       " 'finlvy',\n",
       " 'lianlply',\n",
       " 'fipnllyq',\n",
       " 'fsanlyl',\n",
       " 'pianlrly',\n",
       " 'fipnoly',\n",
       " 'fianlelzy',\n",
       " 'qjfianlly',\n",
       " 'fiablwy',\n",
       " 'fwianluly',\n",
       " 'kganlly',\n",
       " 'ftiaclly',\n",
       " 'fiynlfy',\n",
       " 'efianwlly',\n",
       " 'fiarlkly',\n",
       " 'fivanlzly',\n",
       " 'hfikanlly',\n",
       " 'fianflny',\n",
       " 'fianrllo',\n",
       " 'lianlle',\n",
       " 'kiaonlly',\n",
       " 'fianlblg',\n",
       " 'fibahlly',\n",
       " 'fxalnly',\n",
       " 'fqiafnlly',\n",
       " 'fxiabnlly',\n",
       " 'bianlwy',\n",
       " 'fuaknlly',\n",
       " 'bfzanlly',\n",
       " 'fgiaflly',\n",
       " 'jfaanlly',\n",
       " 'finntlly',\n",
       " 'fianvlmy',\n",
       " 'fimanlby',\n",
       " 'fobanlly',\n",
       " 'fianillfy',\n",
       " 'ofiailly',\n",
       " 'zeianlly',\n",
       " 'fianlljyl',\n",
       " 'mfizanlly',\n",
       " 'tianllj',\n",
       " 'fiznllyi',\n",
       " 'franlply',\n",
       " 'fianlwty',\n",
       " 'ftianzly',\n",
       " 'nianlrly',\n",
       " 'fiancllp',\n",
       " 'fianvllo',\n",
       " 'fikanlxly',\n",
       " 'fiazllhy',\n",
       " 'yfianllfy',\n",
       " 'fiianlcly',\n",
       " 'foanvlly',\n",
       " 'fimaenlly',\n",
       " 'fivanflly',\n",
       " 'fifanhly',\n",
       " 'finallly',\n",
       " 'ifdanlly',\n",
       " 'ffizanlly',\n",
       " 'fianlklwy',\n",
       " 'fzianllym',\n",
       " 'faianllz',\n",
       " 'afqanlly',\n",
       " 'fianqwy',\n",
       " 'kfianrly',\n",
       " 'fianlliyj',\n",
       " 'fcianll',\n",
       " 'fiatlldy',\n",
       " 'fixanllt',\n",
       " 'feaynlly',\n",
       " 'fianllnjy',\n",
       " 'fjanluy',\n",
       " 'fianqlloy',\n",
       " 'fiasnllj',\n",
       " 'fianvlpy',\n",
       " 'fmiacnlly',\n",
       " 'xoanlly',\n",
       " 'fiaslxy',\n",
       " 'fianllcg',\n",
       " 'fiazwnlly',\n",
       " 'fiafllhy',\n",
       " 'yfiailly',\n",
       " 'foanglly',\n",
       " 'fiancally',\n",
       " 'fiadqlly',\n",
       " 'fjianqlly',\n",
       " 'bianlld',\n",
       " 'fianlnlyi',\n",
       " 'vianllyw',\n",
       " 'fiahllo',\n",
       " 'fianrfly',\n",
       " 'fiuajlly',\n",
       " 'fhianllw',\n",
       " 'vvanlly',\n",
       " 'fiabnllyh',\n",
       " 'fiatnlls',\n",
       " 'esanlly',\n",
       " 'fianlqlq',\n",
       " 'fianlqlyq',\n",
       " 'mianlxy',\n",
       " 'fqianllym',\n",
       " 'fianldlyq',\n",
       " 'fsxnlly',\n",
       " 'fifnlwy',\n",
       " 'uyanlly',\n",
       " 'fcagnlly',\n",
       " 'fiagtlly',\n",
       " 'nfiranlly',\n",
       " 'fiarlnlly',\n",
       " 'fbantlly',\n",
       " 'flanxly',\n",
       " 'fikanlnly',\n",
       " 'fiandlliy',\n",
       " 'fiailty',\n",
       " 'fioznlly',\n",
       " 'fwdianlly',\n",
       " 'srianlly',\n",
       " 'fignlnly',\n",
       " 'fiaslvly',\n",
       " 'fganlli',\n",
       " 'fivanely',\n",
       " 'fiaonklly',\n",
       " 'fbialnlly',\n",
       " 'fianlldyq',\n",
       " 'fianllxw',\n",
       " 'fjxnlly',\n",
       " 'iacnlly',\n",
       " 'fiwanlloy',\n",
       " 'fiapflly',\n",
       " 'ffiwnlly',\n",
       " 'ftzianlly',\n",
       " 'efianlply',\n",
       " 'ofianlkly',\n",
       " 'aimanlly',\n",
       " 'fihanllyi',\n",
       " 'fiakllyi',\n",
       " 'qfianlqly',\n",
       " 'failly',\n",
       " 'fianllcr',\n",
       " 'fuianllz',\n",
       " 'gsanlly',\n",
       " 'ftanllgy',\n",
       " 'dianley',\n",
       " 'sfianluy',\n",
       " 'feianhly',\n",
       " 'fianlvuy',\n",
       " 'fkianlley',\n",
       " 'fianlmyl',\n",
       " 'qiamlly',\n",
       " 'fpianlhly',\n",
       " 'faanllyo',\n",
       " 'fbianlqy',\n",
       " 'aafianlly',\n",
       " 'fianhklly',\n",
       " 'fianwllyl',\n",
       " 'fianllyv',\n",
       " 'fianluyr',\n",
       " 'afiantly',\n",
       " 'fianlfyx',\n",
       " 'fianlrys',\n",
       " 'fimnllay',\n",
       " 'mfianllgy',\n",
       " 'fdnnlly',\n",
       " 'nipnlly',\n",
       " 'fiannla',\n",
       " 'fainllty',\n",
       " 'fiavnlll',\n",
       " 'jfianldly',\n",
       " 'fzianllry',\n",
       " 'qinanlly',\n",
       " 'fyaolly',\n",
       " 'fiiianlly',\n",
       " 'vianhlly',\n",
       " 'fioanzlly',\n",
       " 'fdianllyn',\n",
       " 'fimanklly',\n",
       " 'fiajnhlly',\n",
       " 'rfianlldy',\n",
       " 'uianllyv',\n",
       " 'pianvlly',\n",
       " 'dyianlly',\n",
       " 'fiiailly',\n",
       " 'finnlhly',\n",
       " 'fiajhlly',\n",
       " 'fkianllyl',\n",
       " 'finallwy',\n",
       " 'fiknsly',\n",
       " 'tignlly',\n",
       " 'francly',\n",
       " 'finlply',\n",
       " 'fqianljy',\n",
       " 'fianwlcy',\n",
       " 'fipanllay',\n",
       " 'fiacnllu',\n",
       " 'fianrxlly',\n",
       " 'pianllyr',\n",
       " 'fianlmlo',\n",
       " 'ofoianlly',\n",
       " 'fijanklly',\n",
       " 'fiaintlly',\n",
       " 'fiavljly',\n",
       " 'ftianlley',\n",
       " 'lfianjlly',\n",
       " 'fiacnqlly',\n",
       " 'cianlty',\n",
       " 'feiuanlly',\n",
       " 'kfianllyg',\n",
       " 'fjianllyh',\n",
       " 'fpaklly',\n",
       " 'fkanllyk',\n",
       " 'hianily',\n",
       " 'fihanlluy',\n",
       " 'fxianllv',\n",
       " 'fiansllyf',\n",
       " 'fianlklym',\n",
       " 'ifanlzy',\n",
       " 'ofiajlly',\n",
       " 'fikdanlly',\n",
       " 'xiaflly',\n",
       " 'xfianlwly',\n",
       " 'fianlut',\n",
       " 'fiznmlly',\n",
       " 'fivndly',\n",
       " 'fuianldly',\n",
       " 'zfianlyy',\n",
       " 'fhiajlly',\n",
       " 'xiallly',\n",
       " 'fjianllyd',\n",
       " 'ofiangly',\n",
       " 'sianllyl',\n",
       " 'pfianlfly',\n",
       " 'hiasnlly',\n",
       " 'fianflld',\n",
       " 'fianllkhy',\n",
       " 'fiantlk',\n",
       " 'fpianllx',\n",
       " 'fiawlhy',\n",
       " 'fianfslly',\n",
       " 'fxianlvly',\n",
       " 'fiadnylly',\n",
       " 'fiannllyy',\n",
       " 'ibnlly',\n",
       " 'fjianllgy',\n",
       " 'uianllj',\n",
       " 'mianplly',\n",
       " 'fianjllb',\n",
       " 'fwikanlly',\n",
       " 'kianlkly',\n",
       " 'fiansvy',\n",
       " 'dixnlly',\n",
       " 'fdanltly',\n",
       " 'fiknllyt',\n",
       " 'vfianllyi',\n",
       " 'fiamnlyy',\n",
       " 'viafnlly',\n",
       " 'fionllyg',\n",
       " 'fciwnlly',\n",
       " 'ziatlly',\n",
       " 'fvisanlly',\n",
       " 'ftaflly',\n",
       " 'sfianllys',\n",
       " 'fhuianlly',\n",
       " 'fvidnlly',\n",
       " 'ufiannlly',\n",
       " 'fkianllh',\n",
       " 'fifnllw',\n",
       " 'lihanlly',\n",
       " 'fianflyl',\n",
       " 'wfianlmly',\n",
       " 'fmcanlly',\n",
       " 'fipnllxy',\n",
       " 'fiadnllyz',\n",
       " 'rianley',\n",
       " 'figngly',\n",
       " 'fiamllfy',\n",
       " 'fkanlhly',\n",
       " 'fiilly',\n",
       " 'fianllkn',\n",
       " 'fiafaly',\n",
       " 'fnanlsly',\n",
       " 'fiatnllc',\n",
       " 'vuanlly',\n",
       " 'ffiantlly',\n",
       " 'wfiaunlly',\n",
       " 'fianhlldy',\n",
       " 'fihanlfy',\n",
       " 'fiaonloly',\n",
       " 'fhnanlly',\n",
       " 'fiangjly',\n",
       " 'fpamnlly',\n",
       " 'finrally',\n",
       " 'fsanllyn',\n",
       " 'fxianlsy',\n",
       " 'ftanlldy',\n",
       " 'fianllyu',\n",
       " 'ficblly',\n",
       " 'fiwaynlly',\n",
       " 'fiaiflly',\n",
       " 'fianrllyz',\n",
       " 'fiathlly',\n",
       " 'fianljlyq',\n",
       " 'figanlbly',\n",
       " 'fniailly',\n",
       " 'fianlzlyx',\n",
       " 'ficnllyg',\n",
       " 'gfiajnlly',\n",
       " 'cienlly',\n",
       " 'fianflyk',\n",
       " 'faanlyly',\n",
       " 'cfiaully',\n",
       " 'fimamnlly',\n",
       " 'fihanlxy',\n",
       " 'fliahnlly',\n",
       " 'ofianwly',\n",
       " 'fyiallly',\n",
       " 'pianlll',\n",
       " 'fnaflly',\n",
       " 'cianlnly',\n",
       " 'fihqanlly',\n",
       " 'fianzlhy',\n",
       " 'foiainlly',\n",
       " 'iarlly',\n",
       " 'lfiaally',\n",
       " 'fjianly',\n",
       " 'mflianlly',\n",
       " 'cianlluy',\n",
       " 'frianyly',\n",
       " 'fiankklly',\n",
       " 'fiasnlljy',\n",
       " 'fianlapy',\n",
       " 'hainlly',\n",
       " 'oiaclly',\n",
       " 'ufiavlly',\n",
       " 'fiawnllyj',\n",
       " 'franxlly',\n",
       " 'edianlly',\n",
       " 'fiagply',\n",
       " 'fcanllr',\n",
       " 'fimnllyu',\n",
       " 'fidanllyu',\n",
       " 'zfjianlly',\n",
       " 'ufqianlly',\n",
       " 'fianllcoy',\n",
       " 'fkaflly',\n",
       " 'tfiavnlly',\n",
       " 'fzanqly',\n",
       " 'fioablly',\n",
       " 'fiuyanlly',\n",
       " 'firnllw',\n",
       " 'fianlill',\n",
       " 'firanllry',\n",
       " 'fianrljy',\n",
       " 'fianlhyj',\n",
       " 'pfialnlly',\n",
       " 'fianollyy',\n",
       " 'fmankly',\n",
       " 'fikanrly',\n",
       " 'fiwnklly',\n",
       " 'pianrly',\n",
       " 'filanolly',\n",
       " 'tfianlhly',\n",
       " 'fianmlzy',\n",
       " 'fhanllmy',\n",
       " 'gfhianlly',\n",
       " 'fiahnllv',\n",
       " 'fqianlcy',\n",
       " 'kianllgy',\n",
       " 'fitnllm',\n",
       " 'fqianllyp',\n",
       " 'fiaelzly',\n",
       " 'fianlmbly',\n",
       " 'fiabllhy',\n",
       " 'fiainlloy',\n",
       " 'fikaelly',\n",
       " 'qfwianlly',\n",
       " 'fiaqnllhy',\n",
       " 'efiagnlly',\n",
       " 'fiamnllyw',\n",
       " 'zianlqy',\n",
       " 'fmianllyc',\n",
       " 'fiaunllmy',\n",
       " 'fiasnllya',\n",
       " 'fiwfnlly',\n",
       " 'omianlly',\n",
       " 'fizanllyw',\n",
       " 'fiadhnlly',\n",
       " 'iianlvly',\n",
       " 'fianllqsy',\n",
       " 'fiynllyd',\n",
       " 'bfiahnlly',\n",
       " 'fianlolf',\n",
       " 'fiavllw',\n",
       " 'ozianlly',\n",
       " 'vianely',\n",
       " 'fianpllye',\n",
       " 'bfianljy',\n",
       " 'fpiandly',\n",
       " 'fivanllyl',\n",
       " 'fianllob',\n",
       " 'fiansllv',\n",
       " 'filnllyt',\n",
       " 'fzanllsy',\n",
       " 'fiyangly',\n",
       " 'fitnllyg',\n",
       " 'hisnlly',\n",
       " 'fianldyk',\n",
       " 'fipanllgy',\n",
       " 'frranlly',\n",
       " 'qlianlly',\n",
       " 'fiaaclly',\n",
       " 'jianily',\n",
       " 'fianaay',\n",
       " 'mfianhly',\n",
       " 'frianrly',\n",
       " 'fuianlcly',\n",
       " 'fviamlly',\n",
       " 'feianllmy',\n",
       " 'fiajnally',\n",
       " 'fianlcply',\n",
       " 'fikanllj',\n",
       " 'qnanlly',\n",
       " 'emanlly',\n",
       " 'fzmianlly',\n",
       " 'efianlzy',\n",
       " 'finlpy',\n",
       " 'fiahuly',\n",
       " 'fianlnyg',\n",
       " 'fjajnlly',\n",
       " 'fianxl',\n",
       " 'ifiasnlly',\n",
       " 'fiadtlly',\n",
       " 'fsanlloy',\n",
       " 'fijanmly',\n",
       " 'pianllf',\n",
       " 'fganlqy',\n",
       " 'figjlly',\n",
       " 'fdifnlly',\n",
       " 'fijnilly',\n",
       " 'fiaotnlly',\n",
       " 'fiinloy',\n",
       " 'mbfianlly',\n",
       " 'faanlvy',\n",
       " 'fiaxllj',\n",
       " 'fsimanlly',\n",
       " 'fiannllg',\n",
       " 'fiaejly',\n",
       " 'fqianllya',\n",
       " 'fianllxys',\n",
       " 'fiaznllyo',\n",
       " 'fihlanlly',\n",
       " 'fianldb',\n",
       " 'fifmnlly',\n",
       " 'tfianlbly',\n",
       " 'fianmvlly',\n",
       " 'fianllxg',\n",
       " 'fianlsoy',\n",
       " 'fianlzlj',\n",
       " 'wianlfly',\n",
       " 'fiantfly',\n",
       " 'fimnhly',\n",
       " 'dfeianlly',\n",
       " 'fianlpd',\n",
       " 'mfisanlly',\n",
       " 'nbanlly',\n",
       " 'fcanlle',\n",
       " 'filanlli',\n",
       " 'fnanluy',\n",
       " 'fixnully',\n",
       " 'fiinllfy',\n",
       " 'fliazlly',\n",
       " 'fianllyrs',\n",
       " 'fianeyy',\n",
       " 'fiadmnlly',\n",
       " 'ftanully',\n",
       " 'fiankllzy',\n",
       " 'fvanlxy',\n",
       " 'fitanlld',\n",
       " 'gfianlhly',\n",
       " 'dfianlfy',\n",
       " 'diamlly',\n",
       " 'leanlly',\n",
       " 'aianaly',\n",
       " 'fianlcqly',\n",
       " 'fialplly',\n",
       " 'fihanolly',\n",
       " 'fixnllym',\n",
       " 'efiancly',\n",
       " 'clanlly',\n",
       " 'cfiqanlly',\n",
       " 'fiafnlsy',\n",
       " 'fiabllyr',\n",
       " 'mianqlly',\n",
       " 'fjanlliy',\n",
       " 'kifnlly',\n",
       " 'fuianlldy',\n",
       " 'eiajlly',\n",
       " 'fanluly',\n",
       " 'fiagvnlly',\n",
       " 'filnloy',\n",
       " 'lianqly',\n",
       " 'fiayplly',\n",
       " 'foilanlly',\n",
       " 'lfianllyb',\n",
       " 'fiafxly',\n",
       " 'finallyd',\n",
       " 'bibnlly',\n",
       " 'biuanlly',\n",
       " 'gfianlnly',\n",
       " 'fiaolle',\n",
       " 'fhianily',\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two edit distances from input word\n",
    "edits2(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faintly', 'finally', 'finely', 'frankly'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits2(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = (known(edits0(word)) or \n",
    "              known(edits1(word)) or \n",
    "              known(edits2(word)) or \n",
    "              [word])\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    \"\"\"\n",
    "    Get the best correct spelling for the input word\n",
    "    \"\"\"\n",
    "    # Priority is for edit distance 0, then 1, then 2\n",
    "    # else defaults to the input word itself.\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=WORD_COUNTS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FIANLLY'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('FIANLLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_match(match):\n",
    "    \"\"\"\n",
    "    Spell-correct word in match, \n",
    "    and preserve proper upper/lower/title case.\n",
    "    \"\"\"\n",
    "    \n",
    "    word = match.group()\n",
    "    def case_of(text):\n",
    "        \"\"\"\n",
    "        Return the case-function appropriate \n",
    "        for text: upper, lower, title, or just str.:\n",
    "            \"\"\"\n",
    "        return (str.upper if text.isupper() else\n",
    "                str.lower if text.islower() else\n",
    "                str.title if text.istitle() else\n",
    "                str)\n",
    "    return case_of(word)(correct(word.lower()))\n",
    "\n",
    "    \n",
    "def correct_text_generic(text):\n",
    "    \"\"\"\n",
    "    Correct all the words within a text, \n",
    "    returning the corrected text.\n",
    "    \"\"\"\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINALLY'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('FIANLLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "w = Word('fianlly')\n",
    "w.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('finally', 1.0)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flat', 0.85), ('float', 0.15)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('flaot')\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lie'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strang'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('strange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lancaster Stemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "ls = LancasterStemmer()\n",
    "\n",
    "ls.stem('jumping'), ls.stem('jumps'), ls.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lying'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strange'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.stem('strange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('jump', 'jump', 'jump')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regex based stemmer\n",
    "from nltk.stem import RegexpStemmer\n",
    "rs = RegexpStemmer('ing$|s$|ed$', min=4)\n",
    "rs.stem('jumping'), rs.stem('jumps'), rs.stem('jumped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ly'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.stem('lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strange'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.stem('strange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Languages: ('danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "# Snowball Stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "ss = SnowballStemmer(\"german\")\n",
    "print('Supported Languages:', SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobahn'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming on German words\n",
    "# autobahnen -> cars\n",
    "# autobahn -> car\n",
    "ss.stem('autobahnen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spring'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# springen -> jumping\n",
    "# spring -> jump\n",
    "ss.stem('springen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash hi crash yesterday, our crash daili'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "men\n"
     ]
    }
   ],
   "source": [
    "# lemmatize nouns\n",
    "print(wnl.lemmatize('cars', 'n'))\n",
    "print(wnl.lemmatize('men', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "# lemmatize verbs\n",
    "print(wnl.lemmatize('running', 'v'))\n",
    "print(wnl.lemmatize('ate', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "fancy\n"
     ]
    }
   ],
   "source": [
    "# lemmatize adjectives\n",
    "print(wnl.lemmatize('saddest', 'a'))\n",
    "print(wnl.lemmatize('fancier', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ate\n",
      "fancier\n"
     ]
    }
   ],
   "source": [
    "# ineffective lemmatization\n",
    "print(wnl.lemmatize('ate', 'n'))\n",
    "print(wnl.lemmatize('fancier', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash ! his crash yesterday , ours crash daily'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# use spacy.load('en') if you have downloaded the language model en directly after install spacy\n",
    "nlp = spacy.load('en_core', parse=True, tag=True, entity=True)\n",
    "text = 'My system keeps crashing his crashed yesterday, ours crashes daily'\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', , stopwords , computer'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text, is_lower_case=False, stopwords=stopword_list):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "remove_stopwords(\"The, and, if are stopwords, computer is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = expand_contractions(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Original': \"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\",\n",
       " 'Processed': 'us unveil world powerful supercomputer beat china us unveil world powerful supercomputer call summit beat previous record holder chinas sunway taihulight peak performance trillion calculation per second twice fast sunway taihulight capable trillion calculation per second summit server reportedly take size two tennis court'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Original': sample_text,\n",
    " 'Processed': normalize_corpus([sample_text])[0]}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
